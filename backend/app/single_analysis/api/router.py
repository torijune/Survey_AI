from fastapi import APIRouter, UploadFile, File, Form, HTTPException
from app.single_analysis.domain.use_cases import TableAnalysisUseCase
from app.single_analysis.domain.services import TableAnalysisService
from app.single_analysis.infra.openai_client import OpenAIClient
from app.single_analysis.infra.excel_loader import ExcelLoader
from app.single_analysis.infra.statistical_test import StatisticalTester

router = APIRouter(prefix="", tags=["single-analysis"])

@router.post("/parse")
async def parse_table(
    file: UploadFile = File(...),
    analysis_type: str = Form("parse")
):
    """í…Œì´ë¸” íŒŒì‹± ì—”ë“œí¬ì¸íŠ¸"""
    try:
        print(f"[parse] íŒŒì¼ëª…: {file.filename}")
        excel_loader = ExcelLoader()
        file_content = await file.read()
        print(f"[parse] íŒŒì¼ í¬ê¸°: {len(file_content)} bytes")
        
        parsed_data = excel_loader.load_survey_tables(file_content, file.filename or "unknown_file")
        print(f"[parse] íŒŒì‹±ëœ ì§ˆë¬¸ í‚¤: {parsed_data['question_keys']}")
        print(f"[parse] íŒŒì‹±ëœ í…Œì´ë¸” ìˆ˜: {len(parsed_data['tables'])}")
        
        # DataFrameì„ JSONìœ¼ë¡œ ë³€í™˜í•  ë•Œ NaN ê°’ì„ ì²˜ë¦¬
        def convert_dataframe_to_dict(df):
            if hasattr(df, 'to_dict'):
                return df.to_dict(orient="records")
            return df
        
        # NaN ê°’ì„ Noneìœ¼ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
        def clean_nan_values(data):
            if isinstance(data, dict):
                return {k: clean_nan_values(v) for k, v in data.items()}
            elif isinstance(data, list):
                return [clean_nan_values(item) for item in data]
            elif isinstance(data, float) and (data != data or data == float('inf') or data == float('-inf')):
                return None
            return data
        
        tables_dict = {}
        for k, v in parsed_data["tables"].items():
            print(f"[parse] í…Œì´ë¸” {k} ì²˜ë¦¬ ì¤‘...")
            if hasattr(v, 'to_dict'):
                # DataFrameì„ í”„ë¡ íŠ¸ì—”ë“œê°€ ê¸°ëŒ€í•˜ëŠ” êµ¬ì¡°ë¡œ ë³€í™˜
                table_dict = v.to_dict(orient="records")
                # columnsì™€ dataë¥¼ ë¶„ë¦¬
                if table_dict:
                    columns = list(table_dict[0].keys())
                    data = [list(row.values()) for row in table_dict]
                    tables_dict[k] = {
                        "columns": columns,
                        "data": clean_nan_values(data)
                    }
                else:
                    tables_dict[k] = {
                        "columns": [],
                        "data": []
                    }
                print(f"[parse] í…Œì´ë¸” {k} ì™„ë£Œ - í–‰ ìˆ˜: {len(table_dict)}")
            else:
                tables_dict[k] = v
                print(f"[parse] í…Œì´ë¸” {k} ì™„ë£Œ - DataFrameì´ ì•„ë‹˜")
        
        result = {
            "success": True,
            "question_keys": parsed_data["question_keys"],
            "question_texts": parsed_data["question_texts"],
            "tables": tables_dict
        }
        
        print(f"[parse] ì‘ë‹µ ì™„ë£Œ - ì§ˆë¬¸ ìˆ˜: {len(result['question_keys'])}")
        return result
    except Exception as e:
        print(f"[parse] ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/recommend-test-types")
async def recommend_test_types(
    file: UploadFile = File(...),
    analysis_type: str = Form("recommend_test_types"),
    lang: str = Form("í•œêµ­ì–´"),
    use_statistical_test: str = Form("true")
):
    """í†µê³„ ê²€ì • ë°©ë²• ì¶”ì²œ ì—”ë“œí¬ì¸íŠ¸"""
    try:
        excel_loader = ExcelLoader()
        openai_client = OpenAIClient()
        file_content = await file.read()
        
        # íŒŒì¼ íŒŒì‹±
        parsed_data = excel_loader.load_survey_tables(file_content, file.filename or "unknown_file")
        question_keys = parsed_data["question_keys"]
        question_texts = parsed_data["question_texts"]
        tables = parsed_data["tables"]
        
        # í†µê³„ ê²€ì • ë¯¸ì‚¬ìš© ì‹œ ëª¨ë“  ì§ˆë¬¸ì„ manualë¡œ ì„¤ì •
        if use_statistical_test.lower() != "true":
            test_type_map = {key: "manual" for key in question_keys}
            return {
                "success": True,
                "test_type_map": test_type_map
            }
        
        # í†µê³„ ê²€ì • ì‚¬ìš© ì‹œ LLMìœ¼ë¡œ ì¶”ì²œ
        test_type_map = {}
        for key in question_keys:
            if key in tables and key in question_texts:
                table = tables[key]
                question_text = question_texts[key]
                
                # LLMìœ¼ë¡œ í†µê³„ ê²€ì • ë°©ë²• ì¶”ì²œ
                prompt = f"""
ë‹¹ì‹ ì€ í†µê³„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì•„ë˜ëŠ” ì„¤ë¬¸ ë¬¸í•­ê³¼ ì—´ ì´ë¦„ ëª©ë¡ì…ë‹ˆë‹¤.

ë¬¸í•­: {question_text}
ì—´ ì´ë¦„: {', '.join(table.columns.tolist())}

ë‹¹ì‹ ì˜ ì„ë¬´ëŠ”, ì´ ë¬¸í•­ì´ ì•„ë˜ ì¤‘ ì–´ë–¤ í†µê³„ ë¶„ì„ ìœ í˜•ì— í•´ë‹¹í•˜ëŠ”ì§€ ë¶„ë¥˜í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

ğŸ“‹ ë¶„ë¥˜ ê¸°ì¤€:

1ï¸âƒ£ **manual** (ë³µìˆ˜ì‘ë‹µ/ë‹¤ì¤‘ì‘ë‹µ/ìˆœìœ„í˜•):
    - í•œ ì‘ë‹µìê°€ ì—¬ëŸ¬ í•­ëª©ì„ ì„ íƒí•˜ê±°ë‚˜, ì—¬ëŸ¬ ìˆœìœ„ë¥¼ ë™ì‹œì— ì‘ë‹µí•˜ëŠ” ê²½ìš°
    - ì˜ˆì‹œ: "ë³µìˆ˜ì‘ë‹µ", "ë‹¤ì¤‘ì‘ë‹µ", "1+2ìˆœìœ„", "1+2+3ìˆœìœ„", "ranking", "ìš°ì„ ìˆœìœ„(1+2)", "ë‹¤ì¤‘ì„ íƒ", "ëª¨ë‘ì„ íƒ"
    - ë¬¸í•­ì— "ë³µìˆ˜", "ë‹¤ì¤‘", "multiple", "ranking" ë“±ì´ í¬í•¨ëœ ê²½ìš°

2ï¸âƒ£ **ft_test** (ì—°ì†í˜• ìˆ˜ì¹˜ ì‘ë‹µ):
    - ë¬¸í•­ì´ 1~5ì  ì²™ë„, í‰ê· , ë¹„ìœ¨, ì ìˆ˜ ë“± ìˆ«ì ê¸°ë°˜ìœ¼ë¡œ ìš”ì•½ë˜ì–´ ìˆëŠ” ê²½ìš°
    - ì˜ˆì‹œ ì—´ ì´ë¦„: "í‰ê· ", "ë§Œì¡±ë„ ì ìˆ˜", "~% ë¹„ìœ¨", "5ì  ì²™ë„", "í‰ê·  ì ìˆ˜", "ê´€ì‹¬ë„ í‰ê· "
    - "ì „í˜€ ê´€ì‹¬ì´ ì—†ë‹¤", "ë§¤ìš° ê´€ì‹¬ ìˆë‹¤" ë“±ì€ ì‹¤ì œë¡œëŠ” ì„ íƒì§€ì´ì§€ë§Œ, ë¹ˆë„ë‚˜ ë¹„ìœ¨ë¡œ ìˆ˜ì¹˜í™”ë˜ì—ˆì„ ê²½ìš° â†’ ì—°ì†í˜•ìœ¼ë¡œ íŒë‹¨

3ï¸âƒ£ **chi_square** (ë²”ì£¼í˜• ì„ íƒ ì‘ë‹µ):
    - ë¬¸í•­ì´ ì‘ë‹µìë“¤ì´ íŠ¹ì • í•­ëª©ì„ **ì„ íƒ**í•˜ê±°ë‚˜ **ë‹¤ì¤‘ì„ íƒ**í•œ ê²°ê³¼ì¼ ê²½ìš°
    - ì˜ˆì‹œ ì—´ ì´ë¦„: "ì£¼ìš” ì´ìš©ì‹œì„¤", "ì„ íƒ ì´ìœ ", "ê°€ì¥ ë§ì´ ì„ íƒí•œ ì¥ì†Œ", "ë‹¤ì¤‘ ì‘ë‹µ"
    - ë‹¨ì¼ ì„ íƒ ë¬¸í•­ (í•œ ëª…ì´ í•œ í•­ëª©ë§Œ ì„ íƒí•˜ëŠ” ê²½ìš°)

ì•„ë˜ ì¤‘ í•˜ë‚˜ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”(ì„¤ëª… ì—†ì´):
- manual
- ft_test  
- chi_square
"""
                
                messages = [
                    {"role": "system", "content": "ë‹¹ì‹ ì€ í†µê³„ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ]
                
                response = await openai_client.call(messages)
                test_type = response.strip().lower()
                
                # ì‘ë‹µ ê²€ì¦
                if test_type not in ["manual", "ft_test", "chi_square"]:
                    test_type = "ft_test"  # ê¸°ë³¸ê°’
                
                test_type_map[key] = test_type
        
        return {
            "success": True,
            "test_type_map": test_type_map
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/analyze")
async def analyze_table(
    file: UploadFile = File(...),
    analysis_type: bool = Form(True),
    selected_key: str = Form(""),
    lang: str = Form("í•œêµ­ì–´"),
    user_id: str = Form(None),
    use_statistical_test: str = Form("true")
):
    try:
        openai_client = OpenAIClient()
        excel_loader = ExcelLoader()
        statistical_tester = StatisticalTester()
        service = TableAnalysisService(openai_client, excel_loader, statistical_tester)
        use_case = TableAnalysisUseCase(service)
        use_statistical_test_bool = use_statistical_test.lower() == "true"
        options = {
            "analysis_type": analysis_type,
            "selected_key": selected_key,
            "lang": lang,
            "user_id": user_id,
            "use_statistical_test": use_statistical_test_bool
        }
        if not use_statistical_test_bool:
            print(f"[table_analysis] manual mode - raw data ì—†ì´ ë¶„ì„ ì§„í–‰")
        file_content = await file.read()
        result = await use_case.execute(file_content, file.filename or "unknown_file", options)
        return result
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e)) 
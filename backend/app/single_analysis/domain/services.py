from typing import List, Dict, Any, Optional
import pandas as pd
import numpy as np
from app.single_analysis.domain.entities import AgentState
from app.single_analysis.infra.openai_client import OpenAIClient
from app.single_analysis.infra.excel_loader import ExcelLoader
from app.single_analysis.infra.statistical_test import StatisticalTester
import re


class TableAnalysisService:
    """í…Œì´ë¸” ë¶„ì„ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ì„œë¹„ìŠ¤"""
    
    def __init__(self, openai_client: OpenAIClient, excel_loader: ExcelLoader, statistical_tester: StatisticalTester):
        self.openai_client = openai_client
        self.excel_loader = excel_loader
        self.statistical_tester = statistical_tester
    
    async def parse_table(self, state: AgentState, on_step=None) -> AgentState:
        """í…Œì´ë¸” íŒŒì„œ ë…¸ë“œ""" 
        if on_step:
            on_step("ğŸ“Š í…Œì´ë¸” íŒŒì„œ ë…¸ë“œ ì‹œì‘")
        
        # íŒŒì¼ì—ì„œ í…Œì´ë¸” íŒŒì‹±
        if state.uploaded_file:
            parsed_data = self.excel_loader.load_survey_tables(
                state.uploaded_file,
                state.file_path
            )
            state.tables = parsed_data["tables"]
            state.question_texts = parsed_data["question_texts"]
            state.question_keys = parsed_data["question_keys"]
        
        # ì„ íƒëœ í‚¤ ë§¤ì¹­
        if state.selected_key and state.tables:
            matching_key = self.excel_loader.find_matching_key(state.selected_key, list(state.tables.keys()))
            if matching_key:
                state.selected_key = matching_key
                state.selected_table = state.tables[matching_key]
                state.selected_question = state.question_texts[matching_key]
            elif state.analysis_type:
                raise Exception(f"ì„ íƒëœ ì§ˆë¬¸ í‚¤ '{state.selected_key}'ì— í•´ë‹¹í•˜ëŠ” í…Œì´ë¸”ì´ ì—†ìŠµë‹ˆë‹¤.")
            else:
                # ë°°ì¹˜ ë¶„ì„ì˜ ê²½ìš° ì²« ë²ˆì§¸ ì§ˆë¬¸ ì‚¬ìš©
                state.selected_key = state.question_keys[0]
                state.selected_table = state.tables[state.selected_key]
                state.selected_question = state.question_texts[state.selected_key]
        
        # í…Œì´ë¸” ì„ í˜•í™”
        if state.selected_table is not None:
            state.linearized_table = self.linearize_row_wise(state.selected_table)
        
        return state
    
    def linearize_row_wise(self, table: pd.DataFrame) -> str:
        """í…Œì´ë¸”ì„ í–‰ ë‹¨ìœ„ë¡œ ì„ í˜•í™”"""
        if table is None or table.empty:
            return ""
        
        # ìˆ«ì ì»¬ëŸ¼ë§Œ ì„ íƒ
        numeric_cols = table.select_dtypes(include=[np.number]).columns.tolist()
        if not numeric_cols:
            return ""
        
        # ì²« ë²ˆì§¸ ì»¬ëŸ¼ (ê·¸ë£¹ëª…)ê³¼ ìˆ«ì ì»¬ëŸ¼ë“¤ë§Œ ì‚¬ìš©
        result_cols = [table.columns[0]] + numeric_cols
        result_df = table[result_cols]
        
        # í–‰ ë‹¨ìœ„ë¡œ ë¬¸ìì—´ ë³€í™˜
        rows = []
        for _, row in result_df.iterrows():
            row_str = " | ".join([str(val) for val in row.values])
            rows.append(row_str)
        
        return "\n".join(rows)
    
    async def generate_hypothesis(self, state: AgentState, on_step=None) -> AgentState:
        """ê°€ì„¤ ìƒì„± ë…¸ë“œ"""
        if on_step:
            on_step("ğŸ’¡ ê°€ì„¤ ìƒì„± ë…¸ë“œ ì‹œì‘")

        selected_table = state.selected_table
        selected_question = state.selected_question
        lang = state.lang if hasattr(state, 'lang') else "í•œêµ­ì–´"

        # rowì™€ column name ì¶”ì¶œ
        if selected_table is not None and isinstance(selected_table, pd.DataFrame):
            if "ëŒ€ë¶„ë¥˜" in selected_table.columns and "ì†Œë¶„ë¥˜" in selected_table.columns:
                selected_table = selected_table.copy()
                selected_table["row_name"] = selected_table["ëŒ€ë¶„ë¥˜"].astype(str) + "_" + selected_table["ì†Œë¶„ë¥˜"].astype(str)
                row_names = selected_table["row_name"].dropna().tolist()
            else:
                row_names = list(selected_table.index)
            column_names = list(selected_table.columns)
        else:
            row_names = []
            column_names = []

        row_names_str = ", ".join(map(str, row_names))
        column_names_str = ", ".join(map(str, column_names))

        # í”„ë¡¬í”„íŠ¸ ì •ì˜
        HYPOTHESIS_PROMPT = {
            "í•œêµ­ì–´": """
        ë‹¹ì‹ ì€ í†µê³„ ë°ì´í„°ë¥¼ í•´ì„í•˜ëŠ” ë°ì´í„° ê³¼í•™ìì…ë‹ˆë‹¤.
        ì•„ë˜ëŠ” ë¶„ì„í•  í‘œì˜ rowëª… (index)ê³¼ columnëª…ì…ë‹ˆë‹¤.

        row: {row_names}
        column: {column_names}

        ë‹¹ì‹ ì˜ ì„ë¬´ëŠ”, ì‚¬ìš©ìì˜ ì§ˆë¬¸ ("{selected_question}")ê³¼ ê´€ë ¨í•´  
        ë°ì´í„°ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆì„ ë²•í•œ ê°€ì„¤(íŒ¨í„´, ê´€ê³„)ì„ 2~5ê°œ ì •ë„ ì œì•ˆí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

        ì˜ˆì‹œ:
        1. ì—°ë ¹ëŒ€ê°€ ë†’ì„ìˆ˜ë¡ ê´€ì‹¬ë„ê°€ ë†’ì„ ê²ƒì´ë‹¤.
        2. ê¸°ì €ì§ˆí™˜ì´ ìˆëŠ” ê²½ìš° ê´€ì‹¬ë„ê°€ ë†’ì„ ê²ƒì´ë‹¤.

        - ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ í•©ë¦¬ì ì¸ ê°€ì„¤ë§Œ ìƒì„±í•  ê²ƒ
        - ì™¸ë¶€ ì§€ì‹ì€ ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€
        - ë¬¸ì¥ ê¸¸ì´ëŠ” ì§§ê³ , ë²ˆí˜¸ ë¦¬ìŠ¤íŠ¸ë¡œ ì‘ì„±
        """,
            "English": """
        You are a data scientist interpreting statistical tables.
        Below are the row names (index) and column names of the table to be analyzed.

        row: {row_names}
        column: {column_names}

        Your task is to propose 2 to 5 hypotheses (patterns or relationships) relevant to the user's question ("{selected_question}") that could be inferred from the data.

        Example:
        1. Older age groups may show higher interest.
        2. Those with chronic illnesses may show higher concern.

        - Only propose reasonable hypotheses based on the data
        - Do not use external knowledge
        - Keep sentences short and format as a numbered list
        """
        }

        prompt = HYPOTHESIS_PROMPT[lang].format(
            row_names=row_names_str,
            column_names=column_names_str,
            selected_question=selected_question
        )

        messages = [
            {"role": "system", "content": "ë‹¹ì‹ ì€ í†µê³„ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤." if lang == "í•œêµ­ì–´" else "You are a statistical analysis expert."},
            {"role": "user", "content": prompt}
        ]

        state.generated_hypotheses = await self.openai_client.call(messages)
        return state
    
    async def decide_test_type(self, state: AgentState, on_step=None) -> AgentState:
        """í†µê³„ ê²€ì • ë°©ë²• LLM ë‹¨ì¼ ë¶„ë¥˜ ë…¸ë“œ (manual/ft_test/chi_square)"""
        if on_step:
            on_step("ğŸ§­ í†µê³„ ê²€ì • ê²°ì • ë…¸ë“œ ì‹œì‘")
        
        use_statistical_test = getattr(state, 'use_statistical_test', True)
        
        # í†µê³„ ê²€ì • ë¯¸ì‚¬ìš© ì‹œ ìë™ìœ¼ë¡œ manualë¡œ ì„¤ì •
        if not use_statistical_test:
            print("[decide_test_type] í†µê³„ ê²€ì • ë¯¸ì‚¬ìš© - ìë™ìœ¼ë¡œ manualë¡œ ì„¤ì •")
            state.test_type = "manual"
            return state
        
        # í†µê³„ ê²€ì • ì‚¬ìš© ì‹œ: ê¸°ì¡´ LLM ë¡œì§
        if state.selected_table is not None:
            columns = state.selected_table.columns.tolist()
            question_text = getattr(state, 'selected_question', "")
            column_names_str = ", ".join(columns)
            TEST_TYPE_PROMPT = """
ë‹¹ì‹ ì€ í†µê³„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì•„ë˜ëŠ” ì„¤ë¬¸ ë¬¸í•­ê³¼ ì—´ ì´ë¦„ ëª©ë¡ì…ë‹ˆë‹¤.

ë¬¸í•­: {question_text}
ì—´ ì´ë¦„: {column_names}

ë‹¹ì‹ ì˜ ì„ë¬´ëŠ”, ì´ ë¬¸í•­ì´ ì•„ë˜ ì¤‘ ì–´ë–¤ í†µê³„ ë¶„ì„ ìœ í˜•ì— í•´ë‹¹í•˜ëŠ”ì§€ ë¶„ë¥˜í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

ğŸ“‹ ë¶„ë¥˜ ê¸°ì¤€:

1ï¸âƒ£ **manual** (ë³µìˆ˜ì‘ë‹µ/ë‹¤ì¤‘ì‘ë‹µ/ìˆœìœ„í˜•):
    - í•œ ì‘ë‹µìê°€ ì—¬ëŸ¬ í•­ëª©ì„ ì„ íƒí•˜ê±°ë‚˜, ì—¬ëŸ¬ ìˆœìœ„ë¥¼ ë™ì‹œì— ì‘ë‹µí•˜ëŠ” ê²½ìš°
        - !!!ì£¼ì˜!!! ë¬¸í•­ì— "1ìˆœìœ„"ë§Œ ìˆëŠ” ê²½ìš°ëŠ” manualì´ ì•„ë‹˜ (ft_testì™€ chi_square ì¤‘ í•˜ë‚˜ë¡œ ê²°ì •)
    - ì˜ˆì‹œ: "ë³µìˆ˜ì‘ë‹µ", "ë‹¤ì¤‘ì‘ë‹µ", "1+2ìˆœìœ„", "1+2+3ìˆœìœ„", "ranking", "ìš°ì„ ìˆœìœ„(1+2)", "ë‹¤ì¤‘ì„ íƒ", "ëª¨ë‘ì„ íƒ"
    - ë¬¸í•­ì— "ë³µìˆ˜", "ë‹¤ì¤‘", "multiple", "ranking" ë“±ì´ í¬í•¨ëœ ê²½ìš°

2ï¸âƒ£ **ft_test** (ì—°ì†í˜• ìˆ˜ì¹˜ ì‘ë‹µ):
    - ë¬¸í•­ì´ 1~5ì  ì²™ë„, í‰ê· , ë¹„ìœ¨, ì ìˆ˜ ë“± ìˆ«ì ê¸°ë°˜ìœ¼ë¡œ ìš”ì•½ë˜ì–´ ìˆëŠ” ê²½ìš°
    - ì˜ˆì‹œ ì—´ ì´ë¦„: "í‰ê· ", "ë§Œì¡±ë„ ì ìˆ˜", "~% ë¹„ìœ¨", "5ì  ì²™ë„", "í‰ê·  ì ìˆ˜", "ê´€ì‹¬ë„ í‰ê· "
    - "ì „í˜€ ê´€ì‹¬ì´ ì—†ë‹¤", "ë§¤ìš° ê´€ì‹¬ ìˆë‹¤" ë“±ì€ ì‹¤ì œë¡œëŠ” ì„ íƒì§€ì´ì§€ë§Œ, ë¹ˆë„ë‚˜ ë¹„ìœ¨ë¡œ ìˆ˜ì¹˜í™”ë˜ì—ˆì„ ê²½ìš° â†’ ì—°ì†í˜•ìœ¼ë¡œ íŒë‹¨
    - í…Œì´ë¸”ì´ ì „ì²´ì ìœ¼ë¡œ í‰ê· ê°’ ë˜ëŠ” %ë¹„ìœ¨ ì¤‘ì‹¬ì´ë©´ ft_test ì„ íƒì´ ë” ì ì ˆ

3ï¸âƒ£ **chi_square** (ë²”ì£¼í˜• ì„ íƒ ì‘ë‹µ):
    - ë¬¸í•­ì´ ì‘ë‹µìë“¤ì´ íŠ¹ì • í•­ëª©ì„ **ì„ íƒ**í•˜ê±°ë‚˜ **ë‹¤ì¤‘ì„ íƒ**í•œ ê²°ê³¼ì¼ ê²½ìš°
    - ì˜ˆì‹œ ì—´ ì´ë¦„: "ì£¼ìš” ì´ìš©ì‹œì„¤", "ì„ íƒ ì´ìœ ", "ê°€ì¥ ë§ì´ ì„ íƒí•œ ì¥ì†Œ", "ë‹¤ì¤‘ ì‘ë‹µ"
    - ë‹¨ì¼ ì„ íƒ ë¬¸í•­ (í•œ ëª…ì´ í•œ í•­ëª©ë§Œ ì„ íƒí•˜ëŠ” ê²½ìš°)

â— **ì˜¤íŒ ì£¼ì˜ì‚¬í•­**:
- ì‘ë‹µ ì„ íƒì§€ ì´ë¦„(ì˜ˆ: "ì „í˜€ ê´€ì‹¬ ì—†ë‹¤", "ë§¤ìš° ê´€ì‹¬ ìˆë‹¤")ê°€ ì—´ ì´ë¦„ì— í¬í•¨ë˜ë”ë¼ë„, **ë¹„ìœ¨, í‰ê·  ë“±ì˜ ìˆ˜ì¹˜í˜• ìš”ì•½**ì´ë©´ `ft_test`ë¡œ ê°„ì£¼
- í…Œì´ë¸”ì´ ì „ì²´ì ìœ¼ë¡œ í‰ê· ê°’ ë˜ëŠ” %ë¹„ìœ¨ ì¤‘ì‹¬ì´ë©´ `ft_test` ì„ íƒì´ ë” ì ì ˆ
- ë¬¸í•­ì— "1ìˆœìœ„"ë§Œ ìˆëŠ” ê²½ìš°ëŠ” ë³µìˆ˜ì‘ë‹µì´ ì•„ë‹ˆê¸° ë•Œë¬¸ì— manualì´ ì•„ë‹˜ (ft_testì™€ chi_square ì¤‘ í•˜ë‚˜ë¡œ ê²°ì •)
- "1+2ìˆœìœ„", "1+2+3ìˆœìœ„" ë“± ë³µìˆ˜ ìˆœìœ„ë§Œ ë³µìˆ˜ì‘ë‹µìœ¼ë¡œ manualë¡œ ë¶„ë¥˜

---

ì•„ë˜ ì¤‘ í•˜ë‚˜ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”(ì„¤ëª… ì—†ì´):
- manual
- ft_test  
- chi_square
"""
            prompt = TEST_TYPE_PROMPT.format(
                question_text=question_text,
                column_names=column_names_str
            )
            messages = [
                {"role": "system", "content": "ë‹¹ì‹ ì€ í†µê³„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ]
            llm_result = await self.openai_client.call(messages)
            llm_output = llm_result.strip().lower()
            if "manual" in llm_output:
                state.test_type = "manual"
            elif "chi" in llm_output:
                state.test_type = "chi_square"
            elif "ft" in llm_output:
                state.test_type = "ft_test"
            else:
                state.test_type = "unknown"
        return state
    
    async def run_statistical_analysis(self, state: AgentState, on_step=None) -> AgentState:
        """í†µê³„ ë¶„ì„ ì‹¤í–‰ ë…¸ë“œ"""
        if on_step:
            on_step("âœ… F/T ë¶„ì„ ë…¸ë“œ ì‹œì‘")
        try:
            from io import BytesIO
            use_statistical_test = getattr(state, 'use_statistical_test', True)
            
            if use_statistical_test and hasattr(state, 'raw_data_file') and state.raw_data_file is not None:
                # í†µê³„ ê²€ì • ì‚¬ìš© ì‹œ: Raw Dataë¥¼ ì‚¬ìš©í•œ í†µê³„ ë¶„ì„
                print("[ft_analysis_node] raw_data_file exists - í†µê³„ ê²€ì • ì‚¬ìš©")
                raw_data_file = BytesIO(state.raw_data_file) if isinstance(state.raw_data_file, (bytes, bytearray)) else state.raw_data_file
                raw_data = pd.read_excel(raw_data_file, sheet_name="DATA")
                demo_df = pd.read_excel(raw_data_file, sheet_name="DEMO")
                print(f"[ft_analysis_node] raw_data.columns: {raw_data.columns.tolist()}")
                print(f"[ft_analysis_node] demo_df.columns: {demo_df.columns.tolist()}")
                raw_data.columns = [col.replace("-", "_").strip() for col in raw_data.columns]
                demo_mapping = self.statistical_tester.extract_demo_mapping_from_dataframe(demo_df)
                print(f"[ft_analysis_node] demo_mapping: {demo_mapping}")
                test_type = getattr(state, 'test_type', None)
                question_key = getattr(state, 'selected_key', None)
                lang = getattr(state, 'lang', "í•œêµ­ì–´")
                print(f"[ft_analysis_node] test_type: {test_type}, question_key: {question_key}, lang: {lang}")
                if not isinstance(test_type, str) or not test_type:
                    raise ValueError("test_typeì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                if not isinstance(question_key, str) or not question_key:
                    raise ValueError("question_keyê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                result_df = self.statistical_tester.run_statistical_tests(test_type, raw_data, question_key, demo_mapping)
                print(f"[ft_analysis_node] result_df shape: {result_df.shape}")
                print(f"[ft_analysis_node] result_df: {result_df}")
                # Ensure result_df is always a DataFrame
                if not isinstance(result_df, pd.DataFrame):
                    print(f"[ft_analysis_node] result_df is not DataFrame, converting to empty DataFrame")
                    result_df = pd.DataFrame([])
                summary_text = self.statistical_tester.summarize_ft_test(result_df, lang=lang)
                state.raw_data = raw_data
                state.ft_test_result = result_df
                state.ft_test_summary = summary_text
            else:
                # í†µê³„ ê²€ì • ë¯¸ì‚¬ìš© ì‹œ: í†µê³„í‘œë§Œì„ ì‚¬ìš©í•œ manual í†µê³„ ë¶„ì„
                print("[ft_analysis_node] í†µê³„ ê²€ì • ë¯¸ì‚¬ìš© - í†µê³„í‘œë§Œìœ¼ë¡œ manual ë¶„ì„")
                selected_table = getattr(state, 'selected_table', None)
                if selected_table is not None and isinstance(selected_table, pd.DataFrame):
                    # í†µê³„í‘œì—ì„œ manual ë°©ì‹ìœ¼ë¡œ ìœ ì˜ì„± ìˆëŠ” ëŒ€ë¶„ë¥˜ ì¶”ì¶œ
                    result_df = self.run_manual_analysis_from_table(selected_table)
                    summary_text = self.summarize_manual_analysis(result_df, lang=getattr(state, 'lang', "í•œêµ­ì–´"))
                    state.ft_test_result = result_df
                    state.ft_test_summary = summary_text
                else:
                    print("[ft_analysis_node] selected_tableì´ ì—†ìŠµë‹ˆë‹¤.")
                    state.ft_error = "ë¶„ì„í•  í…Œì´ë¸”ì´ ì—†ìŠµë‹ˆë‹¤."
                    state.ft_test_result = pd.DataFrame([])
                    state.ft_test_summary = "í†µê³„ ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
        except Exception as e:
            print(f"[ft_analysis_node] Exception: {e}")
            state.ft_error = str(e)
            # Set empty DataFrame on error
            state.ft_test_result = pd.DataFrame([])
            state.ft_test_summary = "í†µê³„ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        return state
    
    async def extract_anchor(self, state: AgentState, on_step=None) -> AgentState:
        """ì•µì»¤ ì¶”ì¶œ ë…¸ë“œ"""
        if on_step:
            on_step("ğŸ“Œ ì•µì»¤ ì¶”ì¶œ ë…¸ë“œ ì‹œì‘")
        
        selected_table = getattr(state, 'selected_table', None)
        lang = getattr(state, 'lang', 'í•œêµ­ì–´')
        anchor = []
        
        if selected_table is not None and isinstance(selected_table, pd.DataFrame):
            exclude_cols = set([
                "ëŒ€ë¶„ë¥˜", "ì†Œë¶„ë¥˜", "ì‚¬ë¡€ìˆ˜",
                "ëŒ€ë¶„ë¥˜_ì†Œë¶„ë¥˜"
            ])
            
            def is_anchor_candidate(col):
                col_str = str(col).strip()
                if col_str in exclude_cols:
                    return False
                # %ë¡œ ëë‚˜ëŠ” ì»¬ëŸ¼ ì œì™¸ (ê³µë°± í¬í•¨)
                if col_str.rstrip().endswith('%'):
                    return False
                # í‰ê· , í•©ê³„, std, score ë“± í¬í•¨ì‹œ ì œì™¸
                if any(keyword in col_str for keyword in ['í‰ê· ', 'í•©ê³„', 'std', 'score']):
                    return False
                return True
            
            # "ì „ ì²´" ë˜ëŠ” "ì „ì²´" row ì°¾ê¸° (ê³µë°± ì œê±°)
            total_row = selected_table[selected_table["ëŒ€ë¶„ë¥˜"].astype(str).str.strip().str.replace(" ", "") == "ì „ì²´"]
            if total_row.empty:
                state.anchor = []
                state.ft_error = "âŒ 'ì „ ì²´' ë˜ëŠ” 'ì „ì²´'ì— í•´ë‹¹í•˜ëŠ” í–‰ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
                return state
            
            total_row = total_row.iloc[0]
            candidate_cols = [col for col in selected_table.columns if is_anchor_candidate(col)]
            values = total_row[candidate_cols]
            values_numeric = pd.to_numeric(values, errors='coerce')
            high_value_cols = values_numeric.dropna().sort_values(ascending=False)
            cumulative_sum = 0
            selected_cols = []
            for col, val in high_value_cols.items():
                cumulative_sum += val
                selected_cols.append(col)
                if cumulative_sum >= 60:
                    break
            anchor = selected_cols
        
        state.anchor = anchor
        return state
    
    async def analyze_table(self, state: AgentState, on_step=None) -> AgentState:
        """í…Œì´ë¸” ë¶„ì„ ë…¸ë“œ"""
        if on_step:
            on_step("ğŸ¤– í…Œì´ë¸” ë¶„ì„ ë…¸ë“œ ì‹œì‘")
        
        lang = getattr(state, 'lang', 'í•œêµ­ì–´')
        linearized_table = getattr(state, 'linearized_table', '')
        ft_test_summary = getattr(state, 'ft_test_summary', '')
        selected_question = getattr(state, 'selected_question', '')
        anchor = getattr(state, 'anchor', 'ì—†ìŒ')
        
        prompt = self.TABLE_ANALYSIS_PROMPT[lang].format(
            selected_question=selected_question,
            linearized_table=linearized_table,
            ft_test_summary=str(ft_test_summary),
            anchor=anchor
        )
        
        messages = [
            {"role": "system", "content": "ë‹¹ì‹ ì€ í†µê³„ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤." if lang == "í•œêµ­ì–´" else "You are a statistical analysis expert."},
            {"role": "user", "content": prompt}
        ]
        
        state.table_analysis = await self.openai_client.call(messages)
        return state
    
    async def check_hallucination(self, state: AgentState, on_step=None) -> AgentState:
        """í™˜ê° ê²€ì¦ ë…¸ë“œ"""
        if on_step:
            on_step("ğŸ§  í™˜ê° í‰ê°€ ë…¸ë“œ ì‹œì‘")
        
        lang = getattr(state, 'lang', 'í•œêµ­ì–´')
        hallucination_reject_num = getattr(state, 'hallucination_reject_num', 0)
        
        # ìˆ˜ì • ì´ë ¥ì´ ìˆìœ¼ë©´ ë§ˆì§€ë§‰ ìˆ˜ì •ë³¸ ì‚¬ìš©
        if hasattr(state, 'revised_analysis_history') and state.revised_analysis_history:
            table_analysis = state.revised_analysis_history[-1]
        else:
            table_analysis = getattr(state, 'table_analysis', '')
        
        prompt = self.HALLUCINATION_CHECK_PROMPT[lang].format(
            selected_question=getattr(state, 'selected_question', ''),
            linearized_table=getattr(state, 'linearized_table', ''),
            ft_test_summary=str(getattr(state, 'ft_test_summary', '')),
            table_analysis=table_analysis
        )
        
        messages = [
            {"role": "system", "content": "ë‹¹ì‹ ì€ í†µê³„ í•´ì„ ê²°ê³¼ë¥¼ ê²€ì¦í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤." if lang == "í•œêµ­ì–´" else "You are a statistical analysis auditor."},
            {"role": "user", "content": prompt}
        ]
        
        result = await self.openai_client.call(messages)
        result_str = result.strip() if hasattr(result, 'strip') else str(result)
        
        if result_str.lower().startswith("reject"):
            decision = "reject"
            feedback = result_str[len("reject"):].strip(": ").strip()
            hallucination_reject_num += 1
            if hasattr(state, 'revised_analysis_history'):
                state.revised_analysis_history.append(table_analysis)
            else:
                state.revised_analysis_history = [table_analysis]
        else:
            decision = "accept"
            feedback = ""
        
        state.hallucination_check = decision
        state.feedback = feedback
        state.hallucination_reject_num = hallucination_reject_num
        return state
    
    async def revise_analysis(self, state: AgentState, on_step=None) -> AgentState:
        """ë¶„ì„ ìˆ˜ì • ë…¸ë“œ"""
        if on_step:
            on_step("âœï¸ ë¶„ì„ ìˆ˜ì • ë…¸ë“œ ì‹œì‘")
        
        lang = getattr(state, 'lang', 'í•œêµ­ì–´')
        
        # report_to_modifyëŠ” revised_historyê°€ ìˆìœ¼ë©´ ë§ˆì§€ë§‰ ê²ƒì„, ì—†ìœ¼ë©´ ì´ˆì•ˆì„ fallback
        report_to_modify = state.revised_analysis_history[-1] if getattr(state, 'revised_analysis_history', None) else getattr(state, 'table_analysis', '')
        
        prompt = self.REVISION_PROMPT[lang].format(
            linearized_table=getattr(state, 'linearized_table', ''),
            ft_test_summary=str(getattr(state, 'ft_test_summary', '')),
            anchor=getattr(state, 'anchor', ''),
            report_to_modify=report_to_modify,
            feedback=getattr(state, 'feedback', '')
        )
        
        messages = [
            {"role": "system", "content": "ë‹¹ì‹ ì€ í†µê³„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¸êµ¬ì§‘ë‹¨ ê°„ íŒ¨í„´ê³¼ ê²½í–¥ì„±ì„ ê°ê´€ì ìœ¼ë¡œ ìš”ì•½í•˜ëŠ” ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤." if lang == "í•œêµ­ì–´" else "You are a data analyst who objectively summarizes population-level patterns based on statistical data."},
            {"role": "user", "content": prompt}
        ]
        
        result = await self.openai_client.call(messages)
        new_revised_analysis = result.strip() if hasattr(result, 'strip') else str(result)
        
        # Append to revision history
        if hasattr(state, 'revised_analysis_history') and state.revised_analysis_history:
            revision_history = state.revised_analysis_history
        else:
            revision_history = []
        revision_history.append(new_revised_analysis)
        state.revised_analysis = new_revised_analysis
        state.revised_analysis_history = revision_history
        return state
    
    async def polish_sentence(self, state: AgentState, on_step=None) -> AgentState:
        """ë¬¸ì¥ ë‹¤ë“¬ê¸° ë…¸ë“œ"""
        if on_step:
            on_step("ğŸ’… ë¬¸ì¥ ë‹¤ë“¬ê¸° ë…¸ë“œ ì‹œì‘")
        
        lang = getattr(state, 'lang', 'í•œêµ­ì–´')
        hallucination_reject_num = getattr(state, 'hallucination_reject_num', 0)
        raw_summary = state.revised_analysis if hallucination_reject_num > 0 else state.table_analysis
        
        prompt = self.POLISHING_PROMPT[lang].format(raw_summary=raw_summary)
        
        messages = [
            {"role": "system", "content": "ë‹¹ì‹ ì€ í†µê³„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‘ì„±ëœ í•œêµ­ì–´ ë³´ê³ ì„œë¥¼ ë‹¤ë“¬ëŠ” ë¬¸ì²´ ì „ë¬¸ ì—ë””í„°ì…ë‹ˆë‹¤." if lang == "í•œêµ­ì–´" else "You are a stylistic editor for statistical summaries written in Korean."},
            {"role": "user", "content": prompt}
        ]
        
        result = await self.openai_client.call(messages)
        polishing_result = result.strip() if hasattr(result, 'strip') else str(result)
        state.polishing_result = polishing_result
        return state 

    async def decide_batch_test_types(self, question_infos: list, lang: str = "í•œêµ­ì–´") -> dict:
        """ë°°ì¹˜ ë¶„ì„ìš©: ì—¬ëŸ¬ ì§ˆë¬¸ì— ëŒ€í•´ í†µê³„ ê²€ì • ë°©ë²•ì„ ì¼ê´„ ê²°ì •"""
        try:
            # 1. manual íŒì • (ë³µìˆ˜ì‘ë‹µ/ìˆœìœ„/ë‹¤ì¤‘ ë“± í‚¤ì›Œë“œ)
            manual_keys = set()
            non_manual_questions = []
            for q in question_infos:
                key, text, columns = q['key'], q['text'], q['columns']
                if self.rule_based_test_type_decision(text) == 'manual':
                    manual_keys.add(key)
                else:
                    non_manual_questions.append(q)
            
            # 2. LLM í”„ë¡¬í”„íŠ¸ ìƒì„± (ë³µìˆ˜ì‘ë‹µ ì•„ë‹Œ ì§ˆë¬¸ë“¤)
            prompt_lines = []
            for q in non_manual_questions:
                col_str = ', '.join(q['columns'])
                prompt_lines.append(f"{q['key']}: {col_str}")
            prompt_body = '\n'.join(prompt_lines)
            
            if lang == "í•œêµ­ì–´":
                prompt = f"""
                ì•„ë˜ëŠ” ì„¤ë¬¸ í†µê³„í‘œì˜ ê° ì§ˆë¬¸ë³„ ì—´ ì´ë¦„ ëª©ë¡ì…ë‹ˆë‹¤.
                
                ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” ê° ì§ˆë¬¸ì— ëŒ€í•´ **ê°€ì¥ ì í•©í•œ í†µê³„ ê²€ì • ë°©ë²•**(ft_test ë˜ëŠ” chi_square)ì„ ê²°ì •í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.
                
                - ft_test: í‰ê· , ì ìˆ˜, ë¹„ìœ¨ ë“± ì—°ì†í˜•(ìˆ˜ì¹˜í˜•) ë°ì´í„°ì— ì í•©
                - chi_square: í•­ëª© ì„ íƒ, ë‹¤ì¤‘ì‘ë‹µ ë“± ë²”ì£¼í˜•(ì„ íƒí˜•) ë°ì´í„°ì— ì í•©
                
                ì•„ë˜ ê¸°ì¤€ì„ ì°¸ê³ í•˜ì„¸ìš”:
                - ì—´ ì´ë¦„ì— 'í‰ê· ', 'ì ìˆ˜', '%', 'ë¹„ìœ¨' ë“±ì´ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ft_test
                - í•­ëª© ì„ íƒ, ë‹¤ì¤‘ì‘ë‹µ, ë²”ì£¼í˜• ì„ íƒì§€ë©´ chi_square
                
                ì•„ë˜ì™€ ê°™ì€ í˜•ì‹ìœ¼ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”(ì„¤ëª… ì—†ì´):
                
                ì˜ˆì‹œ:
                Q1: ft_test
                Q2: chi_square
                Q3: ft_test
                
                ì§ˆë¬¸ë³„ ì—´ ëª©ë¡:
                {prompt_body}
                
                ë‹µë³€ í˜•ì‹:
                Q1: ft_test
                Q2: chi_square
                ...
                """
            else:
                prompt = f"""
                Below are the column headers for each survey question.
            
                Your task is to determine the **most appropriate statistical test type** (ft_test or chi_square) for each question.
                
                - ft_test: Use for continuous/numeric data (mean, score, %, ratio, etc.)
                - chi_square: Use for categorical/choice/multiple response data
                
                Guidelines:
                - If column names include 'mean', 'score', '%', 'ratio', etc. â†’ ft_test
                - If the question is about selecting items, multiple responses, or categorical choices â†’ chi_square
                - If the question is multiple response/ranking, use 'manual' (already auto-classified)
                
                Please answer in the following format (no explanation):
                
                Example:
                Q1: ft_test
                Q2: chi_square
                Q3: ft_test
                
                Question columns:
                {prompt_body}
                
                Answer format:
                Q1: ft_test
                Q2: chi_square
                ...
                """
            
            # 3. LLM í˜¸ì¶œ (ì—†ìœ¼ë©´ ëª¨ë‘ ft_test)
            llm_result = None
            if non_manual_questions:
                messages = [
                    {"role": "system", "content": "ë‹¹ì‹ ì€ í†µê³„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤." if lang == "í•œêµ­ì–´" else "You are a statistics expert."},
                    {"role": "user", "content": prompt}
                ]
                try:
                    llm_result = await self.openai_client.call(messages)
                except Exception as e:
                    print(f"[decide_batch_test_types] LLM í˜¸ì¶œ ì‹¤íŒ¨: {e}")
                    # fallback: ëª¨ë‘ ft_test
                    llm_result = '\n'.join([f"{q['key']}: ft_test" for q in non_manual_questions])
            
            # 4. LLM ì‘ë‹µ íŒŒì‹±
            test_type_map = {key: 'manual' for key in manual_keys}
            if llm_result:
                import re
                for line in llm_result.splitlines():
                    m = re.match(r"([\w\-]+):\s*(ft_test|chi_square)", line.strip(), re.I)
                    if m:
                        key, ttype = m.group(1), m.group(2).lower()
                        test_type_map[key] = ttype
            
            # 5. ëˆ„ë½ëœ ì§ˆë¬¸ì€ ê¸°ë³¸ê°’(ft_test)
            for q in question_infos:
                if q['key'] not in test_type_map:
                    test_type_map[q['key']] = 'ft_test'
            
            return test_type_map
        except Exception as e:
            print(f"[decide_batch_test_types] ì˜¤ë¥˜: {e}")
            # fallback: ëª¨ë“  ì§ˆë¬¸ì„ ft_testë¡œ ì„¤ì •
            return {q["key"]: "ft_test" for q in question_infos}

    def rule_based_test_type_decision(self, question_text=""):
        """ì§ˆë¬¸ í…ìŠ¤íŠ¸ì— ë³µìˆ˜ì‘ë‹µ/ìˆœìœ„/ë‹¤ì¤‘ ë“± í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ manual, ì•„ë‹ˆë©´ None"""
        multi_response_keywords = [
            "1+2", "1+2+3", "ë³µìˆ˜", "ë‹¤ì¤‘", "multiple", "rank", "ranking", "ìš°ì„ ìˆœìœ„", "ë³µìˆ˜ì‘ë‹µ", "ìˆœìœ„"
        ]
        text_to_check = question_text.lower()
        if any(keyword.lower() in text_to_check for keyword in multi_response_keywords):
            return "manual"
        return None

    def run_manual_analysis_from_table(self, table: pd.DataFrame) -> pd.DataFrame:
        """í†µê³„í‘œë§Œì„ ì‚¬ìš©í•˜ì—¬ manual ë°©ì‹ìœ¼ë¡œ ìœ ì˜ì„± ìˆëŠ” ëŒ€ë¶„ë¥˜ ì¶”ì¶œ (ì‹ ë¢°êµ¬ê°„ ê¸°ë°˜)"""
        try:
            if table is None or table.empty:
                return pd.DataFrame([])
            
            # "ëŒ€ë¶„ë¥˜" ì»¬ëŸ¼ì´ ìˆëŠ”ì§€ í™•ì¸
            if "ëŒ€ë¶„ë¥˜" not in table.columns:
                return pd.DataFrame([])
            
            # "ì „ì²´" í–‰ ì°¾ê¸°
            overall_row = table[table["ëŒ€ë¶„ë¥˜"].astype(str).str.strip().str.replace(" ", "") == "ì „ì²´"]
            if overall_row.empty:
                print("[run_manual_analysis_from_table] 'ì „ì²´' í–‰ì´ ì—†ìŠµë‹ˆë‹¤.")
                return pd.DataFrame([])
            overall_n = overall_row["ì‚¬ë¡€ìˆ˜"]
            
            # ìˆ«ì ì»¬ëŸ¼ë§Œ ì„ íƒ (ëŒ€ë¶„ë¥˜, ì†Œë¶„ë¥˜, ì‚¬ë¡€ìˆ˜ ì œì™¸)
            exclude_cols = ["ëŒ€ë¶„ë¥˜", "ì†Œë¶„ë¥˜", "ì‚¬ë¡€ìˆ˜"]
            numeric_cols = []
            
            for col in table.columns:
                if col in exclude_cols:
                    continue
                try:
                    # ì»¬ëŸ¼ì´ ë¬¸ìì—´ì¸ì§€ í™•ì¸
                    if table[col].dtype == 'object':
                        # ë¬¸ìì—´ì„ ìˆ«ìë¡œ ë³€í™˜ ì‹œë„
                        numeric_data = pd.to_numeric(table[col], errors='coerce')
                        # NaNì´ ì•„ë‹Œ ê°’ì´ ìˆìœ¼ë©´ ìˆ«ì ì»¬ëŸ¼ìœ¼ë¡œ ê°„ì£¼
                        if not numeric_data.isna().all():
                            numeric_cols.append(col)
                    else:
                        # ì´ë¯¸ ìˆ«ì íƒ€ì…ì´ë©´ ì¶”ê°€
                        numeric_cols.append(col)
                except Exception as e:
                    print(f"[run_manual_analysis_from_table] ì»¬ëŸ¼ {col} ê²€ì‚¬ ì¤‘ ì˜¤ë¥˜: {e}")
                    continue
            
            if not numeric_cols:
                print("[run_manual_analysis_from_table] ìˆ«ì ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                return pd.DataFrame([])
            
            print(f"[run_manual_analysis_from_table] ë¶„ì„í•  ìˆ«ì ì»¬ëŸ¼: {numeric_cols}")
            
            results = []
            for col in numeric_cols:
                try:
                    # ìˆ«ìë¡œ ë³€í™˜
                    if table[col].dtype == 'object':
                        numeric_data = pd.to_numeric(table[col], errors='coerce')
                    else:
                        numeric_data = table[col]
                    
                    # ì „ì²´ ê¸°ì¤€ê°’ ê³„ì‚°
                    overall_mask = table["ëŒ€ë¶„ë¥˜"].astype(str).str.strip().str.replace(" ", "") == "ì „ì²´"
                    overall_values = numeric_data[overall_mask]
                    
                    if overall_values.empty or overall_values.isna().all():
                        print(f"[run_manual_analysis_from_table] ì»¬ëŸ¼ {col}ì˜ ì „ì²´ ê°’ì´ ì—†ìŠµë‹ˆë‹¤.")
                        continue
                    
                    overall_value = overall_values.iloc[0]
                    if pd.isna(overall_value):
                        continue
                    
                    # ì‚¬ë¡€ìˆ˜ ê³„ì‚° (ê¸°ë³¸ê°’ 100)
                    if "ì‚¬ë¡€ìˆ˜" in table.columns:
                        try:
                            if table["ì‚¬ë¡€ìˆ˜"].dtype == 'object':
                                case_data = pd.to_numeric(table["ì‚¬ë¡€ìˆ˜"], errors='coerce')
                            else:
                                case_data = table["ì‚¬ë¡€ìˆ˜"]
                            overall_n = case_data[overall_mask].iloc[0]
                            if pd.isna(overall_n) or overall_n <= 0:
                                overall_n = 100
                        except Exception as e:
                            print(f"[run_manual_analysis_from_table] ì‚¬ë¡€ìˆ˜ ê³„ì‚° ì˜¤ë¥˜: {e}")
                            overall_n = 100
                    
                    # í‘œì¤€ì˜¤ì°¨ ê³„ì‚°
                    overall_std = numeric_data.std()
                    if overall_std == 0 or pd.isna(overall_std):
                        continue
                    
                    std_error = overall_std / np.sqrt(overall_n)
                    z_score = 1.96
                    ci_lower = overall_value - z_score * std_error
                    ci_upper = overall_value + z_score * std_error
                    
                    # ê° ëŒ€ë¶„ë¥˜ë³„ ë¶„ì„
                    for idx, row in table.iterrows():
                        if str(row["ëŒ€ë¶„ë¥˜"]).strip().replace(" ", "") == "ì „ì²´":
                            continue
                        
                        group_value = numeric_data.iloc[idx]
                        if pd.isna(group_value):
                            continue
                        
                        # ê·¸ë£¹ ë¼ë²¨ ìƒì„±
                        if "ì†Œë¶„ë¥˜" in table.columns and pd.notna(row['ì†Œë¶„ë¥˜']):
                            group_label = f"{row['ëŒ€ë¶„ë¥˜']} - {row['ì†Œë¶„ë¥˜']}"
                        else:
                            group_label = row['ëŒ€ë¶„ë¥˜']
                        
                        # ì‹ ë¢°êµ¬ê°„ ê¸°ë°˜ ìœ ì˜ì„± íŒë‹¨
                        significant = group_value < ci_lower or group_value > ci_upper
                        
                        results.append({
                            "ëŒ€ë¶„ë¥˜": group_label,
                            "í‰ê· ê°’": round(group_value, 3),
                            "ìœ ì˜ë¯¸ ì—¬ë¶€": "ìœ ì˜ë¯¸í•¨" if significant else "ë¬´ì˜ë¯¸í•¨",
                            "ê¸°ì¤€ í‰ê· ": round(overall_value, 3),
                            "ì‹ ë¢°êµ¬ê°„": f"{round(ci_lower, 1)} ~ {round(ci_upper, 1)}",
                            "ìœ ì˜ì„±": "*" if significant else ""
                        })
                        
                except Exception as e:
                    print(f"[run_manual_analysis_from_table] ì»¬ëŸ¼ {col} ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
                    continue
            
            return pd.DataFrame(results)
            
        except Exception as e:
            print(f"[run_manual_analysis_from_table] ì˜¤ë¥˜: {e}")
            return pd.DataFrame([])

    def summarize_manual_analysis(self, result_df: pd.DataFrame, lang: str = "í•œêµ­ì–´") -> str:
        """
        Manual ë¶„ì„ ê²°ê³¼ë¥¼ ìì—°ì–´ë¡œ ìš”ì•½
        - ìœ ì˜ì„±(ë³„í‘œ)ì´ ìˆëŠ” í•­ëª©ë§Œ ì¶”ë¦¼
        - ëª¨ë‘ ìœ ì˜í•˜ë©´ ì „ì²´ ìœ ì˜, ì¼ë¶€ë§Œ ìœ ì˜í•˜ë©´ í•´ë‹¹ ê·¸ë£¹ ë‚˜ì—´
        - ìœ ì˜í•œ í•­ëª©ì´ ì—†ìœ¼ë©´ í‰ê·  ì°¨ì´ ìƒìœ„ 3ê°œ ì–¸ê¸‰
        """
        if result_df is None or result_df.empty:
            return "ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤." if lang == "í•œêµ­ì–´" else "No analysis result."
        significant = result_df[result_df["ìœ ì˜ì„±"] != ""]
        summary = []
        if not significant.empty:
            sig_items = significant["ëŒ€ë¶„ë¥˜"].tolist()
            if len(sig_items) == len(result_df):
                summary.append(
                    "ëª¨ë“  í•­ëª©ì—ì„œ ì „ì²´ í‰ê· ê³¼ ìœ ì˜ë¯¸í•œ ì°¨ì´ê°€ ê´€ì°°ë˜ì—ˆìŒ. ëŒ€ë¶„ë¥˜ ì „ë°˜ì— ê±¸ì³ ì˜ë¯¸ ìˆëŠ” ì°¨ì´ê°€ ì¡´ì¬í•¨."
                    if lang == "í•œêµ­ì–´" else
                    "All categories showed significant differences from the overall mean. Broad variation was observed across major groups."
                )
            else:
                summary.append(
                    f"{', '.join(sig_items)}ëŠ” ì „ì²´ í‰ê· ê³¼ ìœ ì˜ë¯¸í•œ ì°¨ì´ë¥¼ ë³´ì˜€ìŒ."
                    if lang == "í•œêµ­ì–´" else
                    f"{', '.join(sig_items)} showed significant differences from the overall mean."
                )
        else:
            # ìœ ì˜í•œ í•­ëª©ì´ ì „í˜€ ì—†ì„ ê²½ìš° â†’ í‰ê·  ì°¨ì´ ìƒìœ„ 3ê°œ ì–¸ê¸‰
            if not result_df.empty and "í‰ê· ê°’" in result_df.columns and "ê¸°ì¤€ í‰ê· " in result_df.columns:
                result_df["í‰ê· ì°¨ì´"] = (result_df["í‰ê· ê°’"] - result_df["ê¸°ì¤€ í‰ê· "]).abs()
                top3 = result_df.nlargest(3, "í‰ê· ì°¨ì´")[["ëŒ€ë¶„ë¥˜", "í‰ê· ê°’", "ê¸°ì¤€ í‰ê· "]]
                top3_text = ", ".join(f"{row['ëŒ€ë¶„ë¥˜']} (í‰ê· : {row['í‰ê· ê°’']}, ì „ì²´: {row['ê¸°ì¤€ í‰ê· ']})" for _, row in top3.iterrows())
                summary.append(
                    f"ìœ ì˜ë¯¸í•œ ì°¨ì´ëŠ” ì—†ì—ˆì§€ë§Œ, í‰ê·  ì°¨ì´ê°€ í° í•­ëª©ì€ {top3_text} ìˆœì´ì—ˆìŒ."
                    if lang == "í•œêµ­ì–´" else
                    f"No significant differences, but the largest mean differences were: {top3_text}."
                )
            else:
                summary.append("ìœ ì˜ë¯¸í•œ ì°¨ì´ê°€ ì—†ìŠµë‹ˆë‹¤." if lang == "í•œêµ­ì–´" else "No significant differences.")
        return "  ".join(summary)

    def summarize_ft_test(self, result_df, lang: str = "í•œêµ­ì–´") -> str:
        """
        ft_test/chi_square ê²°ê³¼ë¥¼ ìì—°ì–´ë¡œ ìš”ì•½
        - ìœ ì˜ì„±(ë³„í‘œ)ì´ ìˆëŠ” í•­ëª©ë§Œ ì¶”ë¦¼
        - ëª¨ë‘ ìœ ì˜í•˜ë©´ ì „ì²´ ìœ ì˜, ì¼ë¶€ë§Œ ìœ ì˜í•˜ë©´ í•´ë‹¹ ê·¸ë£¹ ë‚˜ì—´
        - ìœ ì˜í•œ í•­ëª©ì´ ì—†ìœ¼ë©´ p-value ìƒìœ„ 3ê°œ ì–¸ê¸‰
        """
        if result_df is None or result_df.empty:
            return "ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤." if lang == "í•œêµ­ì–´" else "No analysis result."
        significant = result_df[result_df["ìœ ì˜ì„±"] != ""]
        summary = []
        if not significant.empty:
            sig_items = significant["ëŒ€ë¶„ë¥˜"].tolist()
            if len(sig_items) == len(result_df):
                summary.append(
                    "ëª¨ë“  í•­ëª©ì—ì„œ í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ì°¨ì´ê°€ ê´€ì°°ë˜ì—ˆìŒ. ëŒ€ë¶„ë¥˜ ì „ë°˜ì— ê±¸ì³ ì˜ë¯¸ ìˆëŠ” ì°¨ì´ê°€ ì¡´ì¬í•¨."
                    if lang == "í•œêµ­ì–´" else
                    "All categories showed statistically significant differences. Broad variation was observed across major groups."
                )
            else:
                summary.append(
                    f"{', '.join(sig_items)}ëŠ” í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•œ ì°¨ì´ë¥¼ ë³´ì˜€ìŒ."
                    if lang == "í•œêµ­ì–´" else
                    f"{', '.join(sig_items)} showed statistically significant differences."
                )
        else:
            # ìœ ì˜í•œ í•­ëª©ì´ ì „í˜€ ì—†ì„ ê²½ìš° â†’ p-value ê¸°ì¤€ ìƒìœ„ 3ê°œ ì–¸ê¸‰
            if not result_df.empty and "p-value" in result_df.columns:
                top3 = result_df.nsmallest(3, "p-value")[["ëŒ€ë¶„ë¥˜", "p-value"]]
                top3_text = ", ".join(f"{row['ëŒ€ë¶„ë¥˜']} (p={row['p-value']:.3f})" for _, row in top3.iterrows())
                summary.append(
                    f"í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•œ í•­ëª©ì€ ì—†ì—ˆì§€ë§Œ, ìƒëŒ€ì ìœ¼ë¡œ p-valueê°€ ë‚®ì€ í•­ëª©ì€ {top3_text} ìˆœì´ì—ˆìŒ."
                    if lang == "í•œêµ­ì–´" else
                    f"No items reached statistical significance, but the ones with the lowest p-values were: {top3_text}."
                )
            else:
                summary.append("í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•œ í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤." if lang == "í•œêµ­ì–´" else "No statistically significant items.")
        return "  ".join(summary)

    # --- PROMPT DEFINITIONS ---
    TABLE_ANALYSIS_PROMPT = {
        "í•œêµ­ì–´": """
        ë‹¹ì‹ ì€ í†µê³„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¸êµ¬ì§‘ë‹¨ ê°„ ê²½í–¥ì„ ìš”ì•½í•˜ëŠ” ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
        íŠ¹íˆ ì•„ë˜ ë‘ ê°€ì§€ ì •ë³´ë¥¼ ì¢…í•©ì ìœ¼ë¡œ í™œìš©í•´ í•µì‹¬ì  ê²½í–¥ì„ ë„ì¶œí•´ì•¼ í•©ë‹ˆë‹¤:

        1ï¸âƒ£ **í†µê³„ ë¶„ì„ ê²°ê³¼(ft_test_summary)**: ì–´ë–¤ ëŒ€ë¶„ë¥˜(row)ê°€ í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ì°¨ì´ë¥¼ ë³´ì˜€ëŠ”ì§€ ì•Œë ¤ì¤ë‹ˆë‹¤.
        2ï¸âƒ£ **ì¤‘ìš” ë³€ìˆ˜(anchor)**: ì–´ë–¤ column(í•­ëª©)ì´ ì‘ë‹µìì˜ ì „ì²´ ì‘ë‹µì—ì„œ ê°€ì¥ íˆ¬í‘œìœ¨ì´ ë†’ì€ í•­ëª©ì¸ì§€ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.

        ---

        ğŸ“ ì„¤ë¬¸ ì¡°ì‚¬ ì§ˆë¬¸:
        {selected_question}

        ğŸ“Š í‘œ ë°ì´í„° (ì„ í˜•í™”ëœ í˜•íƒœ):
        {linearized_table}

        ğŸ“ˆ ì£¼ìš” í•­ëª© (ë³€ìˆ˜ë“¤ ì¤‘ ê°€ì¥ íˆ¬í‘œìœ¨ì´ ë†’ì€ ë³€ìˆ˜):
        {anchor}

        ğŸ“ˆ í†µê³„ ë¶„ì„ ê²°ê³¼ (í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ëŒ€ë¶„ë¥˜):
        {ft_test_summary}

        ---

        âš ï¸ ì°¸ê³ : ë§Œì•½ í†µê³„ ë¶„ì„ ê²°ê³¼ê°€ ì¡´ì¬í•˜ì§€ ì•Šê±°ë‚˜ ì‚¬ìš©ìê°€ ë¶„ì„ì„ ì§„í–‰í•˜ì§€ ì•Šê¸°ë¡œ ì„ íƒí•œ ê²½ìš°, ì£¼ìš” í•­ëª©(anchor)ì„ ì¤‘ì‹¬ìœ¼ë¡œ ê²½í–¥ì„ íŒŒì•…í•˜ê³  ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìš”ì•½í•  ê²ƒ.

        Let's think step by step.

        ğŸ¯ ë¶„ì„ ë° ìš”ì•½ ì§€ì¹¨:
        1. ë°˜ë“œì‹œ **F/T test ê²°ê³¼ì—ì„œ í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ëŒ€ë¶„ë¥˜ë§Œì„ ì¤‘ì‹¬ìœ¼ë¡œ ë¶„ì„**í•  ê²ƒ (p-value < 0.05, ìœ ì˜ì„± ë³„(*) ì¡´ì¬)
        2. ëª¨ë“  ëŒ€ë¶„ë¥˜ / ì†Œë¶„ë¥˜ë¥¼ ë‚˜ì—´í•˜ì§€ ë§ê³ , **í†µê³„ ë¶„ì„ ê²°ê³¼**ì—ì„œ ì°¨ì´ê°€ í¬ê³  ì˜ë¯¸ ìˆëŠ” ëŒ€ë¶„ë¥˜ë§Œ ì„ íƒì ìœ¼ë¡œ ì–¸ê¸‰í•  ê²ƒ
            - í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ëŒ€ë¶„ë¥˜ê°€ ì—†ì„ ê²½ìš° (ìœ ì˜ì„± ë³„(*)ê°€ ì—†ì„ ê²½ìš°) ì£¼ì–´ì§„ p-valueê°€ ì‘ì€ ëŒ€ë¶„ë¥˜ì—ì„œ ì£¼ìš” í•­ëª©ì— í¬í•¨ë˜ëŠ” ëŒ€ë¶„ë¥˜ë§Œ ì–¸ê¸‰í•  ê²ƒ
        3. **ì ˆëŒ€ í•´ì„í•˜ì§€ ë§ ê²ƒ**. ìˆ˜ì¹˜ì  ì°¨ì´ì— ëŒ€í•œ ì¸ê³¼ í•´ì„(ì˜ˆ: ê±´ê°•ì— ë¯¼ê°í•´ì„œ, ì£¼ë³€ì— ìˆì–´ì„œ ë“±)ì€ ëª¨ë‘ **ê¸ˆì§€**í•¨
        4. ì™¸ë¶€ ë°°ê²½ì§€ì‹, ì£¼ê´€ì  ì¶”ë¡ , í•´ì„ì  ì–¸ê¸‰ì€ ì ˆëŒ€ ê¸ˆì§€. í‘œë¡œë¶€í„° ì§ì ‘ **í™•ì¸ ê°€ëŠ¥í•œ ì‚¬ì‹¤ë§Œ ì„œìˆ **í•  ê²ƒ
        5. ìˆ˜ì¹˜ ê¸°ë°˜ ê²½í–¥ì„ ë‹¤ìŒê³¼ ê°™ì€ í˜•ì‹ìœ¼ë¡œ ì„œìˆ í•˜ë©° ìŒìŠ´ì²´ë¡œ ì‘ì„±í•  ê²ƒ (ì˜ˆ: ~í–ˆìŒ, ~ë¡œ ë‚˜íƒ€ë‚¬ìŒ):
        - ìƒëŒ€ì ìœ¼ë¡œ ë” ë†’ì€ ê²½í–¥ ë³´ì˜€ìŒ
        - ë‚®ì€ ê°’ì„ ë‚˜íƒ€ëƒˆìŒ
        6. ë¬¸ì¥ ê°„ ì—°ê²°ì–´ë¥¼ í™œìš©í•´ ìì—°ìŠ¤ëŸ½ê²Œ ì„œìˆ í•˜ê³ , ë„ˆë¬´ ë‹¨ì¡°ë¡­ê±°ë‚˜ ë°˜ë³µì ì¸ í‘œí˜„ (~í–ˆìŒ. ~í–ˆìŒ.)ì€ ì—°ì†ì ìœ¼ë¡œ ì‚¬ìš©í•˜ì§€ ë§ ê²ƒ
        7. **ìœ ì˜ì„±ì´ ì—†ê±°ë‚˜, ê²€ì •ì—ì„œ ì œì™¸ëœ í•­ëª©ì€ ì ˆëŒ€ ì–¸ê¸‰í•˜ì§€ ë§ ê²ƒ**
        8. ëª¨ë“  ëŒ€ë¶„ë¥˜ê°€ ìœ ì˜ì„±ì´ ìˆê³  ì¤‘ìš”í•˜ë‹¤ë©´ ëª¨ë“  ë³€ìˆ˜ì— ëŒ€í•´ ì„¤ëª…í•˜ì§€ ë§ê³ , **ëª¨ë“  ëŒ€ë¶„ë¥˜ë“¤ì´ ì¤‘ìš”í–ˆë‹¤ê³ ë§Œ ì–¸ê¸‰**í•  ê²ƒ
        9. **íŠ¹ì • ëŒ€ë¶„ë¥˜ê°€ ê°€ì¥ ë‘ë“œëŸ¬ì§„ ì°¨ì´ë¥¼ ë³´ì˜€ì„ ê²½ìš°**, í•´ë‹¹ ê²½í–¥ì„ ê°•ì¡°í•  ê²ƒ
        10. ìˆ«ìê°’ì„ ì§ì ‘ ì“°ì§€ ë§ê³  ìƒëŒ€ì ì¸ ê²½í–¥ë§Œ ì–¸ê¸‰í•  ê²ƒ
        11. í†µê³„ì  ìœ ì˜ë¯¸ì„±ìœ¼ë¡œ ì¸í•´~~, í†µê³„ì ìœ¼ë¡œ ì°¨ì´ê°€ ìˆì–´~~, í†µê³„ ê²°ê³¼ê°€ ì—†ìœ¼ë¯€ë¡œ~~ ì´ëŸ°ì‹ìœ¼ë¡œ í†µê³„ ê²€ì •ì˜ ê²°ê³¼ ìœ ë¬´ì— ëŒ€í•œ ë‚´ìš©ì€ ì‘ì„±í•˜ì§€ ë§ê³ , í†µê³„ ê²€ì • ê²°ê³¼ê°€ ìˆìœ¼ë©´ í•´ë‹¹ ê²°ê³¼ì˜ ëŒ€ë¶„ë¥˜ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ìš”ì•½í•  ê²ƒ.
        """,
        "English": """
        You are a data analyst summarizing trends across population groups based on statistical data.
        You must integrate the following two pieces of information to identify key patterns:

        1ï¸âƒ£ **Statistical Test Results (ft_test_summary)**: indicates which row groups (categories) showed statistically significant differences
        2ï¸âƒ£ **Key Variables (anchor)**: columns (features) that had the highest overall selection rate among respondents

        ---

        ğŸ“ Survey Question:
        {selected_question}

        ğŸ“Š Table Data (Linearized):
        {linearized_table}

        ğŸ“ˆ Key Variables (most frequently selected):
        {anchor}

        ğŸ“ˆ Statistical Test Results (significant groups):
        {ft_test_summary}

        ---

        âš ï¸ Note: If there are no statistical results or if the user has opted out of statistical analysis, summarize based on key variables (anchor) and observed trends around them.

        Let's think step by step.

        ğŸ¯ Guidelines for Analysis and Summary:
        1. Focus only on row groups that are statistically significant (p-value < 0.05, marked with asterisk)
        2. Do not list all groups/subgroups; highlight only those with major, meaningful differences
            - If there are no statistically significant categories (if there are no significant stars (*)), only mention the categories included in the main items with small p-values.
        3. **Do not interpret causality** (e.g., due to health sensitivity, etc.) â€“ strictly prohibited
        4. No external knowledge or subjective speculation allowed â€“ only describe facts verifiable from the table
        5. Describe trends using expressions like:
        - Showed relatively higher trend
        - Showed lower values
        6. Use natural transitions; avoid repetitive sentence structures
        7. **Do not mention non-significant or excluded categories**
        8. If all row groups are significant and important, donâ€™t describe each â€” state they were all important
        9. **If one group shows the most outstanding difference**, emphasize that
        10. Avoid exact numerical values â€” describe only relative tendencies"""
    }
    HALLUCINATION_CHECK_PROMPT = {
        "í•œêµ­ì–´": """
        ë‹¹ì‹ ì€ í†µê³„ í•´ì„ ê²°ê³¼ë¥¼ ê²€ì¦í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

        ì•„ë˜ì˜ í…Œì´ë¸” ë°ì´í„°ì™€ í†µê³„ ë¶„ì„ ê²°ê³¼(F/T-test ê¸°ë°˜), ê·¸ë¦¬ê³  í•´ë‹¹ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‘ì„±ëœ ìš”ì•½ ë³´ê³ ì„œê°€ ì£¼ì–´ì§‘ë‹ˆë‹¤.

        ğŸ“ ì„¤ë¬¸ ë¬¸í•­:
        {selected_question}

        ğŸ“Š ì„ í˜•í™”ëœ í…Œì´ë¸”:
        {linearized_table}

        ğŸ“ˆ í†µê³„ ë¶„ì„ ê²°ê³¼ (F/T-test ê²°ê³¼ ìš”ì•½):
        {ft_test_summary}

        ğŸ§¾ ìƒì„±ëœ ìš”ì•½:
        {table_analysis}

        ---

        ì´ ìš”ì•½ì´ ìœ„ì˜ í†µê³„ ë¶„ì„ ê²°ê³¼ë¥¼ **ì •í™•í•˜ê³  ì¼ê´€ì„± ìˆê²Œ** ë°˜ì˜í•˜ê³  ìˆëŠ”ì§€ í‰ê°€í•´ì£¼ì„¸ìš”.

        âš ï¸ ì£¼ì˜ ì‚¬í•­ (ìœ„ë°˜ ì‹œ ìš°ì„  í”¼ë“œë°± ì œê³µ, ì‹¬ê°í•œ ì™œê³¡ì— í•œí•´ reject):
        1. F/T-testì—ì„œ í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ì°¨ì´ê°€ í™•ì¸ëœ ëŒ€ë¶„ë¥˜ê°€ ìš”ì•½ì— ì–¸ê¸‰ë˜ì§€ ì•Šì€ ê²½ìš°
            1.1  í†µê³„ ë¶„ì„ ê²°ê³¼ê°€ ì—†ì„ ê²½ìš°, ì‹¤ì œ í‘œì™€ ìƒì„±ëœ ìš”ì•½ì— ì™œê³¡ì´ ì—†ëŠ”ì§€ì— ëŒ€í•´ì„œë§Œ í‰ê°€í•´ì£¼ì„¸ìš”.
        2. ìœ ì˜ë¯¸í•œ ì°¨ì´ê°€ í™•ì¸ëœ ëŒ€ë¶„ë¥˜ì—ì„œì˜ ì£¼ìš” ê²½í–¥ì´ë‚˜ ìˆ˜ì¹˜ ê²°ê³¼ê°€ ì™œê³¡ë˜ì–´ í•´ì„ëœ ê²½ìš° (e.g. ë” ë†’ì§€ ì•Šì€ë° ë” ë†’ë‹¤ê³  ì˜ëª» ëœ ì£¼ì¥ì„ í•˜ëŠ” ê²½ìš°)

        ğŸ¯ í‰ê°€ ë°©ì‹:
        - ìš”ì•½ì´ ì „ì²´ì ìœ¼ë¡œ ì‹ ë¢°í•  ë§Œí•˜ê³  í†µê³„ ê²°ê³¼ë¥¼ ì˜ ë°˜ì˜í•˜ë©´ "accept"
        - ìœ„ í•­ëª© ìœ„ë°˜ ì‹œ "reject: [ì´ìœ ]" í˜•ì‹ìœ¼ë¡œ ì¶œë ¥

        â€» F/T-test ê²°ê³¼ëŠ” ì¤‘ìš”í•œ ê¸°ì¤€ì´ì§€ë§Œ, ì‚¬ì†Œí•œ ëˆ„ë½ì€ reject ëŒ€ì‹  í”¼ë“œë°±ìœ¼ë¡œ ì²˜ë¦¬í•´ë„ ë©ë‹ˆë‹¤. ëª…ë°±í•œ ì™œê³¡ì´ë‚˜ ì¤‘ëŒ€í•œ ëˆ„ë½ ì‹œì—ë§Œ reject í•˜ì„¸ìš”.
        """,
        "English": """
You are a statistical analysis auditor.

Below is a statistical summary table (linearized format), F/T-test results, and a summary report written based on them.

ğŸ“ Survey question:
{selected_question}

ğŸ“Š Linearized Table:
{linearized_table}

ğŸ“ˆ Statistical Test Summary (F/T-test):
{ft_test_summary}

ğŸ§¾ Generated Summary Report:
{table_analysis}

---

Please evaluate whether the summary accurately and consistently reflects the statistical test results above.

âš ï¸ Evaluation Guidelines (Provide feedback first. Only reject in cases of serious distortion):
1. If a major category with statistically significant difference is missing in the summary
2. If the key trends or directions are misinterpreted (e.g. stating itâ€™s higher when it isnâ€™t)

ğŸ¯ Evaluation Instructions:
- If the summary is overall reliable and reflects the results well, answer "accept"
- If any violations occur, return: "reject: [reason]"

â€» F/T-test is a key basis, but minor omissions can be handled with feedback only. Use "reject" only for clear distortions or major omissions.
"""}
    REVISION_PROMPT = {
        "í•œêµ­ì–´": """
        ë‹¹ì‹ ì€ í†µê³„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¸êµ¬ì§‘ë‹¨ ê°„ íŒ¨í„´ê³¼ ê²½í–¥ì„±ì„ ê°ê´€ì ìœ¼ë¡œ ìš”ì•½í•˜ëŠ” ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

        ì•„ë˜ëŠ” í…Œì´ë¸” ë¶„ì„ ê²°ê³¼ì— ëŒ€í•´ ì¼ë¶€ ì˜ëª»ëœ í•´ì„ì´ í¬í•¨ëœ ìš”ì•½ì…ë‹ˆë‹¤. í”¼ë“œë°±ê³¼ ì‚¬ì „ì— ìƒì„±ëœ ê°€ì„¤ì„ ì°¸ê³ í•˜ì—¬ ì˜ëª»ëœ ë‚´ìš©ì„ ì œê±°í•˜ê³ , ì›ë³¸ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìˆ˜ì¹˜ ê¸°ë°˜ì˜ ê°ê´€ì  ë¶„ì„ì„ ë‹¤ì‹œ ì‘ì„±í•  ê²ƒ.

        ğŸ“Š í‘œ ë°ì´í„° (ì„ í˜•í™”ëœ í˜•íƒœ):
        {linearized_table}

        ğŸ“ˆ ì£¼ìš” í•­ëª© (ë³€ìˆ˜ë“¤ ì¤‘ ê°€ì¥ íˆ¬í‘œìœ¨ì´ ë†’ì€ ë³€ìˆ˜):
        {anchor}

        ğŸ“ˆ í†µê³„ ë¶„ì„ ê²°ê³¼ (í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ëŒ€ë¶„ë¥˜):
        {ft_test_summary}

        ğŸ“ Rejectëœ ë³´ê³ ì„œ (ìˆ˜ì •í•´ì•¼í•  ë³´ê³ ì„œ):
        {report_to_modify}

        â— í”¼ë“œë°± (ìˆ˜ì •ì´ í•„ìš”í•œ ì´ìœ  ë˜ëŠ” ì˜ëª»ëœ ë¶€ë¶„):
        {feedback}

        ---

        Let's think step by step

        ğŸ¯ ìˆ˜ì • ë° ì¬ì‘ì„± ì§€ì¹¨:

        1. ë°˜ë“œì‹œ **F/T test ê²°ê³¼ì—ì„œ í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ëŒ€ë¶„ë¥˜ë§Œì„ ì¤‘ì‹¬ìœ¼ë¡œ ë¶„ì„**í•  ê²ƒ (p-value < 0.05, ìœ ì˜ì„± ë³„(*) ì¡´ì¬)
        2. ëª¨ë“  ëŒ€ë¶„ë¥˜ / ì†Œë¶„ë¥˜ë¥¼ ë‚˜ì—´í•˜ì§€ ë§ê³ , **ê²€ì • ê²°ê³¼ì—ì„œ ì°¨ì´ê°€ í¬ê³  ì˜ë¯¸ ìˆëŠ” ëŒ€ë¶„ë¥˜ë§Œ ì„ íƒì ìœ¼ë¡œ ì–¸ê¸‰**í•  ê²ƒ
        3. **ì ˆëŒ€ í•´ì„í•˜ì§€ ë§ ê²ƒ**. ìˆ˜ì¹˜ì  ì°¨ì´ì— ëŒ€í•œ ì¸ê³¼ í•´ì„(ì˜ˆ: ê±´ê°•ì— ë¯¼ê°í•´ì„œ, ì£¼ë³€ì— ìˆì–´ì„œ ë“±)ì€ ëª¨ë‘ ê¸ˆì§€í•¨
        4. ì™¸ë¶€ ë°°ê²½ì§€ì‹, ì£¼ê´€ì  ì¶”ë¡ , í•´ì„ì  ì–¸ê¸‰ì€ ì ˆëŒ€ ê¸ˆì§€. **í‘œë¡œë¶€í„° ì§ì ‘ í™•ì¸ ê°€ëŠ¥í•œ ì‚¬ì‹¤ë§Œ ì„œìˆ **í•  ê²ƒ
        5. ìˆ˜ì¹˜ ê¸°ë°˜ ê²½í–¥ì„ ë‹¤ìŒê³¼ ê°™ì€ í˜•ì‹ìœ¼ë¡œ ì„œìˆ í•  ê²ƒ:
        - ìƒëŒ€ì ìœ¼ë¡œ ë” ë†’ì€ ê²½í–¥ ë³´ì˜€ìŒ
        - ë‚®ì€ ê°’ì„ ë‚˜íƒ€ëƒˆìŒ
        6. ë³´ê³ ì„œ ìŒìŠ´ì²´ë¡œ ì‘ì„±í•  ê²ƒ (ì˜ˆ: ~í–ˆìŒ, ~ë¡œ ë‚˜íƒ€ë‚¬ìŒ)
        7. ë¬¸ì¥ ê°„ ì—°ê²°ì–´ë¥¼ í™œìš©í•´ ìì—°ìŠ¤ëŸ½ê²Œ ì„œìˆ í•˜ê³ , ë„ˆë¬´ ë‹¨ì¡°ë¡­ê±°ë‚˜ ë°˜ë³µì ì¸ í‘œí˜„ (~í–ˆìŒ. ~í–ˆìŒ.)ì€ í”¼í•  ê²ƒ
        8. **ìœ ì˜ì„±ì´ ì—†ê±°ë‚˜, ê²€ì •ì—ì„œ ì œì™¸ëœ í•­ëª©ì€ ì ˆëŒ€ ì–¸ê¸‰í•˜ì§€ ë§ ê²ƒ**
        9. **íŠ¹ì • ëŒ€ë¶„ë¥˜ê°€ ê°€ì¥ ë‘ë“œëŸ¬ì§„ ì°¨ì´ë¥¼ ë³´ì˜€ì„ ê²½ìš°**, í•´ë‹¹ ê²½í–¥ì„ ê°•ì¡°í•  ê²ƒ
        10. ìˆ«ìê°’ì„ ì§ì ‘ ì“°ì§€ ë§ê³  ìƒëŒ€ì ì¸ ê²½í–¥ë§Œ ì–¸ê¸‰í•  ê²ƒ
        11. ì´ì „ ìˆ˜ì • ë²„ì „ì˜ ë¬¸ì¥ í‘œí˜„ì„ ì¬ì‚¬ìš©í•˜ì§€ ì•Šê³ , ìƒˆë¡œìš´ ì–´íœ˜ì™€ êµ¬ì¡°ë¡œ ì‘ì„±í•  ê²ƒ
        12. ì¶”ë¡  ê³¼ì •ì„ ì‘ì„±í•˜ì§€ ë§ê³  ìµœì¢…ì ìœ¼ë¡œ ìˆ˜ì •í•œ ë³´ê³ ì„œë§Œ ì¶œë ¥í•˜ì„¸ìš”.
        """,
        "English": """
        You are a data analyst who objectively summarizes population-level patterns based on statistical data.

        Below is a summary that contains partially incorrect interpretations of a statistical table analysis. Based on the given feedback and hypotheses, revise the summary by removing inaccurate parts and rewrite a new objective analysis grounded in the data.

        ğŸ“Š Table data (linearized):
        {linearized_table}

        ğŸ“ˆ Key variables (most selected):
        {anchor}

        ğŸ“ˆ Statistical analysis results (significant categories):
        {ft_test_summary}

        ğŸ“ Rejected summary (needs revision):
        {report_to_modify}

        â— Feedback (reason for revision or incorrect points):
        {feedback}

        ---

        Let's think step by step

        ğŸ¯ Revision Guidelines:

        1. Focus only on categories that showed statistically significant differences in the F/T test (p-value < 0.05, marked with *)
        2. Do not list all categories/subcategories; mention only those with meaningful differences
        3. **Do not provide causal interpretations** â€“ explanations like â€œdue to health concernsâ€ or similar are prohibited
        4. No external knowledge or speculation â€“ write only what is verifiable from the table
        5. Describe trends in a form such as:
        - Showed relatively higher trend
        - Showed lower values
        6. Write in bullet-style declarative tone (e.g., â€œ~was observedâ€, â€œ~was shownâ€)
        7. Use transition words to make the sentences flow naturally; avoid repetitive sentence endings
        8. **Do not mention non-significant or excluded categories**
        9. **If a particular group showed the strongest difference**, emphasize it
        10. Do not mention actual numerical values, only describe relative trends
        11. Do not reuse previous sentence structures â€“ use new wording and phrasing
        12. Do not explain the reasoning â€“ only output the final revised summary
        """}
    POLISHING_PROMPT = {
        "í•œêµ­ì–´": """
        ë‹¹ì‹ ì€ í†µê³„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‘ì„±ëœ í•œêµ­ì–´ ë³´ê³ ì„œë¥¼ ë‹¤ë“¬ëŠ” ë¬¸ì²´ ì „ë¬¸ ì—ë””í„°ì…ë‹ˆë‹¤.

        ì•„ë˜ëŠ” í†µê³„ ë¶„ì„ ê²°ê³¼ë¥¼ ìš”ì•½í•œ ì´ˆì•ˆì…ë‹ˆë‹¤.  
        ë¬¸ì¥ì´ ë‹¨ì ˆì ì´ê±°ë‚˜(~í–ˆìŒ. ~í–ˆìŒ ë°˜ë³µ), í‘œí˜„ì´ ì¤‘ë³µë˜ê±°ë‚˜, ë¶ˆí•„ìš”í•œ ì¸ì‚¬ì´íŠ¸ê°€ í¬í•¨ë˜ì–´ ìˆë‹¤ë©´, **ì˜ë¯¸ë¥¼ ë³€ê²½í•˜ì§€ ì•Šê³ ** ë” ì½ê¸° ì‰¬ìš´ ë¬¸ì¥ìœ¼ë¡œ ë‹¤ë“¬ìœ¼ì„¸ìš”.

        ğŸ¯ ë‹¤ìŒ ì§€ì¹¨ì„ ì—„ê²©íˆ ë”°ë¥´ì„¸ìš”:

        1. **ë‚´ìš© ì¶”ê°€, ì‚­ì œ ê¸ˆì§€** â€” ìˆ˜ì¹˜ ê¸°ë°˜ì˜ ì›ë¬¸ ì •ë³´ì—ì„œ ë²—ì–´ë‚˜ëŠ” ìƒˆë¡œìš´ í•´ì„, ë°°ê²½ ì„¤ëª…, ì¸ê³¼ê´€ê³„ ìœ ì¶”ëŠ” ëª¨ë‘ ê¸ˆì§€
        2. **'ìŒìŠ´ì²´' ìŠ¤íƒ€ì¼ ìœ ì§€** â€” ì˜ˆ: ~í–ˆìŒ, ~ë¡œ ë‚˜íƒ€ë‚¬ìŒ
        3. **ì¸ì‚¬ì´íŠ¸ ì œê±°** â€” â€˜ê±´ê°•ì— ë¯¼ê°í•´ì„œâ€™, â€˜ì§ì ‘ ì˜í–¥ì„ ë°›ì•„ì„œâ€™ ë“± ì£¼ê´€ì  ì¶”ë¡ ì€ ëª¨ë‘ ì œê±°í•˜ê³ , í‘œë¡œë¶€í„° ë“œëŸ¬ë‚˜ëŠ” ì‚¬ì‹¤ë§Œ ìœ ì§€
        4. **í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•œ í•­ëª©(ë³„í‘œ í¬í•¨ëœ ëŒ€ë¶„ë¥˜)**ë§Œ ë¬¸ì¥ì— í¬í•¨ë˜ì—ˆëŠ”ì§€ í™•ì¸í•  ê²ƒ
        5. **ì¤‘ë³µ í‘œí˜„ ì œê±° ë° ì—°ê²°** â€” ë™ì¼ ì˜ë¯¸ì˜ í‘œí˜„ ë°˜ë³µ("ë†’ê²Œ ë‚˜íƒ€ë‚¬ìŒ", "ê´€ì‹¬ì´ ë†’ì•˜ìŒ")ì€ í”¼í•˜ê³  ì—°ê²°ì–´ë¥¼ í†µí•´ ê°„ê²°í•˜ê²Œ ì •ë¦¬
        6. **ë‹¨ì¡°ë¡œìš´ ë‚˜ì—´ í”¼í•˜ê¸°** â€” ~í–ˆìŒ. ~í–ˆìŒ. ë°˜ë³µí•˜ì§€ ë§ê³ , ë¬¸ì¥ êµ¬ì¡°ë¥¼ ë‹¤ì–‘í™”í•˜ê³  ì—°ê´€ëœ í•­ëª©ì€ í•œ ë¬¸ì¥ìœ¼ë¡œ ë¬¶ê¸°
        7. **ë‹¤ì–‘í•œ í‘œí˜„ í˜¼ìš©** â€” ì•„ë˜ì™€ ê°™ì€ í‘œí˜„ì„ ì ì ˆíˆ ì„ì–´ ì‚¬ìš©í•  ê²ƒ:
        - ë‘ë“œëŸ¬ì§„ ê²½í–¥ ë³´ì˜€ìŒ
        - ëšœë ·í•œ ì°¨ì´ë¥¼ ë‚˜íƒ€ëƒˆìŒ
        - ìƒëŒ€ì ìœ¼ë¡œ ë†’ì€ ê°’ì„ ë³´ì˜€ìŒ
        - ê°€ì¥ ë†’ê²Œ í™•ì¸ëìŒ
        8. **ë¶ˆí•„ìš”í•œ ì†Œë¶„ë¥˜ ë˜ëŠ” ëª¨ë“  ê·¸ë£¹ ë‚˜ì—´ ê¸ˆì§€** â€” ìš”ì•½ì€ íŠ¹ì§•ì ì¸ ê·¸ë£¹ ì¤‘ì‹¬ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ì‘ì„±í•  ê²ƒ
        9. **í‘œ ê¸°ë°˜ ì‚¬ì‹¤ë§Œ ìš”ì•½** â€” ìˆ˜ì¹˜ ê¸°ë°˜ ê²½í–¥ë§Œ ì „ë‹¬í•˜ê³ , í•´ì„ì€ í¬í•¨í•˜ì§€ ë§ ê²ƒ

        ğŸ“ ê¸°ì¡´ ìš”ì•½:
        {raw_summary}

        ---

        ğŸ¯ ë‹¤ë“¬ì–´ì§„ ìµœì¢… ìš”ì•½ë¬¸:
        """,
        "English": """
        You are a stylistic editor for statistical summaries written in Korean.

        Below is a draft summary of a statistical analysis.  
        If the sentences are too choppy ("~í–ˆìŒ. ~í–ˆìŒ." repetition), redundant, or include subjective insights, rewrite them into a more readable style **without altering their meaning**.

        ğŸ¯ Strictly follow these instructions:

        1. **No additions or deletions** â€” Do not add new interpretations, background, or causal reasoning beyond the original numeric-based content.
        2. **Keep declarative tone** â€” Use styles like: "~was observed", "~was shown"
        3. **Remove speculative insights** â€” Phrases like â€œdue to health concernsâ€ or â€œbecause they were affectedâ€ must be removed; stick only to observable facts
        4. **Only include categories with statistical significance (asterisked)** in the report
        5. **Eliminate and connect duplicates** â€” Avoid repeating the same idea (e.g., â€œwas highâ€, â€œinterest was highâ€); connect with transitions
        6. **Avoid monotonous structure** â€” Donâ€™t repeat "~was observed." repeatedly; vary structure and combine related findings into single sentences
        7. **Use varied expressions** â€” Mix in phrases like:
        - Showed notable trend
        - Displayed clear difference
        - Exhibited relatively high values
        - Recorded the highest
        8. **Avoid listing all subgroups** â€” Focus on concise summaries of characteristic groups
        9. **Only report table-based facts** â€” Do not include interpretations; describe numeric trends only

        ğŸ“ Original draft:
        {raw_summary}

        ---

        ğŸ¯ Polished final summary:
        """
        } 
from typing import List, Dict, Any, Optional
import pandas as pd
import numpy as np
from ..table_analysis.entities import AgentState
from ...infrastructure.openai.client import OpenAIClient
from ...infrastructure.file.excel_loader import ExcelLoader
from ...infrastructure.statistics.statistical_tester import StatisticalTester
import re


class TableAnalysisService:
    """í…Œì´ë¸” ë¶„ì„ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ì„œë¹„ìŠ¤"""
    
    def __init__(self, openai_client: OpenAIClient, excel_loader: ExcelLoader, statistical_tester: StatisticalTester):
        self.openai_client = openai_client
        self.excel_loader = excel_loader
        self.statistical_tester = statistical_tester
    
    async def parse_table(self, state: AgentState, on_step=None) -> AgentState:
        """í…Œì´ë¸” íŒŒì„œ ë…¸ë“œ"""
        if on_step:
            on_step("ğŸ“Š í…Œì´ë¸” íŒŒì„œ ë…¸ë“œ ì‹œì‘")
        
        # íŒŒì¼ì—ì„œ í…Œì´ë¸” íŒŒì‹±
        if state.uploaded_file:
            parsed_data = self.excel_loader.load_survey_tables(
                state.uploaded_file,
                state.file_path
            )
            state.tables = parsed_data["tables"]
            state.question_texts = parsed_data["question_texts"]
            state.question_keys = parsed_data["question_keys"]
        
        # ì„ íƒëœ í‚¤ ë§¤ì¹­
        if state.selected_key and state.tables:
            matching_key = self.excel_loader.find_matching_key(state.selected_key, list(state.tables.keys()))
            if matching_key:
                state.selected_key = matching_key
                state.selected_table = state.tables[matching_key]
                state.selected_question = state.question_texts[matching_key]
            elif state.analysis_type:
                raise Exception(f"ì„ íƒëœ ì§ˆë¬¸ í‚¤ '{state.selected_key}'ì— í•´ë‹¹í•˜ëŠ” í…Œì´ë¸”ì´ ì—†ìŠµë‹ˆë‹¤.")
            else:
                # ë°°ì¹˜ ë¶„ì„ì˜ ê²½ìš° ì²« ë²ˆì§¸ ì§ˆë¬¸ ì‚¬ìš©
                state.selected_key = state.question_keys[0]
                state.selected_table = state.tables[state.selected_key]
                state.selected_question = state.question_texts[state.selected_key]
        
        # í…Œì´ë¸” ì„ í˜•í™”
        if state.selected_table is not None:
            state.linearized_table = self.linearize_row_wise(state.selected_table)
        
        return state
    
    def linearize_row_wise(self, table: pd.DataFrame) -> str:
        """í…Œì´ë¸”ì„ í–‰ ë‹¨ìœ„ë¡œ ì„ í˜•í™”"""
        if table is None or table.empty:
            return ""
        
        # ìˆ«ì ì»¬ëŸ¼ë§Œ ì„ íƒ
        numeric_cols = table.select_dtypes(include=[np.number]).columns.tolist()
        if not numeric_cols:
            return ""
        
        # ì²« ë²ˆì§¸ ì»¬ëŸ¼ (ê·¸ë£¹ëª…)ê³¼ ìˆ«ì ì»¬ëŸ¼ë“¤ë§Œ ì‚¬ìš©
        result_cols = [table.columns[0]] + numeric_cols
        result_df = table[result_cols]
        
        # í–‰ ë‹¨ìœ„ë¡œ ë¬¸ìì—´ ë³€í™˜
        rows = []
        for _, row in result_df.iterrows():
            row_str = " | ".join([str(val) for val in row.values])
            rows.append(row_str)
        
        return "\n".join(rows)
    
    async def generate_hypothesis(self, state: AgentState, on_step=None) -> AgentState:
        """ê°€ì„¤ ìƒì„± ë…¸ë“œ"""
        if on_step:
            on_step("ğŸ’¡ ê°€ì„¤ ìƒì„± ë…¸ë“œ ì‹œì‘")

        selected_table = state.selected_table
        selected_question = state.selected_question
        lang = state.lang if hasattr(state, 'lang') else "í•œêµ­ì–´"

        # rowì™€ column name ì¶”ì¶œ
        if selected_table is not None and isinstance(selected_table, pd.DataFrame):
            if "ëŒ€ë¶„ë¥˜" in selected_table.columns and "ì†Œë¶„ë¥˜" in selected_table.columns:
                selected_table = selected_table.copy()
                selected_table["row_name"] = selected_table["ëŒ€ë¶„ë¥˜"].astype(str) + "_" + selected_table["ì†Œë¶„ë¥˜"].astype(str)
                row_names = selected_table["row_name"].dropna().tolist()
            else:
                row_names = list(selected_table.index)
            column_names = list(selected_table.columns)
        else:
            row_names = []
            column_names = []

        row_names_str = ", ".join(map(str, row_names))
        column_names_str = ", ".join(map(str, column_names))

        # í”„ë¡¬í”„íŠ¸ ì •ì˜
        HYPOTHESIS_PROMPT = {
            "í•œêµ­ì–´": """
ë‹¹ì‹ ì€ í†µê³„ ë°ì´í„°ë¥¼ í•´ì„í•˜ëŠ” ë°ì´í„° ê³¼í•™ìì…ë‹ˆë‹¤.
ì•„ë˜ëŠ” ë¶„ì„í•  í‘œì˜ rowëª… (index)ê³¼ columnëª…ì…ë‹ˆë‹¤.

row: {row_names}
column: {column_names}

ë‹¹ì‹ ì˜ ì„ë¬´ëŠ”, ì‚¬ìš©ìì˜ ì§ˆë¬¸ ("{selected_question}")ê³¼ ê´€ë ¨í•´  
ë°ì´í„°ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆì„ ë²•í•œ ê°€ì„¤(íŒ¨í„´, ê´€ê³„)ì„ 2~5ê°œ ì •ë„ ì œì•ˆí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

ì˜ˆì‹œ:
1. ì—°ë ¹ëŒ€ê°€ ë†’ì„ìˆ˜ë¡ ê´€ì‹¬ë„ê°€ ë†’ì„ ê²ƒì´ë‹¤.
2. ê¸°ì €ì§ˆí™˜ì´ ìˆëŠ” ê²½ìš° ê´€ì‹¬ë„ê°€ ë†’ì„ ê²ƒì´ë‹¤.

- ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ í•©ë¦¬ì ì¸ ê°€ì„¤ë§Œ ìƒì„±í•  ê²ƒ
- ì™¸ë¶€ ì§€ì‹ì€ ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€
- ë¬¸ì¥ ê¸¸ì´ëŠ” ì§§ê³ , ë²ˆí˜¸ ë¦¬ìŠ¤íŠ¸ë¡œ ì‘ì„±
""",
            "English": """
You are a data scientist interpreting statistical tables.
Below are the row names (index) and column names of the table to be analyzed.

row: {row_names}
column: {column_names}

Your task is to propose 2 to 5 hypotheses (patterns or relationships) relevant to the user's question ("{selected_question}") that could be inferred from the data.

Example:
1. Older age groups may show higher interest.
2. Those with chronic illnesses may show higher concern.

- Only propose reasonable hypotheses based on the data
- Do not use external knowledge
- Keep sentences short and format as a numbered list
"""
        }

        prompt = HYPOTHESIS_PROMPT[lang].format(
            row_names=row_names_str,
            column_names=column_names_str,
            selected_question=selected_question
        )

        messages = [
            {"role": "system", "content": "ë‹¹ì‹ ì€ í†µê³„ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤." if lang == "í•œêµ­ì–´" else "You are a statistical analysis expert."},
            {"role": "user", "content": prompt}
        ]

        state.generated_hypotheses = await self.openai_client.call(messages)
        return state
    
    async def decide_test_type(self, state: AgentState, on_step=None) -> AgentState:
        """í†µê³„ ê²€ì • ë°©ë²• LLM ë‹¨ì¼ ë¶„ë¥˜ ë…¸ë“œ (manual/ft_test/chi_square)"""
        if on_step:
            on_step("ğŸ§­ í†µê³„ ê²€ì • ê²°ì • ë…¸ë“œ ì‹œì‘")
        if state.selected_table is not None:
            columns = state.selected_table.columns.tolist()
            question_text = getattr(state, 'selected_question', "")
            column_names_str = ", ".join(columns)
            TEST_TYPE_PROMPT = """
ë‹¹ì‹ ì€ í†µê³„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì•„ë˜ëŠ” ì„¤ë¬¸ ë¬¸í•­ê³¼ ì—´ ì´ë¦„ ëª©ë¡ì…ë‹ˆë‹¤.

ë¬¸í•­: {question_text}
ì—´ ì´ë¦„: {column_names}

ë‹¹ì‹ ì˜ ì„ë¬´ëŠ”, ì´ ë¬¸í•­ì´ ì•„ë˜ ì¤‘ ì–´ë–¤ í†µê³„ ë¶„ì„ ìœ í˜•ì— í•´ë‹¹í•˜ëŠ”ì§€ ë¶„ë¥˜í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

ğŸ“‹ ë¶„ë¥˜ ê¸°ì¤€:

1ï¸âƒ£ **manual** (ë³µìˆ˜ì‘ë‹µ/ë‹¤ì¤‘ì‘ë‹µ/ìˆœìœ„í˜•):
    - í•œ ì‘ë‹µìê°€ ì—¬ëŸ¬ í•­ëª©ì„ ì„ íƒí•˜ê±°ë‚˜, ì—¬ëŸ¬ ìˆœìœ„ë¥¼ ë™ì‹œì— ì‘ë‹µí•˜ëŠ” ê²½ìš°
        - !!!ì£¼ì˜!!! "1ìˆœìœ„"ë§Œ ìˆëŠ” ê²½ìš°ëŠ” manualì´ ì•„ë‹˜ (ft_testì™€ chi_square ì¤‘ í•˜ë‚˜ë¡œ ê²°ì •)
    - ì˜ˆì‹œ: "ë³µìˆ˜ì‘ë‹µ", "ë‹¤ì¤‘ì‘ë‹µ", "1+2ìˆœìœ„", "1+2+3ìˆœìœ„", "ranking", "ìš°ì„ ìˆœìœ„(1+2)", "ë‹¤ì¤‘ì„ íƒ"
    - ë¬¸í•­ì— "ë³µìˆ˜", "ë‹¤ì¤‘", "multiple", "ranking" ë“±ì´ í¬í•¨ëœ ê²½ìš°

2ï¸âƒ£ **ft_test** (ì—°ì†í˜• ìˆ˜ì¹˜ ì‘ë‹µ):
    - ë¬¸í•­ì´ 1~5ì  ì²™ë„, í‰ê· , ë¹„ìœ¨, ì ìˆ˜ ë“± ìˆ«ì ê¸°ë°˜ìœ¼ë¡œ ìš”ì•½ë˜ì–´ ìˆëŠ” ê²½ìš°
    - ì˜ˆì‹œ ì—´ ì´ë¦„: "í‰ê· ", "ë§Œì¡±ë„ ì ìˆ˜", "~% ë¹„ìœ¨", "5ì  ì²™ë„", "í‰ê·  ì ìˆ˜", "ê´€ì‹¬ë„ í‰ê· "
    - "ì „í˜€ ê´€ì‹¬ì´ ì—†ë‹¤", "ë§¤ìš° ê´€ì‹¬ ìˆë‹¤" ë“±ì€ ì‹¤ì œë¡œëŠ” ì„ íƒì§€ì´ì§€ë§Œ, ë¹ˆë„ë‚˜ ë¹„ìœ¨ë¡œ ìˆ˜ì¹˜í™”ë˜ì—ˆì„ ê²½ìš° â†’ ì—°ì†í˜•ìœ¼ë¡œ íŒë‹¨
    - í…Œì´ë¸”ì´ ì „ì²´ì ìœ¼ë¡œ í‰ê· ê°’ ë˜ëŠ” %ë¹„ìœ¨ ì¤‘ì‹¬ì´ë©´ ft_test ì„ íƒì´ ë” ì ì ˆ

3ï¸âƒ£ **chi_square** (ë²”ì£¼í˜• ì„ íƒ ì‘ë‹µ):
    - ë¬¸í•­ì´ ì‘ë‹µìë“¤ì´ íŠ¹ì • í•­ëª©ì„ **ì„ íƒ**í•˜ê±°ë‚˜ **ë‹¤ì¤‘ì„ íƒ**í•œ ê²°ê³¼ì¼ ê²½ìš°
    - ì˜ˆì‹œ ì—´ ì´ë¦„: "ì£¼ìš” ì´ìš©ì‹œì„¤", "ì„ íƒ ì´ìœ ", "ê°€ì¥ ë§ì´ ì„ íƒí•œ ì¥ì†Œ", "ë‹¤ì¤‘ ì‘ë‹µ"
    - ë‹¨ì¼ ì„ íƒ ë¬¸í•­ (í•œ ëª…ì´ í•œ í•­ëª©ë§Œ ì„ íƒí•˜ëŠ” ê²½ìš°)

â— **ì˜¤íŒ ì£¼ì˜ì‚¬í•­**:
- ì‘ë‹µ ì„ íƒì§€ ì´ë¦„(ì˜ˆ: "ì „í˜€ ê´€ì‹¬ ì—†ë‹¤", "ë§¤ìš° ê´€ì‹¬ ìˆë‹¤")ê°€ ì—´ ì´ë¦„ì— í¬í•¨ë˜ë”ë¼ë„, **ë¹„ìœ¨, í‰ê·  ë“±ì˜ ìˆ˜ì¹˜í˜• ìš”ì•½**ì´ë©´ `ft_test`ë¡œ ê°„ì£¼
- í…Œì´ë¸”ì´ ì „ì²´ì ìœ¼ë¡œ í‰ê· ê°’ ë˜ëŠ” %ë¹„ìœ¨ ì¤‘ì‹¬ì´ë©´ `ft_test` ì„ íƒì´ ë” ì ì ˆ
- "1ìˆœìœ„"ë§Œ ìˆëŠ” ê²½ìš°ëŠ” manualì´ ì•„ë‹˜ (ft_testì™€ chi_square ì¤‘ í•˜ë‚˜ë¡œ ê²°ì •)
- "1+2ìˆœìœ„", "1+2+3ìˆœìœ„" ë“± ë³µìˆ˜ ìˆœìœ„ë§Œ manualë¡œ ë¶„ë¥˜

---

ì•„ë˜ ì¤‘ í•˜ë‚˜ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”(ì„¤ëª… ì—†ì´):
- manual
- ft_test  
- chi_square
"""
            prompt = TEST_TYPE_PROMPT.format(
                question_text=question_text,
                column_names=column_names_str
            )
            messages = [
                {"role": "system", "content": "ë‹¹ì‹ ì€ í†µê³„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ]
            llm_result = await self.openai_client.call(messages)
            llm_output = llm_result.strip().lower()
            if "manual" in llm_output:
                state.test_type = "manual"
            elif "chi" in llm_output:
                state.test_type = "chi_square"
            elif "ft" in llm_output:
                state.test_type = "ft_test"
            else:
                state.test_type = "unknown"
        return state
    
    async def run_statistical_analysis(self, state: AgentState, on_step=None) -> AgentState:
        """í†µê³„ ë¶„ì„ ì‹¤í–‰ ë…¸ë“œ"""
        if on_step:
            on_step("âœ… F/T ë¶„ì„ ë…¸ë“œ ì‹œì‘")
        try:
            import pandas as pd
            from io import BytesIO
            if hasattr(state, 'raw_data_file') and state.raw_data_file is not None:
                print("[ft_analysis_node] raw_data_file exists")
                raw_data_file = BytesIO(state.raw_data_file) if isinstance(state.raw_data_file, (bytes, bytearray)) else state.raw_data_file
                raw_data = pd.read_excel(raw_data_file, sheet_name="DATA")
                demo_df = pd.read_excel(raw_data_file, sheet_name="DEMO")
                print(f"[ft_analysis_node] raw_data.columns: {raw_data.columns.tolist()}")
                print(f"[ft_analysis_node] demo_df.columns: {demo_df.columns.tolist()}")
                raw_data.columns = [col.replace("-", "_").strip() for col in raw_data.columns]
                demo_mapping = self.statistical_tester.extract_demo_mapping_from_dataframe(demo_df)
                print(f"[ft_analysis_node] demo_mapping: {demo_mapping}")
                test_type = getattr(state, 'test_type', None)
                question_key = getattr(state, 'selected_key', None)
                lang = getattr(state, 'lang', "í•œêµ­ì–´")
                print(f"[ft_analysis_node] test_type: {test_type}, question_key: {question_key}, lang: {lang}")
                if not isinstance(test_type, str) or not test_type:
                    raise ValueError("test_typeì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                if not isinstance(question_key, str) or not question_key:
                    raise ValueError("question_keyê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                result_df = self.statistical_tester.run_statistical_tests(test_type, raw_data, question_key, demo_mapping)
                print(f"[ft_analysis_node] result_df shape: {result_df.shape}")
                print(f"[ft_analysis_node] result_df: {result_df}")
                summary_text = self.statistical_tester.summarize_ft_test(result_df, lang=lang)
                state.raw_data = raw_data
                state.ft_test_result = result_df
                state.ft_test_summary = summary_text
            else:
                print("[ft_analysis_node] raw_data_file is None")
                state.ft_error = "raw_data_fileì´ ì—†ìŠµë‹ˆë‹¤."
        except Exception as e:
            print(f"[ft_analysis_node] Exception: {e}")
            state.ft_error = str(e)
        return state
    
    async def extract_anchor(self, state: AgentState, on_step=None) -> AgentState:
        """ì•µì»¤ ì¶”ì¶œ ë…¸ë“œ"""
        if on_step:
            on_step("ğŸ“Œ ì•µì»¤ ì¶”ì¶œ ë…¸ë“œ ì‹œì‘")
        
        selected_table = getattr(state, 'selected_table', None)
        lang = getattr(state, 'lang', 'í•œêµ­ì–´')
        anchor = []
        
        if selected_table is not None and isinstance(selected_table, pd.DataFrame):
            exclude_cols = set([
                "ëŒ€ë¶„ë¥˜", "ì†Œë¶„ë¥˜", "ì‚¬ë¡€ìˆ˜",
                "ëŒ€ë¶„ë¥˜_ì†Œë¶„ë¥˜"
            ])
            
            def is_anchor_candidate(col):
                col_str = str(col).strip()
                if col_str in exclude_cols:
                    return False
                # %ë¡œ ëë‚˜ëŠ” ì»¬ëŸ¼ ì œì™¸ (ê³µë°± í¬í•¨)
                if col_str.rstrip().endswith('%'):
                    return False
                # í‰ê· , í•©ê³„, std, score ë“± í¬í•¨ì‹œ ì œì™¸
                if any(keyword in col_str for keyword in ['í‰ê· ', 'í•©ê³„', 'std', 'score']):
                    return False
                return True
            
            # "ì „ ì²´" ë˜ëŠ” "ì „ì²´" row ì°¾ê¸° (ê³µë°± ì œê±°)
            total_row = selected_table[selected_table["ëŒ€ë¶„ë¥˜"].astype(str).str.strip().str.replace(" ", "") == "ì „ì²´"]
            if total_row.empty:
                state.anchor = []
                state.ft_error = "âŒ 'ì „ ì²´' ë˜ëŠ” 'ì „ì²´'ì— í•´ë‹¹í•˜ëŠ” í–‰ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
                return state
            
            total_row = total_row.iloc[0]
            candidate_cols = [col for col in selected_table.columns if is_anchor_candidate(col)]
            values = total_row[candidate_cols]
            values_numeric = pd.to_numeric(values, errors='coerce')
            high_value_cols = values_numeric.dropna().sort_values(ascending=False)
            cumulative_sum = 0
            selected_cols = []
            for col, val in high_value_cols.items():
                cumulative_sum += val
                selected_cols.append(col)
                if cumulative_sum >= 60:
                    break
            anchor = selected_cols
        
        state.anchor = anchor
        return state
    
    async def analyze_table(self, state: AgentState, on_step=None) -> AgentState:
        """í…Œì´ë¸” ë¶„ì„ ë…¸ë“œ"""
        if on_step:
            on_step("ğŸ¤– í…Œì´ë¸” ë¶„ì„ ë…¸ë“œ ì‹œì‘")
        
        lang = getattr(state, 'lang', 'í•œêµ­ì–´')
        linearized_table = getattr(state, 'linearized_table', '')
        ft_test_summary = getattr(state, 'ft_test_summary', '')
        selected_question = getattr(state, 'selected_question', '')
        anchor = getattr(state, 'anchor', 'ì—†ìŒ')
        
        prompt = self.TABLE_ANALYSIS_PROMPT[lang].format(
            selected_question=selected_question,
            linearized_table=linearized_table,
            ft_test_summary=str(ft_test_summary),
            anchor=anchor
        )
        
        messages = [
            {"role": "system", "content": "ë‹¹ì‹ ì€ í†µê³„ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤." if lang == "í•œêµ­ì–´" else "You are a statistical analysis expert."},
            {"role": "user", "content": prompt}
        ]
        
        state.table_analysis = await self.openai_client.call(messages)
        return state
    
    async def check_hallucination(self, state: AgentState, on_step=None) -> AgentState:
        """í™˜ê° ê²€ì¦ ë…¸ë“œ"""
        if on_step:
            on_step("ğŸ§  í™˜ê° í‰ê°€ ë…¸ë“œ ì‹œì‘")
        
        lang = getattr(state, 'lang', 'í•œêµ­ì–´')
        hallucination_reject_num = getattr(state, 'hallucination_reject_num', 0)
        
        # ìˆ˜ì • ì´ë ¥ì´ ìˆìœ¼ë©´ ë§ˆì§€ë§‰ ìˆ˜ì •ë³¸ ì‚¬ìš©
        if hasattr(state, 'revised_analysis_history') and state.revised_analysis_history:
            table_analysis = state.revised_analysis_history[-1]
        else:
            table_analysis = getattr(state, 'table_analysis', '')
        
        prompt = self.HALLUCINATION_CHECK_PROMPT[lang].format(
            selected_question=getattr(state, 'selected_question', ''),
            linearized_table=getattr(state, 'linearized_table', ''),
            ft_test_summary=str(getattr(state, 'ft_test_summary', '')),
            table_analysis=table_analysis
        )
        
        messages = [
            {"role": "system", "content": "ë‹¹ì‹ ì€ í†µê³„ í•´ì„ ê²°ê³¼ë¥¼ ê²€ì¦í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤." if lang == "í•œêµ­ì–´" else "You are a statistical analysis auditor."},
            {"role": "user", "content": prompt}
        ]
        
        result = await self.openai_client.call(messages)
        result_str = result.strip() if hasattr(result, 'strip') else str(result)
        
        if result_str.lower().startswith("reject"):
            decision = "reject"
            feedback = result_str[len("reject"):].strip(": ").strip()
            hallucination_reject_num += 1
            if hasattr(state, 'revised_analysis_history'):
                state.revised_analysis_history.append(table_analysis)
            else:
                state.revised_analysis_history = [table_analysis]
        else:
            decision = "accept"
            feedback = ""
        
        state.hallucination_check = decision
        state.feedback = feedback
        state.hallucination_reject_num = hallucination_reject_num
        return state
    
    async def revise_analysis(self, state: AgentState, on_step=None) -> AgentState:
        """ë¶„ì„ ìˆ˜ì • ë…¸ë“œ"""
        if on_step:
            on_step("âœï¸ ë¶„ì„ ìˆ˜ì • ë…¸ë“œ ì‹œì‘")
        
        lang = getattr(state, 'lang', 'í•œêµ­ì–´')
        
        # report_to_modifyëŠ” revised_historyê°€ ìˆìœ¼ë©´ ë§ˆì§€ë§‰ ê²ƒì„, ì—†ìœ¼ë©´ ì´ˆì•ˆì„ fallback
        report_to_modify = state.revised_analysis_history[-1] if getattr(state, 'revised_analysis_history', None) else getattr(state, 'table_analysis', '')
        
        prompt = self.REVISION_PROMPT[lang].format(
            linearized_table=getattr(state, 'linearized_table', ''),
            ft_test_summary=str(getattr(state, 'ft_test_summary', '')),
            anchor=getattr(state, 'anchor', ''),
            report_to_modify=report_to_modify,
            feedback=getattr(state, 'feedback', '')
        )
        
        messages = [
            {"role": "system", "content": "ë‹¹ì‹ ì€ í†µê³„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¸êµ¬ì§‘ë‹¨ ê°„ íŒ¨í„´ê³¼ ê²½í–¥ì„±ì„ ê°ê´€ì ìœ¼ë¡œ ìš”ì•½í•˜ëŠ” ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤." if lang == "í•œêµ­ì–´" else "You are a data analyst who objectively summarizes population-level patterns based on statistical data."},
            {"role": "user", "content": prompt}
        ]
        
        result = await self.openai_client.call(messages)
        new_revised_analysis = result.strip() if hasattr(result, 'strip') else str(result)
        
        # Append to revision history
        if hasattr(state, 'revised_analysis_history') and state.revised_analysis_history:
            revision_history = state.revised_analysis_history
        else:
            revision_history = []
        revision_history.append(new_revised_analysis)
        state.revised_analysis = new_revised_analysis
        state.revised_analysis_history = revision_history
        return state
    
    async def polish_sentence(self, state: AgentState, on_step=None) -> AgentState:
        """ë¬¸ì¥ ë‹¤ë“¬ê¸° ë…¸ë“œ"""
        if on_step:
            on_step("ğŸ’… ë¬¸ì¥ ë‹¤ë“¬ê¸° ë…¸ë“œ ì‹œì‘")
        
        lang = getattr(state, 'lang', 'í•œêµ­ì–´')
        hallucination_reject_num = getattr(state, 'hallucination_reject_num', 0)
        raw_summary = state.revised_analysis if hallucination_reject_num > 0 else state.table_analysis
        
        prompt = self.POLISHING_PROMPT[lang].format(raw_summary=raw_summary)
        
        messages = [
            {"role": "system", "content": "ë‹¹ì‹ ì€ í†µê³„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‘ì„±ëœ í•œêµ­ì–´ ë³´ê³ ì„œë¥¼ ë‹¤ë“¬ëŠ” ë¬¸ì²´ ì „ë¬¸ ì—ë””í„°ì…ë‹ˆë‹¤." if lang == "í•œêµ­ì–´" else "You are a stylistic editor for statistical summaries written in Korean."},
            {"role": "user", "content": prompt}
        ]
        
        result = await self.openai_client.call(messages)
        polishing_result = result.strip() if hasattr(result, 'strip') else str(result)
        state.polishing_result = polishing_result
        return state 

    # --- PROMPT DEFINITIONS ---
    TABLE_ANALYSIS_PROMPT = {
        "í•œêµ­ì–´": """
ì•„ë˜ëŠ” ì„¤ë¬¸ ë¬¸í•­, ì„ í˜•í™”ëœ í†µê³„í‘œ, F/T-test ìš”ì•½, ì•µì»¤(ì£¼ìš” í•­ëª©)ì…ë‹ˆë‹¤.\n\në¬¸í•­: {selected_question}\ní‘œ: {linearized_table}\nF/T-test ìš”ì•½: {ft_test_summary}\nì£¼ìš” í•­ëª©: {anchor}\n\nì´ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì¸êµ¬ì§‘ë‹¨ ê°„ì˜ ì£¼ìš” íŒ¨í„´ê³¼ ê²½í–¥ì„±ì„ 2~4ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•˜ì„¸ìš”.\n- ê°ê´€ì ì´ê³  ê°„ê²°í•˜ê²Œ ì‘ì„±\n- ìˆ˜ì¹˜, ê²½í–¥, ì°¨ì´ì  ì¤‘ì‹¬\n- ì™¸ë¶€ ì§€ì‹ ì‚¬ìš© ê¸ˆì§€\n""",
        "English": """
Below are the survey question, linearized table, F/T-test summary, and anchor (key items).\n\nQuestion: {selected_question}\nTable: {linearized_table}\nF/T-test summary: {ft_test_summary}\nAnchor: {anchor}\n\nBased on this information, summarize the main patterns and trends among population groups in 2-4 sentences.\n- Be objective and concise\n- Focus on numbers, trends, and differences\n- Do not use external knowledge\n"""
    }
    HALLUCINATION_CHECK_PROMPT = {
        "í•œêµ­ì–´": """
ì•„ë˜ëŠ” ì„¤ë¬¸ ë¬¸í•­, ì„ í˜•í™”ëœ í‘œ, F/T-test ìš”ì•½, ê·¸ë¦¬ê³  ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤.\n\në¬¸í•­: {selected_question}\ní‘œ: {linearized_table}\nF/T-test ìš”ì•½: {ft_test_summary}\në¶„ì„ ê²°ê³¼: {table_analysis}\n\nì´ ë¶„ì„ ê²°ê³¼ê°€ í‘œì™€ ìš”ì•½ì— ê·¼ê±°í•´ íƒ€ë‹¹í•œì§€ ê²€ì¦í•˜ì„¸ìš”.\n- ë§Œì•½ í‘œ/ìš”ì•½ì— ì—†ëŠ” ë‚´ìš©ì„ ì„ì˜ë¡œ í•´ì„í–ˆë‹¤ë©´ reject: (ì´ìœ )\n- íƒ€ë‹¹í•˜ë‹¤ë©´ accept\në‹µë³€ì€ 'accept' ë˜ëŠ” 'reject: ì´ìœ 'ë¡œë§Œ í•´ì£¼ì„¸ìš”.\n""",
        "English": """
Below are the survey question, linearized table, F/T-test summary, and analysis result.\n\nQuestion: {selected_question}\nTable: {linearized_table}\nF/T-test summary: {ft_test_summary}\nAnalysis result: {table_analysis}\n\nCheck if the analysis is valid based on the table and summary.\n- If there is any hallucination or unsupported claim, reply 'reject: (reason)'\n- If valid, reply 'accept'\nAnswer only 'accept' or 'reject: reason'.\n"""
    }
    REVISION_PROMPT = {
        "í•œêµ­ì–´": """
ì•„ë˜ëŠ” ì„ í˜•í™”ëœ í‘œ, F/T-test ìš”ì•½, ì•µì»¤, ê¸°ì¡´ ë¶„ì„ ê²°ê³¼, í”¼ë“œë°±ì…ë‹ˆë‹¤.\n\ní‘œ: {linearized_table}\nF/T-test ìš”ì•½: {ft_test_summary}\nì£¼ìš” í•­ëª©: {anchor}\nê¸°ì¡´ ë¶„ì„: {report_to_modify}\ní”¼ë“œë°±: {feedback}\n\ní”¼ë“œë°±ì„ ë°˜ì˜í•´ ë¶„ì„ ê²°ê³¼ë¥¼ 2~4ë¬¸ì¥ìœ¼ë¡œ ìˆ˜ì •í•˜ì„¸ìš”.\n- ê°ê´€ì ì´ê³  ê°„ê²°í•˜ê²Œ ì‘ì„±\n- ìˆ˜ì¹˜, ê²½í–¥, ì°¨ì´ì  ì¤‘ì‹¬\n- ì™¸ë¶€ ì§€ì‹ ì‚¬ìš© ê¸ˆì§€\n""",
        "English": """
Below are the linearized table, F/T-test summary, anchor, previous analysis, and feedback.\n\nTable: {linearized_table}\nF/T-test summary: {ft_test_summary}\nAnchor: {anchor}\nPrevious analysis: {report_to_modify}\nFeedback: {feedback}\n\nRevise the analysis in 2-4 sentences reflecting the feedback.\n- Be objective and concise\n- Focus on numbers, trends, and differences\n- Do not use external knowledge\n"""
    }
    POLISHING_PROMPT = {
        "í•œêµ­ì–´": """
ì•„ë˜ëŠ” í†µê³„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‘ì„±ëœ ìš”ì•½ë¬¸ì…ë‹ˆë‹¤.\n\n{raw_summary}\n\nì´ ë¬¸ì¥ì„ ë” ìì—°ìŠ¤ëŸ½ê³  ëª…í™•í•˜ê²Œ ë‹¤ë“¬ì–´ì£¼ì„¸ìš”.\n- ë¶ˆí•„ìš”í•œ ë°˜ë³µ, êµ°ë”ë”ê¸° ì œê±°\n- ë¬¸ì¥ ê°„ ì—°ê²° ìì—°ìŠ¤ëŸ½ê²Œ\n- ì˜ë¯¸ ì™œê³¡ ì—†ì´ ê°„ê²°í•˜ê²Œ\n""",
        "English": """
Below is a summary based on statistical data.\n\n{raw_summary}\n\nPolish this text to be more natural and clear.\n- Remove unnecessary repetition\n- Make sentence transitions smooth\n- Be concise without distorting meaning\n"""
    } 
import asyncio
import json
import io
import re
from typing import Dict, Any, Optional, List, Union
import pandas as pd
import numpy as np
from langchain_openai import ChatOpenAI
from langchain.schema import HumanMessage, SystemMessage
import os
from dotenv import load_dotenv
import openpyxl
from scipy import stats
from collections import defaultdict
import openai

load_dotenv()

class AgentState:
    """Agent ìƒíƒœë¥¼ ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤"""
    def __init__(self, **kwargs):
        self.query = kwargs.get("query", "")
        self.file_path = kwargs.get("file_path", "")
        self.analysis_type = kwargs.get("analysis_type", True)
        self.selected_question = kwargs.get("selected_question", "")
        self.selected_table = kwargs.get("selected_table", None)
        self.selected_key = kwargs.get("selected_key", "")
        self.anchor = kwargs.get("anchor", [])
        self.linearized_table = kwargs.get("linearized_table", "")
        self.numeric_analysis = kwargs.get("numeric_analysis", "")
        self.table_analysis = kwargs.get("table_analysis", "")
        self.revised_analysis = kwargs.get("revised_analysis", "")
        self.hallucination_check = kwargs.get("hallucination_check", "")
        self.hallucination_reject_num = kwargs.get("hallucination_reject_num", 0)
        self.feedback = kwargs.get("feedback", "")
        self.polishing_result = kwargs.get("polishing_result", "")
        self.generated_hypotheses = kwargs.get("generated_hypotheses", "")
        self.uploaded_file = kwargs.get("uploaded_file", None)
        self.raw_data_file = kwargs.get("raw_data_file", None)
        self.raw_data = kwargs.get("raw_data", None)
        self.raw_variables = kwargs.get("raw_variables", None)
        self.raw_code_guide = kwargs.get("raw_code_guide", None)
        self.raw_question = kwargs.get("raw_question", None)
        self.test_type = kwargs.get("test_type", None)
        self.ft_test_result = kwargs.get("ft_test_result", {})
        self.ft_test_summary = kwargs.get("ft_test_summary", "")
        self.ft_error = kwargs.get("ft_error", None)
        self.lang = kwargs.get("lang", "í•œêµ­ì–´")
        self.tables = kwargs.get("tables", {})
        self.question_texts = kwargs.get("question_texts", {})
        self.question_keys = kwargs.get("question_keys", [])
        self.revised_analysis_history = kwargs.get("revised_analysis_history", [])
        self.user_id = kwargs.get("user_id", None)
        self.survey_data = kwargs.get("survey_data", None)

class LangGraphWorkflow:
    TABLE_ANALYSIS_PROMPT = {
        "í•œêµ­ì–´": """
ë‹¹ì‹ ì€ í†µê³„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¸êµ¬ì§‘ë‹¨ ê°„ ê²½í–¥ì„ ìš”ì•½í•˜ëŠ” ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
íŠ¹íˆ ì•„ë˜ ë‘ ê°€ì§€ ì •ë³´ë¥¼ ì¢…í•©ì ìœ¼ë¡œ í™œìš©í•´ í•µì‹¬ì  ê²½í–¥ì„ ë„ì¶œí•´ì•¼ í•©ë‹ˆë‹¤:

1ï¸âƒ£ **í†µê³„ ë¶„ì„ ê²°ê³¼(ft_test_summary)**: ì–´ë–¤ ëŒ€ë¶„ë¥˜(row)ê°€ í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ì°¨ì´ë¥¼ ë³´ì˜€ëŠ”ì§€ ì•Œë ¤ì¤ë‹ˆë‹¤.
2ï¸âƒ£ **ì¤‘ìš” ë³€ìˆ˜(anchor)**: ì–´ë–¤ column(í•­ëª©)ì´ ì‘ë‹µìì˜ ì „ì²´ ì‘ë‹µì—ì„œ ê°€ì¥ íˆ¬í‘œìœ¨ì´ ë†’ì€ í•­ëª©ì¸ì§€ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.

---

ğŸ“ ì„¤ë¬¸ ì¡°ì‚¬ ì§ˆë¬¸:
{selected_question}

ğŸ“Š í‘œ ë°ì´í„° (ì„ í˜•í™”ëœ í˜•íƒœ):
{linearized_table}

ğŸ“ˆ ì£¼ìš” í•­ëª© (ë³€ìˆ˜ë“¤ ì¤‘ ê°€ì¥ íˆ¬í‘œìœ¨ì´ ë†’ì€ ë³€ìˆ˜):
{anchor}

ğŸ“ˆ í†µê³„ ë¶„ì„ ê²°ê³¼ (í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ëŒ€ë¶„ë¥˜):
{ft_test_summary}

---

âš ï¸ ì°¸ê³ : ë§Œì•½ í†µê³„ ë¶„ì„ ê²°ê³¼ê°€ ì¡´ì¬í•˜ì§€ ì•Šê±°ë‚˜ ì‚¬ìš©ìê°€ ë¶„ì„ì„ ì§„í–‰í•˜ì§€ ì•Šê¸°ë¡œ ì„ íƒí•œ ê²½ìš°, ì£¼ìš” í•­ëª©(anchor)ì„ ì¤‘ì‹¬ìœ¼ë¡œ ê²½í–¥ì„ íŒŒì•…í•˜ê³  ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìš”ì•½í•  ê²ƒ.

Let's think step by step.

ğŸ¯ ë¶„ì„ ë° ìš”ì•½ ì§€ì¹¨:
1. ë°˜ë“œì‹œ **F/T test ê²°ê³¼ì—ì„œ í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ëŒ€ë¶„ë¥˜ë§Œì„ ì¤‘ì‹¬ìœ¼ë¡œ ë¶„ì„**í•  ê²ƒ (p-value < 0.05, ìœ ì˜ì„± ë³„(*) ì¡´ì¬)
2. ëª¨ë“  ëŒ€ë¶„ë¥˜ / ì†Œë¶„ë¥˜ë¥¼ ë‚˜ì—´í•˜ì§€ ë§ê³ , **í†µê³„ ë¶„ì„ ê²°ê³¼**ì—ì„œ ì°¨ì´ê°€ í¬ê³  ì˜ë¯¸ ìˆëŠ” ëŒ€ë¶„ë¥˜ë§Œ ì„ íƒì ìœ¼ë¡œ ì–¸ê¸‰í•  ê²ƒ
    - í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ëŒ€ë¶„ë¥˜ê°€ ì—†ì„ ê²½ìš° (ìœ ì˜ì„± ë³„(*)ê°€ ì—†ì„ ê²½ìš°) ì£¼ì–´ì§„ p-valueê°€ ì‘ì€ ëŒ€ë¶„ë¥˜ì—ì„œ ì£¼ìš” í•­ëª©ì— í¬í•¨ë˜ëŠ” ëŒ€ë¶„ë¥˜ë§Œ ì–¸ê¸‰í•  ê²ƒ
3. **ì ˆëŒ€ í•´ì„í•˜ì§€ ë§ ê²ƒ**. ìˆ˜ì¹˜ì  ì°¨ì´ì— ëŒ€í•œ ì¸ê³¼ í•´ì„(ì˜ˆ: ê±´ê°•ì— ë¯¼ê°í•´ì„œ, ì£¼ë³€ì— ìˆì–´ì„œ ë“±)ì€ ëª¨ë‘ **ê¸ˆì§€**í•¨
4. ì™¸ë¶€ ë°°ê²½ì§€ì‹, ì£¼ê´€ì  ì¶”ë¡ , í•´ì„ì  ì–¸ê¸‰ì€ ì ˆëŒ€ ê¸ˆì§€. í‘œë¡œë¶€í„° ì§ì ‘ **í™•ì¸ ê°€ëŠ¥í•œ ì‚¬ì‹¤ë§Œ ì„œìˆ **í•  ê²ƒ
5. ìˆ˜ì¹˜ ê¸°ë°˜ ê²½í–¥ì„ ë‹¤ìŒê³¼ ê°™ì€ í˜•ì‹ìœ¼ë¡œ ì„œìˆ í•˜ë©° ìŒìŠ´ì²´ë¡œ ì‘ì„±í•  ê²ƒ (ì˜ˆ: ~í–ˆìŒ, ~ë¡œ ë‚˜íƒ€ë‚¬ìŒ):
   - ìƒëŒ€ì ìœ¼ë¡œ ë” ë†’ì€ ê²½í–¥ ë³´ì˜€ìŒ
   - ë‚®ì€ ê°’ì„ ë‚˜íƒ€ëƒˆìŒ
6. ë¬¸ì¥ ê°„ ì—°ê²°ì–´ë¥¼ í™œìš©í•´ ìì—°ìŠ¤ëŸ½ê²Œ ì„œìˆ í•˜ê³ , ë„ˆë¬´ ë‹¨ì¡°ë¡­ê±°ë‚˜ ë°˜ë³µì ì¸ í‘œí˜„ (~í–ˆìŒ. ~í–ˆìŒ.)ì€ ì—°ì†ì ìœ¼ë¡œ ì‚¬ìš©í•˜ì§€ ë§ ê²ƒ
7. **ìœ ì˜ì„±ì´ ì—†ê±°ë‚˜, ê²€ì •ì—ì„œ ì œì™¸ëœ í•­ëª©ì€ ì ˆëŒ€ ì–¸ê¸‰í•˜ì§€ ë§ ê²ƒ**
8. ëª¨ë“  ëŒ€ë¶„ë¥˜ê°€ ìœ ì˜ì„±ì´ ìˆê³  ì¤‘ìš”í•˜ë‹¤ë©´ ëª¨ë“  ë³€ìˆ˜ì— ëŒ€í•´ ì„¤ëª…í•˜ì§€ ë§ê³ , **ëª¨ë“  ëŒ€ë¶„ë¥˜ë“¤ì´ ì¤‘ìš”í–ˆë‹¤ê³ ë§Œ ì–¸ê¸‰**í•  ê²ƒ
9. **íŠ¹ì • ëŒ€ë¶„ë¥˜ê°€ ê°€ì¥ ë‘ë“œëŸ¬ì§„ ì°¨ì´ë¥¼ ë³´ì˜€ì„ ê²½ìš°**, í•´ë‹¹ ê²½í–¥ì„ ê°•ì¡°í•  ê²ƒ
10. ìˆ«ìê°’ì„ ì§ì ‘ ì“°ì§€ ë§ê³  ìƒëŒ€ì ì¸ ê²½í–¥ë§Œ ì–¸ê¸‰í•  ê²ƒ
""",
        "English": """
You are a data analyst summarizing trends across population groups based on statistical data.
You must integrate the following two pieces of information to identify key patterns:

1ï¸âƒ£ **Statistical Test Results (ft_test_summary)**: indicates which row groups (categories) showed statistically significant differences
2ï¸âƒ£ **Key Variables (anchor)**: columns (features) that had the highest overall selection rate among respondents

---

ğŸ“ Survey Question:
{selected_question}

ğŸ“Š Table Data (Linearized):
{linearized_table}

ğŸ“ˆ Key Variables (most frequently selected):
{anchor}

ğŸ“ˆ Statistical Test Results (significant groups):
{ft_test_summary}

---

âš ï¸ Note: If there are no statistical results or if the user has opted out of statistical analysis, summarize based on key variables (anchor) and observed trends around them.

Let's think step by step.

ğŸ¯ Guidelines for Analysis and Summary:
1. Focus only on row groups that are statistically significant (p-value < 0.05, marked with asterisk)
2. Do not list all groups/subgroups; highlight only those with major, meaningful differences
    - If there are no statistically significant categories (if there are no significant stars (*)), only mention the categories included in the main items with small p-values.
3. **Do not interpret causality** (e.g., due to health sensitivity, etc.) â€“ strictly prohibited
4. No external knowledge or speculation â€“ write only what is verifiable from the table
5. Describe trends using expressions like:
   - Showed relatively higher trend
   - Showed lower values
6. Write in bullet-style declarative tone (e.g., â€œ~was observedâ€, â€œ~was shownâ€)
7. Use transition words to make the sentences flow naturally; avoid repetitive sentence endings
8. **Do not mention non-significant or excluded categories**
9. **If a particular group showed the strongest difference**, emphasize it
10. Do not mention actual numerical values, only describe relative trends
"""
    }
    HALLUCINATION_CHECK_PROMPT = {
        "í•œêµ­ì–´": """
ë‹¹ì‹ ì€ í†µê³„ í•´ì„ ê²°ê³¼ë¥¼ ê²€ì¦í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì•„ë˜ì˜ í…Œì´ë¸” ë°ì´í„°ì™€ ìˆ˜ì¹˜ ë¶„ì„ ê²°ê³¼(F/T-test ê¸°ë°˜), ê·¸ë¦¬ê³  í•´ë‹¹ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‘ì„±ëœ ìš”ì•½ ë³´ê³ ì„œê°€ ì£¼ì–´ì§‘ë‹ˆë‹¤.

ğŸ“ ì„¤ë¬¸ ë¬¸í•­:
{selected_question}

ğŸ“Š ì„ í˜•í™”ëœ í…Œì´ë¸”:
{linearized_table}

ğŸ“ˆ ìˆ˜ì¹˜ ë¶„ì„ ê²°ê³¼ (F/T-test ê²°ê³¼ ìš”ì•½):
{ft_test_summary}

ğŸ§¾ ìƒì„±ëœ ìš”ì•½:
{table_analysis}

---

ì´ ìš”ì•½ì´ ìœ„ì˜ ìˆ˜ì¹˜ ë¶„ì„ ê²°ê³¼ë¥¼ **ì •í™•í•˜ê³  ì¼ê´€ì„± ìˆê²Œ** ë°˜ì˜í•˜ê³  ìˆëŠ”ì§€ í‰ê°€í•´ì£¼ì„¸ìš”.

âš ï¸ ì£¼ì˜ ì‚¬í•­ (ìœ„ë°˜ ì‹œ ìš°ì„  í”¼ë“œë°± ì œê³µ, ì‹¬ê°í•œ ì™œê³¡ì— í•œí•´ reject):
1. F/T-testì—ì„œ í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ì°¨ì´ê°€ í™•ì¸ëœ ëŒ€ë¶„ë¥˜ê°€ ìš”ì•½ì— ì–¸ê¸‰ë˜ì§€ ì•Šì€ ê²½ìš°
2. ìœ ì˜ë¯¸í•œ ì°¨ì´ê°€ í™•ì¸ëœ ëŒ€ë¶„ë¥˜ì—ì„œì˜ ì£¼ìš” ê²½í–¥ì´ë‚˜ ìˆ˜ì¹˜ ê²°ê³¼ê°€ ì™œê³¡ë˜ì–´ í•´ì„ëœ ê²½ìš° (e.g. ë” ë†’ì§€ ì•Šì€ë° ë” ë†’ë‹¤ê³  ì˜ëª» ëœ ì£¼ì¥ì„ í•˜ëŠ” ê²½ìš°)

ğŸ¯ í‰ê°€ ë°©ì‹:
- ìš”ì•½ì´ ì „ì²´ì ìœ¼ë¡œ ì‹ ë¢°í•  ë§Œí•˜ê³  í†µê³„ ê²°ê³¼ë¥¼ ì˜ ë°˜ì˜í•˜ë©´ "accept"
- ìœ„ í•­ëª© ìœ„ë°˜ ì‹œ "reject: [ì´ìœ ]" í˜•ì‹ìœ¼ë¡œ ì¶œë ¥

â€» F/T-test ê²°ê³¼ëŠ” ì¤‘ìš”í•œ ê¸°ì¤€ì´ì§€ë§Œ, ì‚¬ì†Œí•œ ëˆ„ë½ì€ reject ëŒ€ì‹  í”¼ë“œë°±ìœ¼ë¡œ ì²˜ë¦¬í•´ë„ ë©ë‹ˆë‹¤. ëª…ë°±í•œ ì™œê³¡ì´ë‚˜ ì¤‘ëŒ€í•œ ëˆ„ë½ ì‹œì—ë§Œ reject í•˜ì„¸ìš”.
""",
        "English": """
You are a statistical analysis auditor.

Below is a statistical summary table (linearized format), F/T-test results, and a summary report written based on them.

ğŸ“ Survey question:
{selected_question}

ğŸ“Š Linearized Table:
{linearized_table}

ğŸ“ˆ Statistical Test Summary (F/T-test):
{ft_test_summary}

ğŸ§¾ Generated Summary Report:
{table_analysis}

---

Please evaluate whether the summary accurately and consistently reflects the statistical test results above.

âš ï¸ Evaluation Guidelines (Provide feedback first. Only reject in cases of serious distortion):
1. If a major category with statistically significant difference is missing in the summary
2. If the key trends or directions are misinterpreted (e.g. stating itâ€™s higher when it isnâ€™t)

ğŸ¯ Evaluation Instructions:
- If the summary is overall reliable and reflects the results well, answer "accept"
- If any violations occur, return: "reject: [reason]"

â€» F/T-test is a key basis, but minor omissions can be handled with feedback only. Use "reject" only for clear distortions or major omissions.
"""
    }
    REVISION_PROMPT = {
        "í•œêµ­ì–´": """
ë‹¹ì‹ ì€ í†µê³„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¸êµ¬ì§‘ë‹¨ ê°„ íŒ¨í„´ê³¼ ê²½í–¥ì„±ì„ ê°ê´€ì ìœ¼ë¡œ ìš”ì•½í•˜ëŠ” ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì•„ë˜ëŠ” í…Œì´ë¸” ë¶„ì„ ê²°ê³¼ì— ëŒ€í•´ ì¼ë¶€ ì˜ëª»ëœ í•´ì„ì´ í¬í•¨ëœ ìš”ì•½ì…ë‹ˆë‹¤. í”¼ë“œë°±ê³¼ ì‚¬ì „ì— ìƒì„±ëœ ê°€ì„¤ì„ ì°¸ê³ í•˜ì—¬ ì˜ëª»ëœ ë‚´ìš©ì„ ì œê±°í•˜ê³ , ì›ë³¸ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìˆ˜ì¹˜ ê¸°ë°˜ì˜ ê°ê´€ì  ë¶„ì„ì„ ë‹¤ì‹œ ì‘ì„±í•  ê²ƒ.

ğŸ“Š í‘œ ë°ì´í„° (ì„ í˜•í™”ëœ í˜•íƒœ):
{linearized_table}

ğŸ“ˆ ì£¼ìš” í•­ëª© (ë³€ìˆ˜ë“¤ ì¤‘ ê°€ì¥ íˆ¬í‘œìœ¨ì´ ë†’ì€ ë³€ìˆ˜):
{anchor}

ğŸ“ˆ í†µê³„ ë¶„ì„ ê²°ê³¼ (í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ëŒ€ë¶„ë¥˜):
{ft_test_summary}

ğŸ“ Rejectëœ ë³´ê³ ì„œ (ìˆ˜ì •í•´ì•¼í•  ë³´ê³ ì„œ):
{report_to_modify}

â— í”¼ë“œë°± (ìˆ˜ì •ì´ í•„ìš”í•œ ì´ìœ  ë˜ëŠ” ì˜ëª»ëœ ë¶€ë¶„):
{feedback}

---

Let's think step by step

ğŸ¯ ìˆ˜ì • ë° ì¬ì‘ì„± ì§€ì¹¨:

1. ë°˜ë“œì‹œ **F/T test ê²°ê³¼ì—ì„œ í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ëŒ€ë¶„ë¥˜ë§Œì„ ì¤‘ì‹¬ìœ¼ë¡œ ë¶„ì„**í•  ê²ƒ (p-value < 0.05, ìœ ì˜ì„± ë³„(*) ì¡´ì¬)
2. ëª¨ë“  ëŒ€ë¶„ë¥˜ / ì†Œë¶„ë¥˜ë¥¼ ë‚˜ì—´í•˜ì§€ ë§ê³ , **ê²€ì • ê²°ê³¼ì—ì„œ ì°¨ì´ê°€ í¬ê³  ì˜ë¯¸ ìˆëŠ” ëŒ€ë¶„ë¥˜ë§Œ ì„ íƒì ìœ¼ë¡œ ì–¸ê¸‰**í•  ê²ƒ
3. **ì ˆëŒ€ í•´ì„í•˜ì§€ ë§ ê²ƒ**. ìˆ˜ì¹˜ì  ì°¨ì´ì— ëŒ€í•œ ì¸ê³¼ í•´ì„(ì˜ˆ: ê±´ê°•ì— ë¯¼ê°í•´ì„œ, ì£¼ë³€ì— ìˆì–´ì„œ ë“±)ì€ ëª¨ë‘ ê¸ˆì§€í•¨
4. ì™¸ë¶€ ë°°ê²½ì§€ì‹, ì£¼ê´€ì  ì¶”ë¡ , í•´ì„ì  ì–¸ê¸‰ì€ ì ˆëŒ€ ê¸ˆì§€. **í‘œë¡œë¶€í„° ì§ì ‘ í™•ì¸ ê°€ëŠ¥í•œ ì‚¬ì‹¤ë§Œ ì„œìˆ **í•  ê²ƒ
5. ìˆ˜ì¹˜ ê¸°ë°˜ ê²½í–¥ì„ ë‹¤ìŒê³¼ ê°™ì€ í˜•ì‹ìœ¼ë¡œ ì„œìˆ í•  ê²ƒ:
   - ìƒëŒ€ì ìœ¼ë¡œ ë” ë†’ì€ ê²½í–¥ ë³´ì˜€ìŒ
   - ë‚®ì€ ê°’ì„ ë‚˜íƒ€ëƒˆìŒ
6. ë³´ê³ ì„œ ìŒìŠ´ì²´ë¡œ ì‘ì„±í•  ê²ƒ (ì˜ˆ: ~í–ˆìŒ, ~ë¡œ ë‚˜íƒ€ë‚¬ìŒ)
7. ë¬¸ì¥ ê°„ ì—°ê²°ì–´ë¥¼ í™œìš©í•´ ìì—°ìŠ¤ëŸ½ê²Œ ì„œìˆ í•˜ê³ , ë„ˆë¬´ ë‹¨ì¡°ë¡­ê±°ë‚˜ ë°˜ë³µì ì¸ í‘œí˜„ (~í–ˆìŒ. ~í–ˆìŒ.)ì€ í”¼í•  ê²ƒ
8. **ìœ ì˜ì„±ì´ ì—†ê±°ë‚˜, ê²€ì •ì—ì„œ ì œì™¸ëœ í•­ëª©ì€ ì ˆëŒ€ ì–¸ê¸‰í•˜ì§€ ë§ ê²ƒ**
9. **íŠ¹ì • ëŒ€ë¶„ë¥˜ê°€ ê°€ì¥ ë‘ë“œëŸ¬ì§„ ì°¨ì´ë¥¼ ë³´ì˜€ì„ ê²½ìš°**, í•´ë‹¹ ê²½í–¥ì„ ê°•ì¡°í•  ê²ƒ
10. ìˆ«ìê°’ì„ ì§ì ‘ ì“°ì§€ ë§ê³  ìƒëŒ€ì ì¸ ê²½í–¥ë§Œ ì–¸ê¸‰í•  ê²ƒ
11. ì´ì „ ìˆ˜ì • ë²„ì „ì˜ ë¬¸ì¥ í‘œí˜„ì„ ì¬ì‚¬ìš©í•˜ì§€ ì•Šê³ , ìƒˆë¡œìš´ ì–´íœ˜ì™€ êµ¬ì¡°ë¡œ ì‘ì„±í•  ê²ƒ
12. ì¶”ë¡  ê³¼ì •ì„ ì‘ì„±í•˜ì§€ ë§ê³  ìµœì¢…ì ìœ¼ë¡œ ìˆ˜ì •í•œ ë³´ê³ ì„œë§Œ ì¶œë ¥í•˜ì„¸ìš”.
""",
        "English": """
You are a data analyst who objectively summarizes population-level patterns based on statistical data.

Below is a summary that contains partially incorrect interpretations of a statistical table analysis. Based on the given feedback and hypotheses, revise the summary by removing inaccurate parts and rewrite a new objective analysis grounded in the data.

ğŸ“Š Table data (linearized):
{linearized_table}

ğŸ“ˆ Key variables (most selected):
{anchor}

ğŸ“ˆ Statistical analysis results (significant categories):
{ft_test_summary}

ğŸ“ Rejected summary (needs revision):
{report_to_modify}

â— Feedback (reason for revision or incorrect points):
{feedback}

---

Let's think step by step

ğŸ¯ Revision Guidelines:

1. Focus only on categories that showed statistically significant differences in the F/T test (p-value < 0.05, marked with *)
2. Do not list all categories/subcategories; mention only those with meaningful differences
3. **Do not provide causal interpretations** â€“ explanations like â€œdue to health concernsâ€ or similar are prohibited
4. No external knowledge or speculation â€“ write only what is verifiable from the table
5. Describe trends in a form such as:
   - Showed relatively higher trend
   - Showed lower values
6. Write in bullet-style declarative tone (e.g., â€œ~was observedâ€, â€œ~was shownâ€)
7. Use transition words to make the sentences flow naturally; avoid repetitive sentence endings
8. **Do not mention non-significant or excluded categories**
9. **If a particular group showed the strongest difference**, emphasize it
10. Do not explain the reasoning â€“ only output the final revised summary
"""
    }
    POLISHING_PROMPT = {
        "í•œêµ­ì–´": """
ë‹¹ì‹ ì€ í†µê³„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‘ì„±ëœ í•œêµ­ì–´ ë³´ê³ ì„œë¥¼ ë‹¤ë“¬ëŠ” ë¬¸ì²´ ì „ë¬¸ ì—ë””í„°ì…ë‹ˆë‹¤.

ì•„ë˜ëŠ” í†µê³„ ë¶„ì„ ê²°ê³¼ë¥¼ ìš”ì•½í•œ ì´ˆì•ˆì…ë‹ˆë‹¤.  
ë¬¸ì¥ì´ ë‹¨ì ˆì ì´ê±°ë‚˜(~í–ˆìŒ. ~í–ˆìŒ ë°˜ë³µ), í‘œí˜„ì´ ì¤‘ë³µë˜ê±°ë‚˜, ë¶ˆí•„ìš”í•œ ì¸ì‚¬ì´íŠ¸ê°€ í¬í•¨ë˜ì–´ ìˆë‹¤ë©´, **ì˜ë¯¸ë¥¼ ë³€ê²½í•˜ì§€ ì•Šê³ ** ë” ì½ê¸° ì‰¬ìš´ ë¬¸ì¥ìœ¼ë¡œ ë‹¤ë“¬ìœ¼ì„¸ìš”.

ğŸ¯ ë‹¤ìŒ ì§€ì¹¨ì„ ì—„ê²©íˆ ë”°ë¥´ì„¸ìš”:

1. **ë‚´ìš© ì¶”ê°€, ì‚­ì œ ê¸ˆì§€** â€” ìˆ˜ì¹˜ ê¸°ë°˜ì˜ ì›ë¬¸ ì •ë³´ì—ì„œ ë²—ì–´ë‚˜ëŠ” ìƒˆë¡œìš´ í•´ì„, ë°°ê²½ ì„¤ëª…, ì¸ê³¼ê´€ê³„ ìœ ì¶”ëŠ” ëª¨ë‘ ê¸ˆì§€
2. **'ìŒìŠ´ì²´' ìŠ¤íƒ€ì¼ ìœ ì§€** â€” ì˜ˆ: ~í–ˆìŒ, ~ë¡œ ë‚˜íƒ€ë‚¬ìŒ
3. **ì¸ì‚¬ì´íŠ¸ ì œê±°** â€” â€˜ê±´ê°•ì— ë¯¼ê°í•´ì„œâ€™, â€˜ì§ì ‘ ì˜í–¥ì„ ë°›ì•„ì„œâ€™ ë“± ì£¼ê´€ì  ì¶”ë¡ ì€ ëª¨ë‘ ì œê±°í•˜ê³ , í‘œë¡œë¶€í„° ë“œëŸ¬ë‚˜ëŠ” ì‚¬ì‹¤ë§Œ ìœ ì§€
4. **í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•œ í•­ëª©(ë³„í‘œ í¬í•¨ëœ ëŒ€ë¶„ë¥˜)**ë§Œ ë¬¸ì¥ì— í¬í•¨ë˜ì—ˆëŠ”ì§€ í™•ì¸í•  ê²ƒ
5. **ì¤‘ë³µ í‘œí˜„ ì œê±° ë° ì—°ê²°** â€” ë™ì¼ ì˜ë¯¸ì˜ í‘œí˜„ ë°˜ë³µ("ë†’ê²Œ ë‚˜íƒ€ë‚¬ìŒ", "ê´€ì‹¬ì´ ë†’ì•˜ìŒ")ì€ í”¼í•˜ê³  ì—°ê²°ì–´ë¥¼ í†µí•´ ê°„ê²°í•˜ê²Œ ì •ë¦¬
6. **ë‹¨ì¡°ë¡œìš´ ë‚˜ì—´ í”¼í•˜ê¸°** â€” ~í–ˆìŒ. ~í–ˆìŒ. ë°˜ë³µí•˜ì§€ ë§ê³ , ë¬¸ì¥ êµ¬ì¡°ë¥¼ ë‹¤ì–‘í™”í•˜ê³  ì—°ê´€ëœ í•­ëª©ì€ í•œ ë¬¸ì¥ìœ¼ë¡œ ë¬¶ê¸°
7. **ë‹¤ì–‘í•œ í‘œí˜„ í˜¼ìš©** â€” ì•„ë˜ì™€ ê°™ì€ í‘œí˜„ì„ ì ì ˆíˆ ì„ì–´ ì‚¬ìš©í•  ê²ƒ:
   - ë‘ë“œëŸ¬ì§„ ê²½í–¥ ë³´ì˜€ìŒ
   - ëšœë ·í•œ ì°¨ì´ë¥¼ ë‚˜íƒ€ëƒˆìŒ
   - ìƒëŒ€ì ìœ¼ë¡œ ë†’ì€ ê°’ì„ ë³´ì˜€ìŒ
   - ê°€ì¥ ë†’ê²Œ í™•ì¸ëìŒ
8. **ë¶ˆí•„ìš”í•œ ì†Œë¶„ë¥˜ ë˜ëŠ” ëª¨ë“  ê·¸ë£¹ ë‚˜ì—´ ê¸ˆì§€** â€” ìš”ì•½ì€ íŠ¹ì§•ì ì¸ ê·¸ë£¹ ì¤‘ì‹¬ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ì‘ì„±í•  ê²ƒ
9. **í‘œ ê¸°ë°˜ ì‚¬ì‹¤ë§Œ ìš”ì•½** â€” ìˆ˜ì¹˜ ê¸°ë°˜ ê²½í–¥ë§Œ ì „ë‹¬í•˜ê³ , í•´ì„ì€ í¬í•¨í•˜ì§€ ë§ ê²ƒ
10. í†µê³„ ë¶„ì„ ê²°ê³¼, ì„±ë³„ê³¼ ì—°ë ¹ëŒ€ì—ì„œ í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ì°¨ì´ë¥¼ ë³´ì˜€ìŒ. ì´ëŸ¬í•œ ë¬¸ì¥ì²˜ëŸ¼ í†µê³„ ë¶„ì„ ê²°ê³¼ë¥¼ ì§ì ‘ ì–¸ê¸‰í•˜ì§€ ë§ ê²ƒ. í‘œì— ë‚˜íƒ€ë‚œ ìˆ˜ì¹˜ ê¸°ë°˜ì˜ ê²½í–¥ë§Œ ì–¸ê¸‰í•  ê²ƒ.

ì•„ë˜ì˜ ê¸°ì¡´ ìš”ì•½ ì¤‘ì—ì„œ ìœ„ì˜ ì§€ì¹¨ì—ì„œ ì–´ê¸‹ë‚˜ëŠ” ë¬¸ì¥ì´ ìˆë‹¤ë©´ ì§€ì¹¨ì„ ë”°ë¥´ë„ë¡ ìˆ˜ì •í•˜ì„¸ìš”. í•˜ì§€ë§Œ, ê¸°ì¡´ ìš”ì•½ì—ì„œ ì œê³µí•˜ëŠ” ê°’ë“¤ì€ ê·¸ëŒ€ë¡œ ìœ ì§€í•  ê²ƒ.

ğŸ“ ê¸°ì¡´ ìš”ì•½:
{raw_summary}

---

ğŸ¯ ë‹¤ë“¬ì–´ì§„ ìµœì¢… ìš”ì•½ë¬¸:
""",
        "English": """
You are a stylistic editor for statistical summaries written in Korean.

Below is a draft summary of a statistical analysis.  
If the sentences are too choppy ("~í–ˆìŒ. ~í–ˆìŒ." repetition), redundant, or include subjective insights, rewrite them into a more readable style **without altering their meaning**.

ğŸ¯ Strictly follow these instructions:

1. **No additions or deletions** â€” Do not add new interpretations, background, or causal reasoning beyond the original numeric-based content.
2. **Keep declarative tone** â€” Use styles like: "~was observed", "~was shown"
3. **Remove speculative insights** â€” Phrases like â€œdue to health concernsâ€ or â€œbecause they were affectedâ€ must be removed; stick only to observable facts
4. **Only include categories with statistical significance (asterisked)** in the report
5. **Eliminate and connect duplicates** â€” Avoid repeating the same idea (e.g., â€œwas highâ€, â€œinterest was highâ€); connect with transitions
6. **Avoid monotonous structure** â€” Donâ€™t repeat "~was observed." repeatedly; vary structure and combine related findings into single sentences
7. **Use varied expressions** â€” Mix in phrases like:
   - Showed notable trend
   - Displayed clear difference
   - Exhibited relatively high values
   - Recorded the highest
8. **Avoid listing all subgroups** â€” Focus on concise summaries of characteristic groups
9. **Only report table-based facts** â€” Do not include interpretations; describe numeric trends only

ğŸ“ Original draft:
{raw_summary}

---

ğŸ¯ Polished final summary:
"""
    }
    def __init__(self):
        self.llm = ChatOpenAI(
            model="gpt-4o-mini",
            temperature=0.3,
            api_key=os.getenv("OPENAI_API_KEY")
        )
    
    def normalize_key(self, key: str) -> str:
        """í‚¤ ì •ê·œí™”"""
        return key.strip().replace(' ', '').replace('-', '').replace('_', '').replace('.', '').upper()
    
    def find_matching_key(self, target_key: str, available_keys: List[str]) -> Optional[str]:
        """í‚¤ ë§¤ì¹­ ì°¾ê¸°"""
        normalized_target = self.normalize_key(target_key)
        
        # ì •í™•í•œ ë§¤ì¹­
        for key in available_keys:
            if self.normalize_key(key) == normalized_target:
                return key
        
        # í¬í•¨ ê´€ê³„ ë§¤ì¹­
        for key in available_keys:
            normalized_key = self.normalize_key(key)
            if normalized_key in normalized_target or normalized_target in normalized_key:
                return key
        
        # ìœ ì‚¬ë„ ê¸°ë°˜ ë§¤ì¹­ (Levenshtein distance)
        best_match = None
        best_score = float('inf')
        
        for key in available_keys:
            normalized_key = self.normalize_key(key)
            distance = self.levenshtein_distance(normalized_target, normalized_key)
            max_length = max(len(normalized_target), len(normalized_key))
            similarity = distance / max_length
            
            if similarity < 0.3 and similarity < best_score:
                best_match = key
                best_score = similarity
        
        return best_match
    
    def levenshtein_distance(self, str1: str, str2: str) -> int:
        """Levenshtein ê±°ë¦¬ ê³„ì‚°"""
        matrix = [[0] * (len(str2) + 1) for _ in range(len(str1) + 1)]
        
        for i in range(len(str1) + 1):
            matrix[i][0] = i
        
        for j in range(len(str2) + 1):
            matrix[0][j] = j
        
        for i in range(1, len(str1) + 1):
            for j in range(1, len(str2) + 1):
                if str1[i-1] == str2[j-1]:
                    matrix[i][j] = matrix[i-1][j-1]
                else:
                    matrix[i][j] = min(
                        matrix[i-1][j-1] + 1,
                        matrix[i][j-1] + 1,
                        matrix[i-1][j] + 1
                    )
        
        return matrix[len(str1)][len(str2)]
    
    async def load_survey_tables(self, file_content: bytes, file_name: str, sheet_name: str = "í†µê³„í‘œ"):
        """ì„¤ë¬¸ í…Œì´ë¸” ë¡œë“œ - DataProcessorì˜ load_survey_tablesì™€ ë™ì¼í•˜ê²Œ ë™ì‘í•˜ë„ë¡ ìˆ˜ì •"""
        from utils.data_processor import DataProcessor
        data_processor = DataProcessor()
        return data_processor.load_survey_tables(file_content, file_name, sheet_name)
    
    def linearize_row_wise(self, table: pd.DataFrame) -> str:
        """í…Œì´ë¸”ì„ í–‰ ë‹¨ìœ„ë¡œ ì„ í˜•í™”"""
        if table is None or table.empty:
            return ""
        
        # ìˆ«ì ì»¬ëŸ¼ë§Œ ì„ íƒ
        numeric_cols = table.select_dtypes(include=[np.number]).columns.tolist()
        if not numeric_cols:
            return ""
        
        # ì²« ë²ˆì§¸ ì»¬ëŸ¼ (ê·¸ë£¹ëª…)ê³¼ ìˆ«ì ì»¬ëŸ¼ë“¤ë§Œ ì‚¬ìš©
        result_cols = [table.columns[0]] + numeric_cols
        result_df = table[result_cols]
        
        # í–‰ ë‹¨ìœ„ë¡œ ë¬¸ìì—´ ë³€í™˜
        rows = []
        for _, row in result_df.iterrows():
            row_str = " | ".join([str(val) for val in row.values])
            rows.append(row_str)
        
        return "\n".join(rows)
    
    async def make_openai_call(self, messages: List[Dict[str, str]], model: str = "gpt-4o-mini", temperature: float = 0.3) -> str:
        """OpenAI API í˜¸ì¶œ"""
        try:
            langchain_messages = []
            for msg in messages:
                if msg["role"] == "system":
                    langchain_messages.append(SystemMessage(content=msg["content"]))
                else:
                    langchain_messages.append(HumanMessage(content=msg["content"]))
            
            response = await self.llm.ainvoke(langchain_messages)
            return response.content.strip()
        except Exception as e:
            raise Exception(f"OpenAI API í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}")
    
    async def table_parser_node(self, state: AgentState, on_step=None) -> AgentState:
        """í…Œì´ë¸” íŒŒì„œ ë…¸ë“œ"""
        if on_step:
            on_step("ğŸ“Š í…Œì´ë¸” íŒŒì„œ ë…¸ë“œ ì‹œì‘")
        
        # íŒŒì¼ì—ì„œ í…Œì´ë¸” íŒŒì‹±
        if state.uploaded_file:
            parsed_data = await self.load_survey_tables(
                state.uploaded_file,
                state.file_path
            )
            state.tables = parsed_data["tables"]
            state.question_texts = parsed_data["question_texts"]
            state.question_keys = parsed_data["question_keys"]
        
        # ì„ íƒëœ í‚¤ ë§¤ì¹­
        if state.selected_key and state.tables:
            matching_key = self.find_matching_key(state.selected_key, list(state.tables.keys()))
            if matching_key:
                state.selected_key = matching_key
                state.selected_table = state.tables[matching_key]
                state.selected_question = state.question_texts[matching_key]
            elif state.analysis_type:
                raise Exception(f"ì„ íƒëœ ì§ˆë¬¸ í‚¤ '{state.selected_key}'ì— í•´ë‹¹í•˜ëŠ” í…Œì´ë¸”ì´ ì—†ìŠµë‹ˆë‹¤.")
            else:
                # ë°°ì¹˜ ë¶„ì„ì˜ ê²½ìš° ì²« ë²ˆì§¸ ì§ˆë¬¸ ì‚¬ìš©
                state.selected_key = state.question_keys[0]
                state.selected_table = state.tables[state.selected_key]
                state.selected_question = state.question_texts[state.selected_key]
        
        # í…Œì´ë¸” ì„ í˜•í™”
        if state.selected_table is not None:
            state.linearized_table = self.linearize_row_wise(state.selected_table)
        
        return state
    
    async def hypothesis_generate_node(self, state: AgentState, on_step=None) -> AgentState:
        """ê°€ì„¤ ìƒì„± ë…¸ë“œ (Streamlit ë¡œì§ ë°˜ì˜)"""
        if on_step:
            on_step("ğŸ’¡ ê°€ì„¤ ìƒì„± ë…¸ë“œ ì‹œì‘")

        selected_table = state.selected_table
        selected_question = state.selected_question
        lang = state.lang if hasattr(state, 'lang') else "í•œêµ­ì–´"

        # rowì™€ column name ì¶”ì¶œ (Streamlit ë°©ì‹)
        import pandas as pd
        if selected_table is not None and isinstance(selected_table, pd.DataFrame):
            if "ëŒ€ë¶„ë¥˜" in selected_table.columns and "ì†Œë¶„ë¥˜" in selected_table.columns:
                selected_table = selected_table.copy()
                selected_table["row_name"] = selected_table["ëŒ€ë¶„ë¥˜"].astype(str) + "_" + selected_table["ì†Œë¶„ë¥˜"].astype(str)
                row_names = selected_table["row_name"].dropna().tolist()
            else:
                row_names = list(selected_table.index)
            column_names = list(selected_table.columns)
        else:
            row_names = []
            column_names = []

        row_names_str = ", ".join(map(str, row_names))
        column_names_str = ", ".join(map(str, column_names))

        # í”„ë¡¬í”„íŠ¸ ì •ì˜ (Streamlitê³¼ ë™ì¼)
        HYPOTHESIS_PROMPT = {
            "í•œêµ­ì–´": """
ë‹¹ì‹ ì€ í†µê³„ ë°ì´í„°ë¥¼ í•´ì„í•˜ëŠ” ë°ì´í„° ê³¼í•™ìì…ë‹ˆë‹¤.
ì•„ë˜ëŠ” ë¶„ì„í•  í‘œì˜ rowëª… (index)ê³¼ columnëª…ì…ë‹ˆë‹¤.

row: {row_names}
column: {column_names}

ë‹¹ì‹ ì˜ ì„ë¬´ëŠ”, ì‚¬ìš©ìì˜ ì§ˆë¬¸ ("{selected_question}")ê³¼ ê´€ë ¨í•´  
ë°ì´í„°ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆì„ ë²•í•œ ê°€ì„¤(íŒ¨í„´, ê´€ê³„)ì„ 2~5ê°œ ì •ë„ ì œì•ˆí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

ì˜ˆì‹œ:
1. ì—°ë ¹ëŒ€ê°€ ë†’ì„ìˆ˜ë¡ ê´€ì‹¬ë„ê°€ ë†’ì„ ê²ƒì´ë‹¤.
2. ê¸°ì €ì§ˆí™˜ì´ ìˆëŠ” ê²½ìš° ê´€ì‹¬ë„ê°€ ë†’ì„ ê²ƒì´ë‹¤.

- ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ í•©ë¦¬ì ì¸ ê°€ì„¤ë§Œ ìƒì„±í•  ê²ƒ
- ì™¸ë¶€ ì§€ì‹ì€ ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€
- ë¬¸ì¥ ê¸¸ì´ëŠ” ì§§ê³ , ë²ˆí˜¸ ë¦¬ìŠ¤íŠ¸ë¡œ ì‘ì„±
""",
            "English": """
You are a data scientist interpreting statistical tables.
Below are the row names (index) and column names of the table to be analyzed.

row: {row_names}
column: {column_names}

Your task is to propose 2 to 5 hypotheses (patterns or relationships) relevant to the user's question ("{selected_question}") that could be inferred from the data.

Example:
1. Older age groups may show higher interest.
2. Those with chronic illnesses may show higher concern.

- Only propose reasonable hypotheses based on the data
- Do not use external knowledge
- Keep sentences short and format as a numbered list
"""
        }

        prompt = HYPOTHESIS_PROMPT[lang].format(
            row_names=row_names_str,
            column_names=column_names_str,
            selected_question=selected_question
        )

        messages = [
            {"role": "system", "content": "ë‹¹ì‹ ì€ í†µê³„ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤." if lang == "í•œêµ­ì–´" else "You are a statistical analysis expert."},
            {"role": "user", "content": prompt}
        ]

        state.generated_hypotheses = await self.make_openai_call(messages)
        return state
    
    def rule_based_test_type_decision(self, question_text=""):
        """
        ì§ˆë¬¸ í…ìŠ¤íŠ¸ì— ë³µìˆ˜ì‘ë‹µ/ìˆœìœ„/ë‹¤ì¤‘ ë“± í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ manual, ì•„ë‹ˆë©´ None
        """
        multi_response_keywords = [
            "1+2", "1+2+3", "ë³µìˆ˜", "ë‹¤ì¤‘", "multiple", "rank", "ranking", "ìš°ì„ ìˆœìœ„", "ë³µìˆ˜ì‘ë‹µ", "ìˆœìœ„"
        ]
        text_to_check = question_text.lower()
        if any(keyword.lower() in text_to_check for keyword in multi_response_keywords):
            return "manual"
        return None

    async def decide_batch_test_types(self, question_infos, lang="í•œêµ­ì–´"):
        """
        ì „ì²´ ë¶„ì„ìš©: ì—¬ëŸ¬ ì§ˆë¬¸ì— ëŒ€í•´ í†µê³„ ê²€ì • ë°©ë²•ì„ ì¼ê´„ ê²°ì •í•˜ëŠ” í•¨ìˆ˜
        - ê° ì§ˆë¬¸ë³„ë¡œ ë³µìˆ˜ì‘ë‹µ/ì„ì˜(manual) ì—¬ë¶€ëŠ” rule-basedë¡œ íŒì •
        - ë³µìˆ˜ì‘ë‹µì´ ì•„ë‹Œ ì§ˆë¬¸ë“¤ì€ LLMì— í•œ ë²ˆì— í”„ë¡¬í”„íŠ¸ë¡œ ì „ë‹¬í•˜ì—¬ test_type(ft_test/chi_square) ê²°ì •
        - LLM ì‘ë‹µì„ íŒŒì‹±í•´ question_key -> test_type ë§¤í•‘ ë°˜í™˜
        Args:
            question_infos: List[dict] (ê° dict: {key, text, columns})
            lang: ì–¸ì–´ (default: í•œêµ­ì–´)
        Returns:
            Dict[str, str] (question_key -> test_type)
        """
        # 1. manual íŒì • (ë³µìˆ˜ì‘ë‹µ/ìˆœìœ„/ë‹¤ì¤‘ ë“± í‚¤ì›Œë“œ)
        manual_keys = set()
        non_manual_questions = []
        for q in question_infos:
            key, text, columns = q['key'], q['text'], q['columns']
            if self.rule_based_test_type_decision(text) == 'manual':
                manual_keys.add(key)
            else:
                non_manual_questions.append(q)
        # 2. LLM í”„ë¡¬í”„íŠ¸ ìƒì„± (ë³µìˆ˜ì‘ë‹µ ì•„ë‹Œ ì§ˆë¬¸ë“¤)
        prompt_lines = []
        for q in non_manual_questions:
            col_str = ', '.join(q['columns'])
            prompt_lines.append(f"{q['key']}: {col_str}")
        prompt_body = '\n'.join(prompt_lines)
        if lang == "í•œêµ­ì–´":
            prompt = f"""
            ì•„ë˜ëŠ” ì„¤ë¬¸ í†µê³„í‘œì˜ ê° ì§ˆë¬¸ë³„ ì—´ ì´ë¦„ ëª©ë¡ì…ë‹ˆë‹¤.
            
            ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” ê° ì§ˆë¬¸ì— ëŒ€í•´ **ê°€ì¥ ì í•©í•œ í†µê³„ ê²€ì • ë°©ë²•**(ft_test ë˜ëŠ” chi_square)ì„ ê²°ì •í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.
            
            - ft_test: í‰ê· , ì ìˆ˜, ë¹„ìœ¨ ë“± ì—°ì†í˜•(ìˆ˜ì¹˜í˜•) ë°ì´í„°ì— ì í•©
            - chi_square: í•­ëª© ì„ íƒ, ë‹¤ì¤‘ì‘ë‹µ ë“± ë²”ì£¼í˜•(ì„ íƒí˜•) ë°ì´í„°ì— ì í•©
            
            ì•„ë˜ ê¸°ì¤€ì„ ì°¸ê³ í•˜ì„¸ìš”:
            - ì—´ ì´ë¦„ì— 'í‰ê· ', 'ì ìˆ˜', '%', 'ë¹„ìœ¨' ë“±ì´ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ft_test
            - í•­ëª© ì„ íƒ, ë‹¤ì¤‘ì‘ë‹µ, ë²”ì£¼í˜• ì„ íƒì§€ë©´ chi_square
            
            ì•„ë˜ì™€ ê°™ì€ í˜•ì‹ìœ¼ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”(ì„¤ëª… ì—†ì´):
            
            ì˜ˆì‹œ:
            Q1: ft_test
            Q2: chi_square
            Q3: ft_test
            
            ì§ˆë¬¸ë³„ ì—´ ëª©ë¡:
            {prompt_body}
            
            ë‹µë³€ í˜•ì‹:
            Q1: ft_test
            Q2: chi_square
            ...
            """
        else:
            prompt = f"""
            Below are the column headers for each survey question.
        
            Your task is to determine the **most appropriate statistical test type** (ft_test or chi_square) for each question.
            
            - ft_test: Use for continuous/numeric data (mean, score, %, ratio, etc.)
            - chi_square: Use for categorical/choice/multiple response data
            
            Guidelines:
            - If column names include 'mean', 'score', '%', 'ratio', etc. â†’ ft_test
            - If the question is about selecting items, multiple responses, or categorical choices â†’ chi_square
            - If the question is multiple response/ranking, use 'manual' (already auto-classified)
            
            Please answer in the following format (no explanation):
            
            Example:
            Q1: ft_test
            Q2: chi_square
            Q3: ft_test
            
            Question columns:
            {prompt_body}
            
            Answer format:
            Q1: ft_test
            Q2: chi_square
            ...
            """
        # 3. LLM í˜¸ì¶œ (ì—†ìœ¼ë©´ ëª¨ë‘ ft_test)
        llm_result = None
        if non_manual_questions:
            messages = [
                {"role": "system", "content": "ë‹¹ì‹ ì€ í†µê³„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤." if lang == "í•œêµ­ì–´" else "You are a statistics expert."},
                {"role": "user", "content": prompt}
            ]
            try:
                llm_result = await self.make_openai_call(messages)
            except Exception as e:
                print(f"[decide_batch_test_types] LLM í˜¸ì¶œ ì‹¤íŒ¨: {e}")
                # fallback: ëª¨ë‘ ft_test
                llm_result = '\n'.join([f"{q['key']}: ft_test" for q in non_manual_questions])
        # 4. LLM ì‘ë‹µ íŒŒì‹±
        test_type_map = {key: 'manual' for key in manual_keys}
        if llm_result:
            import re
            for line in llm_result.splitlines():
                m = re.match(r"([\w\-]+):\s*(ft_test|chi_square)", line.strip(), re.I)
                if m:
                    key, ttype = m.group(1), m.group(2).lower()
                    test_type_map[key] = ttype
        # 5. ëˆ„ë½ëœ ì§ˆë¬¸ì€ ê¸°ë³¸ê°’(ft_test)
        for q in question_infos:
            if q['key'] not in test_type_map:
                test_type_map[q['key']] = 'ft_test'
        return test_type_map

    async def test_decision_node(self, state: AgentState, on_step=None) -> AgentState:
        """í†µê³„ ê²€ì • ë°©ë²• ê²°ì • ë…¸ë“œ (ì§ˆë¬¸ í…ìŠ¤íŠ¸ manual ì²´í¬, ì»¬ëŸ¼ëª… LLM íŒì •)"""
        if on_step:
            on_step("ğŸ§­ í†µê³„ ê²€ì • ê²°ì • ë…¸ë“œ ì‹œì‘")
        if state.selected_table is not None:
            columns = state.selected_table.columns.tolist()
            IGNORE_COLUMNS = {"ëŒ€ë¶„ë¥˜", "ì†Œë¶„ë¥˜", "ì‚¬ë¡€ìˆ˜", "row_name"}
            filtered_columns = [col for col in columns if col not in IGNORE_COLUMNS]
            question_text = getattr(state, 'selected_question', "")

            # manual ì²´í¬ (ì§ˆë¬¸ í…ìŠ¤íŠ¸ë§Œ)
            manual_check = self.rule_based_test_type_decision(question_text)
            if manual_check == "manual":
                state.test_type = "manual"
                return state

            # LLM í”„ë¡¬í”„íŠ¸ (ì»¬ëŸ¼ëª…ë§Œ)
            TEST_TYPE_PROMPT = """
ë‹¹ì‹ ì€ í†µê³„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì•„ë˜ëŠ” ì„¤ë¬¸ ì‘ë‹µ ê²°ê³¼ í…Œì´ë¸”ì˜ ì—´ ì´ë¦„ ëª©ë¡ì…ë‹ˆë‹¤. ì´ ì—´ë“¤ì€ ì‘ë‹µìë“¤ì´ ì„ íƒí•˜ê±°ë‚˜ í‰ê°€í•œ ì„¤ë¬¸ ë¬¸í•­ì˜ ê²°ê³¼ë¡œ êµ¬ì„±ëœ í†µê³„í‘œì…ë‹ˆë‹¤.

ë‹¹ì‹ ì˜ ì„ë¬´ëŠ”, ì´ í…Œì´ë¸”ì´ **ì–´ë–¤ í†µê³„ ê²€ì •(F/T-test ë˜ëŠ” Chi-square)** ì— ì í•©í•œì§€ë¥¼ íŒë‹¨í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

ğŸ“‹ ì—´ ì´ë¦„ ëª©ë¡:
{column_names}

---
Let's think step by step

íŒë‹¨ ê¸°ì¤€:

- `ft_test` (ì—°ì†í˜• ìˆ˜ì¹˜ ì‘ë‹µ):
    - ë¬¸í•­ì´ 1~5ì  ì²™ë„, í‰ê· , ë¹„ìœ¨, ì ìˆ˜ ë“± ìˆ«ì ê¸°ë°˜ìœ¼ë¡œ ìš”ì•½ë˜ì–´ ìˆë‹¤ë©´ F-test ë˜ëŠ” T-testê°€ ì ì ˆí•©ë‹ˆë‹¤.
    - ì˜ˆì‹œ ì—´ ì´ë¦„: "í‰ê· ", "ë§Œì¡±ë„ ì ìˆ˜", "~% ë¹„ìœ¨", "5ì  ì²™ë„", "í‰ê·  ì ìˆ˜", "ê´€ì‹¬ë„ í‰ê· "
    - "ì „í˜€ ê´€ì‹¬ì´ ì—†ë‹¤", "ë§¤ìš° ê´€ì‹¬ ìˆë‹¤" ë“±ì€ ì‹¤ì œë¡œëŠ” ì„ íƒì§€ì´ì§€ë§Œ, ë¹ˆë„ë‚˜ ë¹„ìœ¨ë¡œ ìˆ˜ì¹˜í™”ë˜ì—ˆì„ ê²½ìš° â†’ ì—°ì†í˜•ìœ¼ë¡œ íŒë‹¨

- `chi_square` (ë²”ì£¼í˜• ì„ íƒ ì‘ë‹µ):
    - ë¬¸í•­ì´ ì‘ë‹µìë“¤ì´ íŠ¹ì • í•­ëª©ì„ **ì„ íƒ**í•˜ê±°ë‚˜ **ë‹¤ì¤‘ì„ íƒ**í•œ ê²°ê³¼ì¼ ê²½ìš°, ë²”ì£¼í˜• ì‘ë‹µìœ¼ë¡œ ë³´ê³  ì¹´ì´ì œê³± ê²€ì •ì´ ì í•©í•©ë‹ˆë‹¤.
    - ì˜ˆì‹œ ì—´ ì´ë¦„: "ì£¼ìš” ì´ìš©ì‹œì„¤", "ì„ íƒ ì´ìœ ", "ê°€ì¥ ë§ì´ ì„ íƒí•œ ì¥ì†Œ", "ë‹¤ì¤‘ ì‘ë‹µ"
â— ì˜¤íŒ ì£¼ì˜:
- ì‘ë‹µ ì„ íƒì§€ ì´ë¦„(ì˜ˆ: "ì „í˜€ ê´€ì‹¬ ì—†ë‹¤", "ë§¤ìš° ê´€ì‹¬ ìˆë‹¤")ê°€ ì—´ ì´ë¦„ì— í¬í•¨ë˜ë”ë¼ë„, **ë¹„ìœ¨, í‰ê·  ë“±ì˜ ìˆ˜ì¹˜í˜• ìš”ì•½**ì´ë©´ `ft_test`ë¡œ ê°„ì£¼í•©ë‹ˆë‹¤.
- í…Œì´ë¸”ì´ ì „ì²´ì ìœ¼ë¡œ í‰ê· ê°’ ë˜ëŠ” %ë¹„ìœ¨ ì¤‘ì‹¬ì´ë©´ `ft_test` ì„ íƒì´ ë” ì ì ˆí•©ë‹ˆë‹¤.

---

ğŸ“Œ ë‹µë³€ í˜•ì‹: ì•„ë˜ì˜ í˜•ì‹ì²˜ëŸ¼ ì„ íƒì˜ ì´ìœ ì— ëŒ€í•´ì„œ ë‹µë³€í•˜ì§€ ë§ê³  "ì í•©í•œ í†µê³„ ê²€ì •ì˜ ë°©ë²•ë§Œ" ì¶œë ¥í•˜ì„¸ìš”.

- ë°˜ë“œì‹œ ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¡œë§Œ ë‹µí•´ì£¼ì„¸ìš” (ì†Œë¬¸ì):
    - ft_test
    - chi_square

ì í•©í•œ í†µê³„ ë°©ë²•: (ft_test ë˜ëŠ” chi_square)
"""
            column_names_str = ", ".join(filtered_columns)
            prompt = TEST_TYPE_PROMPT.format(column_names=column_names_str)

            # LLM í˜¸ì¶œ
            messages = [
                {"role": "system", "content": "ë‹¹ì‹ ì€ í†µê³„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ]
            llm_result = await self.make_openai_call(messages)
            llm_output = llm_result.strip() if hasattr(llm_result, 'strip') else str(llm_result)

            # normalize
            def normalize_test_type(llm_output: str) -> str:
                if "chi" in llm_output.lower():
                    return "chi_square"
                elif "ft" in llm_output.lower():
                    return "ft_test"
                else:
                    return "unknown"
            state.test_type = normalize_test_type(llm_output)
        return state
    
    def assign_significance_stars(self, p_value):
        if p_value < 0.001:
            return "***"
        elif p_value < 0.01:
            return "**"
        elif p_value < 0.05:
            return "*"
        else:
            return ""

    def extract_demo_mapping_from_dataframe(self, df, column="Unnamed: 0"):
        print(f"[extract_demo_mapping_from_dataframe] called with column: {column}")
        col = df[column].dropna().astype(str).reset_index(drop=True)
        print(f"[extract_demo_mapping_from_dataframe] col values: {col.tolist()}")
        cut_idx = None
        for i, val in enumerate(col):
            if val.strip() == 'DEMO1':
                cut_idx = i
                break
        sliced = col[:cut_idx] if cut_idx is not None else col

        demo_dict = {}
        import re
        for entry in sliced:
            entry = str(entry).strip()
            match = re.match(r"(DEMO\d+)[\s'\"]+(.+?)[\'\"\s\.]*$", entry)
            if match:
                key = match.group(1)
                label = match.group(2).strip()
                demo_dict[key] = label
        print(f"[extract_demo_mapping_from_dataframe] demo_dict: {demo_dict}")
        return demo_dict

    def summarize_ft_test(self, result_df, lang: str = "í•œêµ­ì–´") -> str:
        if not isinstance(result_df, pd.DataFrame) or result_df.empty:
            return "í†µê³„ ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
        significant = result_df[result_df["ìœ ì˜ì„±"] != ""]
        summary = []
        if not significant.empty:
            sig_items = significant["ëŒ€ë¶„ë¥˜"].tolist()
            if len(sig_items) == len(result_df):
                summary.append("ëª¨ë“  í•­ëª©ì—ì„œ í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ì°¨ì´ê°€ ê´€ì°°ë˜ì—ˆìŒ. ëŒ€ë¶„ë¥˜ ì „ë°˜ì— ê±¸ì³ ì˜ë¯¸ ìˆëŠ” ì°¨ì´ê°€ ì¡´ì¬í•¨." if lang == "í•œêµ­ì–´" else "All categories showed statistically significant differences. Broad variation was observed across major groups.")
            else:
                summary.append(f"{', '.join(sig_items)}ëŠ” í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•œ ì°¨ì´ë¥¼ ë³´ì˜€ìŒ." if lang == "í•œêµ­ì–´" else f"{', '.join(sig_items)} showed statistically significant differences.")
        else:
            if not result_df.empty:
                top3 = result_df.nsmallest(3, "p-value")[["ëŒ€ë¶„ë¥˜", "p-value"]]
                top3_text = ", ".join(f"{row['ëŒ€ë¶„ë¥˜']} (p={row['p-value']})" for _, row in top3.iterrows())
                summary.append(f"í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•œ í•­ëª©ì€ ì—†ì—ˆì§€ë§Œ, ìƒëŒ€ì ìœ¼ë¡œ p-valueê°€ ë‚®ì€ í•­ëª©ì€ {top3_text} ìˆœì´ì—ˆìŒ." if lang == "í•œêµ­ì–´" else f"No items reached statistical significance, but the ones with the lowest p-values were: {top3_text}.")
        return "  ".join(summary)

    def run_statistical_tests(self, test_type, df, question_key, demo_dict):
        import pandas as pd
        import numpy as np
        import scipy.stats as stats
        print(f"[run_statistical_tests] test_type: {test_type}")
        print(f"[run_statistical_tests] question_key: {question_key}")
        print(f"[run_statistical_tests] demo_dict: {demo_dict}")
        print(f"[run_statistical_tests] df.columns: {df.columns.tolist()}")
        # FT-test
        def run_ft_test_df(df: pd.DataFrame, question_key: str, demo_dict: dict) -> pd.DataFrame:
            question_key = question_key.replace("-", "_").strip()
            rows = []
            for demo_col, label in demo_dict.items():
                print(f"  [FT] demo_col: {demo_col}, label: {label}")
                if demo_col not in df.columns:
                    print(f"    [FT] demo_col '{demo_col}' not in df.columns")
                    continue
                try:
                    groups = df.groupby(demo_col)[question_key].apply(list)
                    group_values = [pd.Series(values).dropna().tolist() for values in groups]
                    print(f"    [FT] group_values lens: {[len(g) for g in group_values]}")
                    if len(group_values) < 2:
                        print(f"    [FT] group_values < 2, skip")
                        continue
                    levene_stat, levene_p = stats.levene(*group_values)
                    if len(group_values) == 2:
                        test_stat, test_p = stats.ttest_ind(
                            group_values[0], group_values[1],
                            equal_var=(levene_p > 0.05)
                        )
                    else:
                        test_stat, test_p = stats.f_oneway(*group_values)
                    row = {
                        "ëŒ€ë¶„ë¥˜": label,
                        "í†µê³„ëŸ‰": round(abs(test_stat), 3),
                        "p-value": round(test_p, 4),
                        "ìœ ì˜ì„±": self.assign_significance_stars(test_p)
                    }
                    print(f"    [FT] result row: {row}")
                    rows.append(row)
                except Exception as e:
                    print(f"    [FT] Exception: {e}")
                    continue
            result_df = pd.DataFrame(rows)
            print(f"[run_ft_test_df] result_df shape: {result_df.shape}")
            print(f"[run_ft_test_df] result_df: {result_df}")
            return result_df
        # Chi-square
        def run_chi_square_test_df(df: pd.DataFrame, question_key: str, demo_dict: dict) -> pd.DataFrame:
            question_key = question_key.replace("-", "_").strip()
            rows = []
            for demo_col, label in demo_dict.items():
                print(f"  [CHI] demo_col: {demo_col}, label: {label}")
                if demo_col not in df.columns:
                    print(f"    [CHI] demo_col '{demo_col}' not in df.columns")
                    continue
                try:
                    normalized_columns = {col.replace("-", "_").strip(): col for col in df.columns}
                    contingency_table = pd.crosstab(df[demo_col], df[normalized_columns[question_key]])
                    print(f"    [CHI] contingency_table shape: {contingency_table.shape}")
                    if contingency_table.shape[0] < 2 or contingency_table.shape[1] < 2:
                        print(f"    [CHI] contingency_table too small, skip")
                        continue
                    chi2, p, dof, expected = stats.chi2_contingency(contingency_table)
                    row = {
                        "ëŒ€ë¶„ë¥˜": label,
                        "í†µê³„ëŸ‰": round(chi2, 3),
                        "p-value": round(p, 4),
                        "ìœ ì˜ì„±": self.assign_significance_stars(p)
                    }
                    print(f"    [CHI] result row: {row}")
                    rows.append(row)
                except Exception as e:
                    print(f"    [CHI] Exception: {e}")
                    continue
            result_df = pd.DataFrame(rows)
            print(f"[run_chi_square_test_df] result_df shape: {result_df.shape}")
            print(f"[run_chi_square_test_df] result_df: {result_df}")
            return result_df
        # manual
        def run_manual_analysis(df: pd.DataFrame, question_key: str, demo_dict: dict) -> pd.DataFrame:
            question_key = question_key.replace("-", "_").strip()
            try:
                overall_row = df[df["ëŒ€ë¶„ë¥˜"].astype(str).str.strip() == "ì „ ì²´"]
                if overall_row.empty:
                    print("    [MANUAL] 'ì „ ì²´' ëŒ€ë¶„ë¥˜ í–‰ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                    return pd.DataFrame([])
                overall_value = overall_row[question_key].values[0]
                overall_n = overall_row["ì‚¬ë¡€ìˆ˜"].values[0]
                overall_std = df[question_key].std()
                std_error = overall_std / np.sqrt(overall_n)
                z_score = 1.96
                ci_lower = overall_value - z_score * std_error
                ci_upper = overall_value + z_score * std_error
                rows = []
                for idx, row in df.iterrows():
                    if row["ëŒ€ë¶„ë¥˜"] == "ì „ ì²´":
                        continue
                    group_value = row[question_key]
                    group_label = f"{row['ëŒ€ë¶„ë¥˜']} - {row['ì†Œë¶„ë¥˜']}" if pd.notna(row['ì†Œë¶„ë¥˜']) else row['ëŒ€ë¶„ë¥˜']
                    significant = group_value < ci_lower or group_value > ci_upper
                    rows.append({
                        "ëŒ€ë¶„ë¥˜": group_label,
                        "í‰ê· ê°’": group_value,
                        "ìœ ì˜ë¯¸ ì—¬ë¶€": "ìœ ì˜ë¯¸í•¨" if significant else "ë¬´ì˜ë¯¸í•¨",
                        "ê¸°ì¤€ í‰ê· ": overall_value,
                        "ì‹ ë¢°êµ¬ê°„": f"{round(ci_lower,1)} ~ {round(ci_upper,1)}",
                        "ìœ ì˜ì„±": "*" if significant else ""
                    })
                result_df = pd.DataFrame(rows)
                print(f"[run_manual_analysis] result_df shape: {result_df.shape}")
                print(f"[run_manual_analysis] result_df: {result_df}")
                return result_df
            except Exception as e:
                print(f"    [MANUAL] Exception: {e}")
                return pd.DataFrame([])
        if test_type == "ft_test":
            return run_ft_test_df(df, question_key, demo_dict)
        elif test_type =="chi_square":
            return run_chi_square_test_df(df, question_key, demo_dict)
        elif test_type == "manual":
            return run_manual_analysis(df, question_key, demo_dict)
        else:
            print(f"[run_statistical_tests] Invalid test_type: {test_type}")
            raise ValueError(f"âŒ ì˜ëª»ëœ test_type: {test_type}")

    async def ft_analysis_node(self, state: AgentState, on_step=None) -> AgentState:
        if on_step:
            on_step("âœ… F/T ë¶„ì„ ë…¸ë“œ ì‹œì‘")
        try:
            import pandas as pd
            from io import BytesIO
            if hasattr(state, 'raw_data_file') and state.raw_data_file is not None:
                print("[ft_analysis_node] raw_data_file exists")
                raw_data_file = BytesIO(state.raw_data_file) if isinstance(state.raw_data_file, (bytes, bytearray)) else state.raw_data_file
                raw_data = pd.read_excel(raw_data_file, sheet_name="DATA")
                demo_df = pd.read_excel(raw_data_file, sheet_name="DEMO")
                print(f"[ft_analysis_node] raw_data.columns: {raw_data.columns.tolist()}")
                print(f"[ft_analysis_node] demo_df.columns: {demo_df.columns.tolist()}")
                raw_data.columns = [col.replace("-", "_").strip() for col in raw_data.columns]
                demo_mapping = self.extract_demo_mapping_from_dataframe(demo_df)
                print(f"[ft_analysis_node] demo_mapping: {demo_mapping}")
                test_type = getattr(state, 'test_type', None)
                question_key = getattr(state, 'selected_key', None)
                lang = getattr(state, 'lang', "í•œêµ­ì–´")
                print(f"[ft_analysis_node] test_type: {test_type}, question_key: {question_key}, lang: {lang}")
                result_df = self.run_statistical_tests(test_type, raw_data, question_key, demo_mapping)
                print(f"[ft_analysis_node] result_df shape: {result_df.shape}")
                print(f"[ft_analysis_node] result_df: {result_df}")
                summary_text = self.summarize_ft_test(result_df, lang=lang)
                state.raw_data = raw_data
                state.ft_test_result = result_df
                state.ft_test_summary = summary_text
            else:
                print("[ft_analysis_node] raw_data_file is None")
                state.ft_error = "raw_data_fileì´ ì—†ìŠµë‹ˆë‹¤."
        except Exception as e:
            print(f"[ft_analysis_node] Exception: {e}")
            state.ft_error = str(e)
        return state
    
    async def get_anchor_node(self, state: AgentState, on_step=None) -> AgentState:
        """ì•µì»¤ ì¶”ì¶œ ë…¸ë“œ (Streamlit get_anchor ë¡œì§ ë°˜ì˜)"""
        if on_step:
            on_step("ğŸ“Œ ì•µì»¤ ì¶”ì¶œ ë…¸ë“œ ì‹œì‘")
        import pandas as pd
        selected_table = getattr(state, 'selected_table', None)
        lang = getattr(state, 'lang', 'í•œêµ­ì–´')
        anchor = []
        if selected_table is not None and isinstance(selected_table, pd.DataFrame):
            exclude_cols = set([
                "ëŒ€ë¶„ë¥˜", "ì†Œë¶„ë¥˜", "ì‚¬ë¡€ìˆ˜",
                "ëŒ€ë¶„ë¥˜_ì†Œë¶„ë¥˜"
            ])
            def is_anchor_candidate(col):
                col_str = str(col).strip()
                if col_str in exclude_cols:
                    return False
                # %ë¡œ ëë‚˜ëŠ” ì»¬ëŸ¼ ì œì™¸ (ê³µë°± í¬í•¨)
                if col_str.rstrip().endswith('%'):
                    return False
                # í‰ê· , í•©ê³„, std, score ë“± í¬í•¨ì‹œ ì œì™¸
                if any(keyword in col_str for keyword in ['í‰ê· ', 'í•©ê³„', 'std', 'score']):
                    return False
                return True
            # "ì „ ì²´" ë˜ëŠ” "ì „ì²´" row ì°¾ê¸° (ê³µë°± ì œê±°)
            total_row = selected_table[selected_table["ëŒ€ë¶„ë¥˜"].astype(str).str.strip().str.replace(" ", "") == "ì „ì²´"]
            if total_row.empty:
                state.anchor = []
                state.ft_error = "âŒ 'ì „ ì²´' ë˜ëŠ” 'ì „ì²´'ì— í•´ë‹¹í•˜ëŠ” í–‰ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
                return state
            total_row = total_row.iloc[0]
            candidate_cols = [col for col in selected_table.columns if is_anchor_candidate(col)]
            values = total_row[candidate_cols]
            values_numeric = pd.to_numeric(values, errors='coerce')
            high_value_cols = values_numeric.dropna().sort_values(ascending=False)
            cumulative_sum = 0
            selected_cols = []
            for col, val in high_value_cols.items():
                cumulative_sum += val
                selected_cols.append(col)
                if cumulative_sum >= 60:
                    break
            anchor = selected_cols
        state.anchor = anchor
        return state
    
    async def table_analyzer(self, state: AgentState, on_step=None) -> AgentState:
        """í…Œì´ë¸” ë¶„ì„ ë…¸ë“œ (Streamlit í”„ë¡¬í”„íŠ¸/ë¡œì§ ë°˜ì˜)"""
        if on_step:
            on_step("ğŸ¤– í…Œì´ë¸” ë¶„ì„ ë…¸ë“œ ì‹œì‘")
        lang = getattr(state, 'lang', 'í•œêµ­ì–´')
        linearized_table = getattr(state, 'linearized_table', '')
        ft_test_summary = getattr(state, 'ft_test_summary', '')
        selected_question = getattr(state, 'selected_question', '')
        anchor = getattr(state, 'anchor', 'ì—†ìŒ')
        prompt = self.TABLE_ANALYSIS_PROMPT[lang].format(
            selected_question=selected_question,
            linearized_table=linearized_table,
            ft_test_summary=str(ft_test_summary),
            anchor=anchor
        )
        messages = [
            {"role": "system", "content": "ë‹¹ì‹ ì€ í†µê³„ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤." if lang == "í•œêµ­ì–´" else "You are a statistical analysis expert."},
            {"role": "user", "content": prompt}
        ]
        state.table_analysis = await self.make_openai_call(messages)
        return state
    
    async def hallucination_check_node(self, state: AgentState, on_step=None) -> AgentState:
        """í™˜ê° ê²€ì¦ ë…¸ë“œ (Streamlit í”„ë¡¬í”„íŠ¸/ë¡œì§ ë°˜ì˜)"""
        if on_step:
            on_step("ğŸ§  í™˜ê° í‰ê°€ ë…¸ë“œ ì‹œì‘")
        lang = getattr(state, 'lang', 'í•œêµ­ì–´')
        hallucination_reject_num = getattr(state, 'hallucination_reject_num', 0)
        # ìˆ˜ì • ì´ë ¥ì´ ìˆìœ¼ë©´ ë§ˆì§€ë§‰ ìˆ˜ì •ë³¸ ì‚¬ìš©
        if hasattr(state, 'revised_analysis_history') and state.revised_analysis_history:
            table_analysis = state.revised_analysis_history[-1]
        else:
            table_analysis = getattr(state, 'table_analysis', '')
        prompt = self.HALLUCINATION_CHECK_PROMPT[lang].format(
            selected_question=getattr(state, 'selected_question', ''),
            linearized_table=getattr(state, 'linearized_table', ''),
            ft_test_summary=str(getattr(state, 'ft_test_summary', '')),
            table_analysis=table_analysis
        )
        messages = [
            {"role": "system", "content": "ë‹¹ì‹ ì€ í†µê³„ í•´ì„ ê²°ê³¼ë¥¼ ê²€ì¦í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤." if lang == "í•œêµ­ì–´" else "You are a statistical analysis auditor."},
            {"role": "user", "content": prompt}
        ]
        result = await self.make_openai_call(messages)
        result_str = result.strip() if hasattr(result, 'strip') else str(result)
        if result_str.lower().startswith("reject"):
            decision = "reject"
            feedback = result_str[len("reject"):].strip(": ").strip()
            hallucination_reject_num += 1
            if hasattr(state, 'revised_analysis_history'):
                state.revised_analysis_history.append(table_analysis)
            else:
                state.revised_analysis_history = [table_analysis]
        else:
            decision = "accept"
            feedback = ""
        state.hallucination_check = decision
        state.feedback = feedback
        state.hallucination_reject_num = hallucination_reject_num
        return state
    
    async def revise_table_analysis(self, state: AgentState, on_step=None) -> AgentState:
        """ë¶„ì„ ìˆ˜ì • ë…¸ë“œ (Streamlit í”„ë¡¬í”„íŠ¸/ë¡œì§ ë°˜ì˜)"""
        if on_step:
            on_step("âœï¸ ë¶„ì„ ìˆ˜ì • ë…¸ë“œ ì‹œì‘")
        lang = getattr(state, 'lang', 'í•œêµ­ì–´')
        # report_to_modifyëŠ” revised_historyê°€ ìˆìœ¼ë©´ ë§ˆì§€ë§‰ ê²ƒì„, ì—†ìœ¼ë©´ ì´ˆì•ˆì„ fallback
        report_to_modify = state.revised_analysis_history[-1] if getattr(state, 'revised_analysis_history', None) else getattr(state, 'table_analysis', '')
        prompt = self.REVISION_PROMPT[lang].format(
            linearized_table=getattr(state, 'linearized_table', ''),
            ft_test_summary=str(getattr(state, 'ft_test_summary', '')),
            anchor=getattr(state, 'anchor', ''),
            report_to_modify=report_to_modify,
            feedback=getattr(state, 'feedback', '')
        )
        messages = [
            {"role": "system", "content": "ë‹¹ì‹ ì€ í†µê³„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¸êµ¬ì§‘ë‹¨ ê°„ íŒ¨í„´ê³¼ ê²½í–¥ì„±ì„ ê°ê´€ì ìœ¼ë¡œ ìš”ì•½í•˜ëŠ” ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤." if lang == "í•œêµ­ì–´" else "You are a data analyst who objectively summarizes population-level patterns based on statistical data."},
            {"role": "user", "content": prompt}
        ]
        result = await self.make_openai_call(messages)
        new_revised_analysis = result.strip() if hasattr(result, 'strip') else str(result)
        # Append to revision history
        if hasattr(state, 'revised_analysis_history') and state.revised_analysis_history:
            revision_history = state.revised_analysis_history
        else:
            revision_history = []
        revision_history.append(new_revised_analysis)
        state.revised_analysis = new_revised_analysis
        state.revised_analysis_history = revision_history
        return state
    
    async def sentence_polish_node(self, state: AgentState, on_step=None) -> AgentState:
        """ë¬¸ì¥ ë‹¤ë“¬ê¸° ë…¸ë“œ (Streamlit í”„ë¡¬í”„íŠ¸/ë¡œì§ ë°˜ì˜)"""
        if on_step:
            on_step("ğŸ’… ë¬¸ì¥ ë‹¤ë“¬ê¸° ë…¸ë“œ ì‹œì‘")
        lang = getattr(state, 'lang', 'í•œêµ­ì–´')
        hallucination_reject_num = getattr(state, 'hallucination_reject_num', 0)
        raw_summary = state.revised_analysis if hallucination_reject_num > 0 else state.table_analysis
        prompt = self.POLISHING_PROMPT[lang].format(raw_summary=raw_summary)
        messages = [
            {"role": "system", "content": "ë‹¹ì‹ ì€ í†µê³„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‘ì„±ëœ í•œêµ­ì–´ ë³´ê³ ì„œë¥¼ ë‹¤ë“¬ëŠ” ë¬¸ì²´ ì „ë¬¸ ì—ë””í„°ì…ë‹ˆë‹¤." if lang == "í•œêµ­ì–´" else "You are a stylistic editor for statistical summaries written in Korean."},
            {"role": "user", "content": prompt}
        ]
        result = await self.make_openai_call(messages)
        polishing_result = result.strip() if hasattr(result, 'strip') else str(result)
        state.polishing_result = polishing_result
        return state
    
    async def execute(self, file_content: bytes, file_name: str, options: Dict[str, Any] = None, raw_data_content: bytes = None, raw_data_filename: str = None) -> Dict[str, Any]:
        """ì›Œí¬í”Œë¡œìš° ì‹¤í–‰"""
        try:
            # ì´ˆê¸° ìƒíƒœ ì„¤ì •
            state = AgentState(
                uploaded_file=file_content,
                file_path=file_name,
                analysis_type=options.get("analysis_type", True) if options else True,
                selected_key=options.get("selected_key", "") if options else "",
                lang=options.get("lang", "í•œêµ­ì–´") if options else "í•œêµ­ì–´",
                user_id=options.get("user_id") if options else None,
                raw_data_file=raw_data_content
            )
            
            on_step = options.get("on_step") if options else None
            
            # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
            state = await self.table_parser_node(state, on_step)
            state = await self.hypothesis_generate_node(state, on_step)
            state = await self.test_decision_node(state, on_step)
            state = await self.ft_analysis_node(state, on_step)
            state = await self.get_anchor_node(state, on_step)
            state = await self.table_analyzer(state, on_step)
            
            # í™˜ê° ê²€ì¦ ë° ìˆ˜ì • ë£¨í”„
            max_revisions = 4
            while state.hallucination_reject_num < max_revisions:
                state = await self.hallucination_check_node(state, on_step)
                if state.hallucination_check == "accept":
                    break
                elif state.hallucination_check == "reject":
                    if state.hallucination_reject_num >= 4:
                        if on_step:
                            on_step("âš ï¸ ê±°ë¶€ íšŸìˆ˜ ì´ˆê³¼, ì¢…ë£Œí•©ë‹ˆë‹¤.")
                        break
                    state = await self.revise_table_analysis(state, on_step)
                    state.hallucination_reject_num += 1
                else:
                    raise Exception(f"ì˜ˆìƒì¹˜ ëª»í•œ ê²°ì •: {state.hallucination_check}")
            
            state = await self.sentence_polish_node(state, on_step)
            
            return {
                "success": True,
                "result": {
                    "polishing_result": state.polishing_result,
                    "table_analysis": state.table_analysis,
                    "ft_test_summary": state.ft_test_summary,
                    "generated_hypotheses": state.generated_hypotheses,
                    "anchor": state.anchor,
                    "revised_analysis_history": state.revised_analysis_history,
                    "test_type": state.test_type,
                    "ft_test_result": state.ft_test_result.to_dict(orient="records") if hasattr(state.ft_test_result, "to_dict") else state.ft_test_result,
                    "revised_analysis_history": state.revised_analysis_history
                }
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": str(e)
            } 

    async def execute_batch(self, file_content: bytes, file_name: str, test_type_map: dict, lang: str = "í•œêµ­ì–´", user_id: Optional[str] = None, raw_data_content: Optional[bytes] = None, raw_data_filename: Optional[str] = None) -> dict:
        """ì „ì²´(ë°°ì¹˜) ë¶„ì„: ì§ˆë¬¸ë³„ test_typeì„ ë°›ì•„ ê° ì§ˆë¬¸ì— ëŒ€í•´ ë¶„ì„ì„ ìˆ˜í–‰"""
        from copy import deepcopy
        # í…Œì´ë¸” íŒŒì‹±
        parsed = await self.load_survey_tables(file_content, file_name)
        tables = parsed["tables"]
        question_texts = parsed["question_texts"]
        question_keys = parsed["question_keys"]
        results = {}
        for key in question_keys:
            state = AgentState(
                uploaded_file=file_content,
                file_path=file_name,
                analysis_type=False,
                selected_key=key,
                lang=lang,
                user_id=user_id,
                raw_data_file=raw_data_content
            )
            # í…Œì´ë¸”/ì§ˆë¬¸ ì„¸íŒ…
            state.tables = tables
            state.question_texts = question_texts
            state.question_keys = question_keys
            state.selected_key = key
            state.selected_table = tables[key]
            state.selected_question = question_texts[key]
            # test_type ì§€ì • (LLM ì¶”ì²œ or ì‚¬ìš©ì ìˆ˜ì •)
            state.test_type = test_type_map.get(key, "ft_test")
            # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ (ê°€ì„¤~í´ë¦¬ì‹±ê¹Œì§€)
            try:
                state = await self.hypothesis_generate_node(state)
                state = await self.ft_analysis_node(state)
                state = await self.get_anchor_node(state)
                state = await self.table_analyzer(state)
                # í™˜ê° ê²€ì¦ ë° ìˆ˜ì • ë£¨í”„
                max_revisions = 4
                while state.hallucination_reject_num < max_revisions:
                    state = await self.hallucination_check_node(state)
                    if state.hallucination_check == "accept":
                        break
                    elif state.hallucination_check == "reject":
                        if state.hallucination_reject_num >= 4:
                            break
                        state = await self.revise_table_analysis(state)
                        state.hallucination_reject_num += 1
                    else:
                        break
                state = await self.sentence_polish_node(state)
                results[key] = {
                    "polishing_result": state.polishing_result,
                    "table_analysis": state.table_analysis,
                    "ft_test_summary": state.ft_test_summary,
                    "generated_hypotheses": state.generated_hypotheses,
                    "anchor": state.anchor,
                    "revised_analysis_history": state.revised_analysis_history,
                    "test_type": state.test_type,
                    "ft_test_result": state.ft_test_result.to_dict(orient="records") if hasattr(state.ft_test_result, "to_dict") else state.ft_test_result,
                }
            except Exception as e:
                results[key] = {"error": str(e)}
        return {"success": True, "result": results} 